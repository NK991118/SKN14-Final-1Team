{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f88a97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c49b271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\playdata\\miniconda3\\envs\\final_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\playdata\\AppData\\Local\\Temp\\ipykernel_27164\\3941828245.py:20: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vs = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store loaded. Count: 3536\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from openai import OpenAI\n",
    "\n",
    "# 경로/모델 설정\n",
    "DB_DIR = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"qna_collection\"\n",
    "EMBED_MODEL = \"BAAI/bge-m3\"\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "TOP_K = 5\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBED_MODEL,\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "# 크로마 벡터스토어 로드\n",
    "vs = Chroma(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    persist_directory=DB_DIR,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "# OpenAI 클라이언트\n",
    "oclient = OpenAI()\n",
    "\n",
    "print(\"Vector store loaded. Count:\", vs._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2464f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\playdata\\AppData\\Local\\Temp\\ipykernel_27164\\4218759091.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  test_docs = retriever.get_relevant_documents(\"BigQuery에서 새로운 데이터셋을 생성하는 방법은 무엇인가요?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 결과 개수: 5\n",
      "[1] source: [\"https://cloud.google.com/bigquery/docs/reference/rest\"]\n",
      "Q: BigQuery에서 새로운 데이터셋을 생성하는 방법은 무엇인가요? A: 새로운 데이터셋을 생성하려면 다음의 API 메서드를 사용합니다: `insert` 메서드. 요청은 다음과 같이 구성됩니다:  ``` POST /bigquery/v2/projects/{projectId}/datasets ``` 여기서 `{projectId}`는 데이터셋을 생성할 프로젝 \n",
      "---\n",
      "[2] source: [\"https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/insert\"]\n",
      "Q: BigQuery에서 새로운 데이터셋을 생성하기 위한 HTTP 요청은 어떻게 구성하나요? A: 새로운 데이터셋을 생성하기 위한 HTTP 요청은 다음과 같이 구성됩니다:  ``` POST https://bigquery.googleapis.com/bigquery/v2/projects/{projectId}/datasets ``` 여기서 `{projectId} \n",
      "---\n",
      "[3] source: [\"https://cloud.google.com/bigquery/docs/reference/rest\"]\n",
      "Q: BigQuery에서 특정 데이터셋에 새로운 루틴을 생성하는 방법은 무엇인가요? A: 새로운 루틴을 생성하려면 다음의 REST API를 사용합니다: POST /bigquery/v2/projects/{projectId}/datasets/{datasetId}/routines \n",
      "---\n",
      "[4] source: [\"https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets\"]\n",
      "Q: BigQuery 데이터셋에 대한 태그를 설정하는 방법은 무엇인가요? A: 데이터셋에 태그(resourceTags)를 추가하려면, 데이터셋을 생성할 때 해당 필드를 사용하여 태그를 지정해야 합니다. 태그 키는 전역적으로 고유해야 하며, 예를 들어 '123456789012/environment' 형식이어야 합니다. 태그 값은 짧은 이름이어야 하며, 예를  \n",
      "---\n",
      "[5] source: [\"https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/insert\"]\n",
      "Q: BigQuery에서 새로운 테이블을 생성하기 위한 HTTP 요청은 어떻게 구성하나요? A: 새로운 테이블을 생성하기 위한 HTTP 요청은 다음과 같이 구성됩니다:  ``` POST https://bigquery.googleapis.com/bigquery/v2/projects/{projectId}/datasets/{datasetId}/tables ``` \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "retriever = vs.as_retriever(search_kwargs={\"k\": TOP_K})\n",
    "test_docs = retriever.get_relevant_documents(\"BigQuery에서 새로운 데이터셋을 생성하는 방법은 무엇인가요?\")\n",
    "print(\"검색 결과 개수:\", len(test_docs))\n",
    "for i, d in enumerate(test_docs, 1):\n",
    "    print(f\"[{i}] source:\", d.metadata.get(\"source\") or d.metadata.get(\"sources\"))\n",
    "    print(d.page_content[:200].replace(\"\\n\",\" \"), \"\\n---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae97e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _show_sources(meta) -> str:\n",
    "\n",
    "    s = meta.get(\"source\")\n",
    "    if not s:\n",
    "        s = meta.get(\"sources\")\n",
    "        if isinstance(s, list):\n",
    "            s = \", \".join([str(x) for x in s])\n",
    "    return s or \"(no source)\"\n",
    "\n",
    "def build_messages(user_query: str, docs):\n",
    "    lines = []\n",
    "    for i, d in enumerate(docs, start=1):\n",
    "        src = _show_sources(d.metadata or {})\n",
    "        body = d.page_content[:1200]\n",
    "        lines.append(f\"[{i}] source={src}\\n{body}\")\n",
    "    context_block = \"\\n\\n\".join(lines) if lines else \"(no context)\"\n",
    "\n",
    "    system_prompt = (\n",
    "        \"너는 Google API 문서 기반 한국어 어시스턴트다. \"\n",
    "        \"아래 제공된 근거 스니펫 안에서 확인 가능한 내용만 답하고, 모르면 모른다고 말해라. \"\n",
    "        \"고유 식별자/API/메서드/필드/에러명/옵션명은 원문 영문을 괄호로 병기하고, \"\n",
    "        \"코드 블록은 수정/번역하지 말고 그대로 인용해라.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"\"\"사용자 질문:\n",
    "{user_query}\n",
    "\n",
    "[근거 스니펫]\n",
    "{context_block}\n",
    "\n",
    "요구사항:\n",
    "- 스니펫에서 직접 확인 가능한 사실만 사용.\n",
    "- 불확실하면 추측하지 말고 부족하다고 명시.\n",
    "- 가능하면 답변 끝에 참조 URL을 [1], [2] 형식으로 표기.\n",
    "- 최종 출력은 한국어.\n",
    "\"\"\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "def rag_answer(query: str, top_k: int = TOP_K):\n",
    "    # 1) 검색\n",
    "    retriever = vs.as_retriever(search_kwargs={\"k\": top_k})\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "    # 2) LLM 호출\n",
    "    messages = build_messages(query, docs)\n",
    "    resp = oclient.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    answer = resp.choices[0].message.content\n",
    "    return answer, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b77dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 답변 ===\n",
      "BigQuery에서 새로운 데이터셋을 생성하려면 `insert` 메서드를 사용해야 합니다. 요청은 다음과 같이 구성됩니다:\n",
      "\n",
      "```\n",
      "POST /bigquery/v2/projects/{projectId}/datasets\n",
      "```\n",
      "\n",
      "여기서 `{projectId}`는 데이터셋을 생성할 프로젝트의 ID입니다. \n",
      "\n",
      "자세한 내용은 [1], [2]를 참조하세요.\n",
      "\n",
      "=== 근거 ===\n",
      "[1] [\"https://cloud.google.com/bigquery/docs/reference/rest\"]\n",
      "[2] [\"https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/insert\"]\n",
      "[3] [\"https://cloud.google.com/bigquery/docs/reference/rest\"]\n",
      "[4] [\"https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets\"]\n",
      "[5] [\"https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/insert\"]\n"
     ]
    }
   ],
   "source": [
    "question = \"BigQuery에서 새로운 데이터셋을 생성하는 방법은 무엇인가요?\"\n",
    "answer, evidences = rag_answer(question)\n",
    "\n",
    "print(\"=== 답변 ===\")\n",
    "print(answer.strip())\n",
    "\n",
    "print(\"\\n=== 근거 ===\")\n",
    "for i, d in enumerate(evidences, start=1):\n",
    "    print(f\"[{i}] {_show_sources(d.metadata or {})}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
