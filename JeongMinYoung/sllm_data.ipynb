{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 초기 system prompt 설정 및 벡터 store 생성",
   "id": "111c8c06253fd506"
  },
  {
   "cell_type": "code",
   "id": "4a1530950a5dfb25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:33:53.319807Z",
     "start_time": "2025-08-28T06:33:45.488327Z"
    }
   },
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from random import randint, choice\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# 벡터 DB 세팅\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_model)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 초기 질문 리스트 가져오기",
   "id": "11d07c79608e82fc"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-28T06:37:55.407750Z",
     "start_time": "2025-08-28T06:37:55.397135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def load_questions_from_jsonl_minimal(path: str, key: str = \"question\"):\n",
    "    \"\"\"JSONL에서 각 라인의 `question` 값만 순서/중복/공백 그대로 추출\"\"\"\n",
    "    questions = []\n",
    "    with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            obj = json.loads(line)\n",
    "            if isinstance(obj, dict) and key in obj:\n",
    "                questions.append(obj[key])\n",
    "    return questions\n",
    "\n",
    "# 사용 예시\n",
    "initial_questions = load_questions_from_jsonl_minimal(\"./question.jsonl\")\n",
    "initial_questions\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['프로젝트의 현재 완료율이 65%인 이유는 무엇인가요?',\n",
       " '기술적 문제 해결을 위해 어떤 추가 리소스가 투입될 예정인가요?',\n",
       " '홍길동의 개인 사정은 어떤 영향을 미쳤으며, 그에 대한 지원 방안은 무엇인가요?',\n",
       " '베타 버전 출시 일정이 2주 지연된 이유는 무엇인가요?',\n",
       " '테스트 단계에서 어떤 특정 모듈의 성능 저하가 발생했나요?',\n",
       " 'QA팀의 테스트 지원 요청에 대한 구체적인 내용은 무엇인가요?',\n",
       " '각 팀원이 매주 작업 진행 상황을 업데이트하는 방법은 어떤 방식으로 이루어지나요?',\n",
       " '외부 협력업체와의 일정 조율은 어떻게 진행되고 있나요?',\n",
       " '프로젝트 진행 상황을 주간 회의에서 어떻게 공유할 계획인가요?',\n",
       " '리스크 관리 섹션을 강화하기 위한 구체적인 방안은 무엇인가요?',\n",
       " '기술적 문제 해결을 위한 개발팀의 협의는 어떤 형태로 이루어지고 있나요?',\n",
       " '추가 리소스 투입 후 성과 점검은 어떤 기준으로 진행되나요?',\n",
       " '테스트 계획서의 내용은 어떻게 구성되어 있으며, 어떤 항목들이 포함되나요?',\n",
       " '사용자 피드백을 어떻게 수집하고 분석할 계획인가요?',\n",
       " '프로젝트 범위에 포함된 교육 콘텐츠는 어떤 형태로 제공될 예정인가요?',\n",
       " '향후 개정 이력에 대한 관리 방안은 어떻게 될 예정인가요?',\n",
       " '프로젝트의 성공적인 완료를 위해 필요한 추가적인 지원은 무엇인가요?',\n",
       " '특정 모듈의 성능 저하가 전체 플랫폼에 어떤 식으로 영향을 미칠 수 있나요?',\n",
       " '각 단계별 진척 상황을 어떻게 기록하고 관리할 예정인가요?',\n",
       " '홍길동 외에 다른 팀원들도 작업 지연이 발생하고 있나요?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:36:08.755015Z",
     "start_time": "2025-08-28T06:36:08.742189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SYSTEM_PROMPT = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"당신은 회사 내의 사내 문서 검색에 대한 정확한 답변을 하는 챗봇 어시스턴트 입니다.\"\n",
    "               \"대답은 항상 공손한 말투로 해야 합니다. \"\n",
    "               \"그리고 검색 결과로만 답변하세요. 문서 밖 지식 금지, 없으면 '해당 질문에 대한 내용이 없습니다.'라고 답하세요. 각 문장/문단 끝에 [[refN]] 인용을 남기세요.\"\n",
    "}\n",
    "\n",
    "def generate_one_chat_sample(initial_q: str, max_turns: int = 5):\n",
    "    messages = [SYSTEM_PROMPT]\n",
    "    current_q = initial_q\n",
    "    for turn in range(randint(2, max_turns + 1)):\n",
    "        # (1) User 질문 추가\n",
    "        messages.append({\"role\": \"user\", \"content\": current_q})\n",
    "\n",
    "        # (2) 문서 검색 (vectorstore에서)\n",
    "        docs = vectorstore.similarity_search(current_q, k=3)\n",
    "        ref_text = \"\\n\".join([f\"{doc.page_content} [[ref{idx+1}]]\" for idx, doc in enumerate(docs)])\n",
    "        messages.append({\"role\": \"system\", \"content\": f\"검색 결과:\\n-----\\n{ref_text}\"})\n",
    "\n",
    "        # (3) assistant 답변 (GPT로 RAG)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            temperature=0.\n",
    "        )\n",
    "        assistant_reply = response.choices[0].message.content\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "\n",
    "        # 다음 질문 생성 여부 랜덤 (5턴이 max면 4턴 미만일때만 질문 생성)\n",
    "        if turn < max_turns - 1 and choice([True, False]):\n",
    "            # (4) GPT에게 다음 질문 생성 요청\n",
    "            followup = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"앞선 대화를 기반으로 자연스러운 후속 질문 하나만 만들어줘.\"},\n",
    "                    *messages\n",
    "                ],\n",
    "                temperature=0.5 # 후속 질문 생성을 위해서 temperature 올림\n",
    "            )\n",
    "            current_q = followup.choices[0].message.content.strip()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return {\"messages\": messages}\n"
   ],
   "id": "8a3d8ed45acbadab",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:35:35.803373Z",
     "start_time": "2025-08-28T06:34:12.550573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = []\n",
    "for q in initial_questions:\n",
    "    sample = generate_one_chat_sample(q, max_turns=5)\n",
    "    train_dataset.append(sample)\n",
    "\n",
    "# 저장\n",
    "with open(\"train_dataset2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_dataset, f, ensure_ascii=False, indent=2)\n"
   ],
   "id": "f0ef55c136165569",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
