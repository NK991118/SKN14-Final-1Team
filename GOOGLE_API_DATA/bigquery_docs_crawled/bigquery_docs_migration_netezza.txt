Source URL: https://cloud.google.com/bigquery/docs/migration/netezza

BigQuery [https://cloud.google.com/bigquery?hl=ko]
Documentation [https://cloud.google.com/bigquery/docs?hl=ko]
가이드 [https://cloud.google.com/bigquery/docs/introduction?hl=ko]
도움이 되었나요?
의견 보내기
이 페이지의 내용
아키텍처 비교 [https://cloud.google.com/bigquery/docs/migration/netezza?hl=ko#architecture_comparison]
Netezza 아키텍처 [https://cloud.google.com/bigquery/docs/migration/netezza?hl=ko#netezza_architecture]
BigQuery 아키텍처 [https://cloud.google.com/bigquery/docs/migration/netezza?hl=ko#bigquery_architecture]
마이그레이션 전 [https://cloud.google.com/bigquery/docs/migration/netezza?hl=ko#pre-migration]
BigQuery 용량 계획 [https://cloud.google.com/bigquery/docs/migration/netezza?hl=ko#capacity_planning]
Google Cloud에서의 보안 [https://cloud.google.com/bigquery/docs/migration/netezza?hl=ko#security]
성능 벤치마킹 [https://cloud.google.com/bigquery/docs/migration/netezza?hl=ko#performance_benchmarking]
기본 프로젝트 설정 [https://cloud.google.com/bigquery/docs/migration/netezza?hl=ko#foundational_project_setup]
IBM Netezza에서 마이그레이션
bookmark_border
이 문서에서는 Netezza에서 BigQuery로 마이그레이션하는 방법에 대한 개략적인 안내를 제공합니다. Netezza와 BigQuery의 기본적인 아키텍처 차이점을 설명하고 BigQuery가 제공하는 추가 기능을 설명합니다. 또한 BigQuery의 이점을 극대화하기 위해 기존 데이터 모델과 추출, 변환, 로드(ETL) 프로세스를 재고하는 방법도 보여줍니다.
이 문서는 Netezza에서 BigQuery로 마이그레이션하고 마이그레이션 프로세스의 기술 과제를 해결하고자 하는 엔터프라이즈 아키텍트, DBA, 애플리케이션 개발자, IT 보안 전문가를 대상으로 합니다. 이 문서에서는 마이그레이션 프로세스의 다음 단계에 대한 세부정보를 제공합니다.
데이터 내보내기
데이터 수집
서드 파티 도구 활용
또한 일괄 SQL 변환 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko]을 사용하여 SQL 스크립트를 일괄적으로 마이그레이션하거나 대화형 SQL 변환 [https://cloud.google.com/bigquery/docs/interactive-sql-translator?hl=ko]을 사용하여 임시 쿼리를 변환할 수 있습니다. IBM Netezza SQL/NZPLSQL은 프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages] 상태의 두 도구에서 모두 지원됩니다.
아키텍처 비교
Netezza는 방대한 양의 데이터를 저장 및 분석하는 데 도움이 되는 강력한 시스템입니다. 하지만 Netezza와 같은 시스템에는 하드웨어, 유지보수, 라이선스에 대한 많은 투자가 필요합니다. 노드 관리, 소스당 데이터 볼륨, 보관처리 비용의 문제로 인해 확장이 어려울 수 있습니다. Netezza를 사용하는 경우 스토리지 및 처리 용량이 하드웨어 어플라이언스에 의해 제한됩니다. 최대 사용률에 도달하면 어플라이언스 용량 확장 프로세스가 정교해지며 불가능해질 수도 있습니다.
BigQuery를 사용하면 인프라를 관리할 필요가 없으며 데이터베이스 관리자도 필요하지 않습니다. BigQuery는 수십 초 내에 색인 없이 수십억 개의 행을 스캔할 수 있는 페타바이트 규모의 완전 관리형 서버리스 데이터 웨어하우스입니다. BigQuery는 Google의 인프라를 공유하므로 각 쿼리를 병렬 처리하고 수만 개의 서버에서 동시에 실행할 수 있습니다. BigQuery는 다음과 같이 차별화되는 핵심 기술이 있습니다.
열 형식 스토리지: 데이터는 행이 아닌 열에 저장되므로 매우 높은 압축 비율과 스캔 처리량을 확보할 수 있습니다.
트리 아키텍처: 쿼리는 디스패치되고 결과는 몇 초 내에 수천 개의 머신에서 집계됩니다.
Netezza 아키텍처
Netezza는 소프트웨어 데이터 추상화 레이어와 함께 제공되는 하드웨어 가속 어플라이언스입니다. 데이터 추상화 레이어는 어플라이언스의 데이터 배포를 관리하고 기본 CPU 및 FPGA 간에 데이터 처리를 분산하여 쿼리를 최적화합니다.
Netezza TwinFin 및 Striper 모델의 지원은 2019년 6월에 종료되었습니다.
다음 다이어그램은 Netezza 내의 데이터 추상화 레이어를 보여줍니다.
이 다이어그램은 다음 데이터 추상화 레이어를 보여줍니다.
디스크 인클로저: 디스크가 장착된 어플라이언스 내부의 실제 공간입니다.
디스크. 디스크 인클로저 내의 물리적 드라이브에서 데이터베이스와 테이블을 저장합니다.
데이터 슬라이스: 디스크에 저장된 데이터의 논리적 표현입니다. 배포 키를 사용하여 데이터가 데이터 슬라이스에 분산됩니다. nzds 명령어를 사용하여 데이터 슬라이스의 상태를 모니터링할 수 있습니다.
데이터 파티션: 특정 스니펫 처리 장치(SPU) [https://www.ibm.com/support/knowledgecenter/en/SSULQD_7.2.1/com.ibm.nz.adm.doc/r_sysadm_nz_hardware_components.html]에서 관리하는 데이터 슬라이스의 논리적 표현입니다. 각 SPU는 쿼리 중에 SPU가 처리하는 사용자 데이터를 포함하는 하나 이상의 데이터 파티션을 소유합니다.
모든 시스템 구성요소는 네트워크 패브릭으로 연결됩니다. Netezza 어플라이언스는 IP 주소 기반의 맞춤설정된 프로토콜을 실행합니다.
BigQuery 아키텍처
BigQuery는 머신러닝, 지리정보 분석, 비즈니스 인텔리전스와 같은 기본 제공 기능으로 데이터를 관리하고 분석할 수 있게 해주는 완전 관리형 엔터프라이즈 데이터 웨어하우스입니다. 자세한 내용은 BigQuery란 무엇인가요? [https://cloud.google.com/bigquery/docs/introduction?hl=ko]를 참조하세요.
BigQuery는 스토리지와 계산을 처리하여 분석 쿼리에 대해 내구성 있는 데이터 스토리지와 고성능 응답을 제공합니다. 자세한 내용은 BigQuery 설명 [https://cloud.google.com/blog/products/data-analytics/new-blog-series-bigquery-explained-overview?hl=ko]을 참고하세요.
BigQuery 가격 책정에 대한 자세한 내용은 BigQuery의 신속한 확장 및 간단한 가격 이해 [https://cloud.google.com/blog/products/gcp/understanding-bigquerys-rapid-scaling-and-simple-pricing?hl=ko]를 참조하세요.
마이그레이션 전
성공적인 데이터 웨어하우스 마이그레이션을 보장하기 위해 프로젝트 타임라인의 초기에 마이그레이션 전략을 계획합니다. 마이그레이션 작업을 체계적으로 계획하는 방법에 대한 자세한 내용은 마이그레이션 대상과 방법: 마이그레이션 프레임워크 [https://cloud.google.com/bigquery/docs/migration/migration-overview?hl=ko#what_and_how_to_migrate_the_migration_framework]를 참조하세요.
BigQuery 용량 계획
BigQuery의 분석 처리량은 슬롯 [https://cloud.google.com/bigquery/docs/slots?hl=ko] 단위로 측정됩니다. BigQuery 슬롯은 SQL 쿼리를 실행하는 데 필요한 Google의 독점적인 컴퓨팅, RAM, 네트워크 처리량 단위입니다. BigQuery는 쿼리 크기와 복잡성에 따라 각 쿼리에 필요한 슬롯 수를 자동으로 계산합니다.
BigQuery에서 쿼리를 실행하려면 다음 가격 책정 모델 중 하나를 선택합니다.
주문형 [https://cloud.google.com/bigquery/pricing?hl=ko#on_demand_pricing]: 각 쿼리에서 처리된 바이트 수에 대한 요금이 청구되는 기본 가격 책정 모델입니다.
용량 기반 가격 책정 [https://cloud.google.com/bigquery/pricing?hl=ko#capacity_compute_analysis_pricing]. 가상 CPU인 슬롯을 구매합니다. 슬롯을 구매하면 쿼리를 실행하는 데 사용할 수 있는 전용 처리 용량을 구매하는 것입니다. 슬롯은 다음 약정 요금제에서 사용할 수 있습니다.
연간: 365일 동안 약정합니다.
3년. 365*3일 동안 약정합니다.
BigQuery 슬롯은 CPU, 메모리, 데이터 처리 등 Netezza의 SPU와 유사한 점이 몇 가지 있습니다. 하지만 동일한 측정 단위를 나타내지는 않습니다. Netezza SPU에는 기본 하드웨어 구성요소에 대한 고정된 매핑이 있는 반면, BigQuery 슬롯은 쿼리를 실행하는 데 사용되는 가상 CPU를 나타냅니다. 슬롯 추정에 도움이 되도록 Cloud Monitoring을 사용한 BigQuery 모니터링 [https://cloud.google.com/bigquery/docs/monitoring?hl=ko]을 설정하고 BigQuery를 사용한 감사 로그를 분석 [https://cloud.google.com/bigquery/audit-logs?hl=ko]하는 것이 좋습니다. BigQuery 슬롯 사용률을 시각화하려면 Looker Studio [https://datastudio.google.com/c/?hl=ko] 또는 Looker [https://cloud.google.com/looker?hl=ko]와 같은 도구를 사용해도 됩니다. 슬롯 사용률을 정기적으로 모니터링하고 분석하면 Google Cloud에서 성장하는 데 필요한 총 슬롯 수를 추정하는데 도움이 됩니다.
예를 들어 처음에 2,000개의 BigQuery 슬롯 [https://cloud.google.com/bigquery/docs/slots?hl=ko]을 예약하여 50개의 중간 복잡성 쿼리를 동시에 실행한다고 가정해 보겠습니다. 쿼리를 실행하는 데 계속 몇 시간이 넘게 걸리고 대시보드에 높은 슬롯 사용률이 표시되면 쿼리가 최적화되지 않았거나 워크로드를 지원하기 위해 추가 BigQuery 슬롯이 필요할 수 있습니다. 연간 또는 3년 약정을 통해 슬롯을 직접 구매하려면 Google Cloud 콘솔 또는 bq 명령줄 도구를 사용하여 BigQuery 예약을 만들면 [https://cloud.google.com/bigquery/docs/reservations-get-started?hl=ko] 됩니다. 용량 기반 구매와 관련된 오프라인 계약을 체결한 경우에는 요금제가 여기에 나온 세부정보와 다를 수 있습니다.
BigQuery에서 스토리지 및 쿼리 처리 비용을 모두 제어하는 방법에 대한 자세한 내용은 워크로드 최적화 [https://cloud.google.com/bigquery/docs/admin-intro?hl=ko#optimize_workloads]를 참고하세요.
Google Cloud에서의 보안
다음 섹션에서는 일반적인 Netezza 보안 제어 및 Google Cloud 환경에서 데이터 웨어하우스를 보호하는 방법을 설명합니다.
ID 및 액세스 관리
Netezza 데이터베이스에는 사용자가 승인된 리소스에 액세스할 수 있게 해주는 완전 통합된 시스템 액세스 제어 기능 [https://www.ibm.com/support/knowledgecenter/en/SSULQD_7.2.1/com.ibm.nz.adm.doc/c_sysadm_nz_db_users_and_groups.html] 집합이 포함되어 있습니다.
Netezza에 대한 액세스는 운영체제에 로그인할 수 있는 Linux 사용자 계정을 관리하여 Netezza 어플라이언스에 대한 네트워크를 통해 제어합니다. Netezza 데이터베이스, 객체, 태스크에 대한 액세스는 시스템에 SQL 연결을 설정할 수 있는 Netezza 데이터베이스 사용자 계정을 사용하여 관리됩니다.
BigQuery는 Google의 Identity and Access Management(IAM) [https://cloud.google.com/bigquery/docs/access-control?hl=ko] 서비스를 사용하여 리소스에 대한 액세스를 관리합니다. BigQuery에서 사용 가능한 리소스 유형은 조직, 프로젝트, 데이터 세트, 테이블, 뷰입니다. IAM 정책 계층 구조에서 데이터 세트는 프로젝트의 하위 리소스입니다. 테이블은 이를 포함하는 데이터 세트에서 권한을 상속합니다.
리소스에 대한 액세스 권한을 부여하려면 사용자, 그룹 또는 서비스 계정에 역할을 하나 이상 할당합니다. 조직 및 프로젝트 역할은 작업을 실행하거나 프로젝트를 관리하기 위한 액세스 권한을 제어하는 반면, 데이터 세트 역할은 프로젝트 내의 데이터를 보거나 수정할 수 있는 액세스 권한을 제어합니다.
IAM은 다음과 같은 유형의 역할을 제공합니다.
사전 정의된 역할 [https://cloud.google.com/iam/docs/choose-predefined-roles?hl=ko]: 일반적인 사용 사례와 액세스 제어 패턴을 지원합니다.
기본 역할 [https://cloud.google.com/bigquery/docs/access-control-primitive-roles?hl=ko]: 소유자, 편집자, 뷰어 역할을 포함합니다. 기본 역할은 특정 서비스에 대한 세분화된 액세스 권한을 제공하며 Google Cloud에서 관리합니다.
커스텀 역할 [https://cloud.google.com/iam/docs/understanding-custom-roles?hl=ko]: 사용자 지정 권한 목록에 따라 세분화된 액세스 권한을 제공합니다.
사전 정의된 역할과 기본 역할을 모두 한 사용자에게 할당할 경우 각 개별 역할의 권한이 통합되어 부여됩니다.
행 수준 보안
다중 수준 보안은 Netezza에서 행 보안 테이블(RST) [https://www.ibm.com/support/knowledgecenter/en/SSULQD_7.2.1/com.ibm.nz.adv.doc/c_advsec_mls_and_row_secure_tables.html]에 대한 사용자 액세스를 제어하기 위한 규칙을 정의하는 데 사용하는 추상 보안 모델입니다. 행 보안 테이블은 행에 있는 보안 라벨로 적절한 권한이 없는 사용자를 필터링하는 데이터베이스 테이블입니다. 쿼리에 대해 반환되는 결과는 쿼리를 수행한 사용자의 권한에 따라 달라집니다.
BigQuery에서 행 수준 보안을 달성하기 위해서는 승인된 뷰 [https://cloud.google.com/bigquery/docs/authorized-views?hl=ko] 및 행 수준 액세스 정책 [https://cloud.google.com/bigquery/docs/managing-row-level-security?hl=ko]을 사용할 수 있습니다. 이러한 정책을 디자인하고 구현하는 방법에 대한 자세한 내용은 BigQuery 행 수준 보안 소개 [https://cloud.google.com/bigquery/docs/row-level-security-intro?hl=ko]를 참조하세요.
데이터 암호화
Netezza 어플라이언스는 어플라이언스에 저장된 데이터의 보안 및 보호를 개선하기 위해 자체 암호화 드라이브(SED) [https://www.ibm.com/support/knowledgecenter/en/SSULQD_7.2.1/com.ibm.nz.adm.doc/c_sysadm_sed_drives.html]를 사용합니다. SED는 데이터가 디스크에 기록될 때 데이터를 암호화합니다. 각 디스크에는 공장에서 설정되어 디스크에 저장되는 디스크 암호화 키(DEK)가 있습니다. 디스크는 데이터를 쓸 때 DEK를 사용하여 데이터를 암호화한 다음 디스크에서 데이터를 읽을 때 데이터를 복호화합니다. 디스크 작업과 암호화 및 복호화는 데이터를 읽고 쓰는 사용자에게 투명하게 공개됩니다. 이 기본 암호화 및 복호화 모드를 안전 삭제 모드라고 합니다.
안전 삭제 모드에서는 데이터를 복호화하고 읽는 데 인증 키나 비밀번호가 필요하지 않습니다. SED는 지원 또는 보증을 위해 디스크를 용도 변경하거나 반품해야 하는 상황에서 쉽고 빠르며 안전한 삭제를 위한 향상된 기능을 제공합니다.
Netezza는 대칭적 암호화를 사용합니다. 데이터가 필드 수준으로 암호화되면 다음 복호화 함수를 사용하여 데이터를 읽고 내보낼 수 있습니다.
varchar = decrypt(varchar text, varchar key [, int algorithm [, varchar IV]]);
nvarchar = decrypt(nvarchar text, nvarchar key [, int algorithm[, varchar IV]]);
BigQuery 내에 저장된 모든 데이터는 저장 데이터 암호화가 적용됩니다. 암호화를 직접 제어하려면 BigQuery용 고객 관리 암호화 키(CMEK)를 사용합니다. CMEK를 사용하면 Google에서 사용자 데이터를 보호하는 키 암호화 키를 관리하는 대신 사용자가 Cloud Key Management Service [https://cloud.google.com/kms/docs?hl=ko]에서 키 암호화 키를 제어하고 관리할 수 있습니다. 자세한 내용은 저장 데이터 암호화 [https://cloud.google.com/bigquery/docs/encryption-at-rest?hl=ko]를 참조하세요.
성능 벤치마킹
마이그레이션 프로세스 진행 상황과 개선을 추적하려면 현재 상태의 Netezza 환경에 대한 기준 성능을 설정하는 것이 중요합니다. 이 기준을 설정하려면 소비 애플리케이션(예: Tableau 또는 Cognos)에서 캡처된 표현 쿼리 집합을 선택합니다.
환경 Netezza BigQuery
데이터 크기 크기 TB -
쿼리 1: 이름(전체 테이블 스캔) mm:ss.ms -
쿼리 2: 이름 mm:ss.ms -
쿼리 3: 이름 mm:ss.ms -
합계 mm:ss.ms -
기본 프로젝트 설정
데이터 이전을 위해 스토리지 리소스를 프로비저닝하기 전에 프로젝트 설정을 완료해야 합니다.
프로젝트를 설정하고 프로젝트 수준에서 IAM을 사용 설정하려면 Google Cloud 아키텍처 프레임워크 [https://cloud.google.com/architecture/framework?hl=ko]를 참고하세요.
기업에 적합한 클라우드 배포를 만들기 위해 기본 리소스를 설계하려면 Google Cloud의 시작 영역 설계 [https://cloud.google.com/architecture/landing-zones?hl=ko]를 참고하세요.
온프레미스 데이터 웨어하우스를 BigQuery로 마이그레이션할 때 필요한 데이터 거버넌스 및 제어에 대해 알아보려면 데이터 보안 및 거버넌스 개요 [https://cloud.google.com/bigquery/docs/data-governance?hl=ko]를 참고하세요.
네트워크 연결
Netezza 인스턴스가 실행되는 온프레미스 데이터 센터와 Google Cloud환경 간에 안정적이고 안전한 네트워크 연결이 필요합니다. 연결을 보호하는 방법에 관한 자세한 내용은 BigQuery의 데이터 거버넌스 소개 [https://cloud.google.com/bigquery/docs/data-governance?hl=ko]를 참고하세요. 데이터 추출을 업로드할 때 네트워크 대역폭이 제한 요소가 될 수 있습니다. 데이터 전송 요구사항을 충족하는 방법에 관한 자세한 내용은 네트워크 대역폭 늘리기 [https://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets?hl=ko#increasing_network_bandwidth]를 참고하세요.
지원되는 데이터 유형 및 속성
Netezza 데이터 유형은 BigQuery 데이터 유형과 다릅니다. BigQuery 데이터 유형에 대한 자세한 내용은 데이터 유형 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko]을 참고하세요. Netezza와 BigQuery 데이터 유형 간의 자세한 비교는 IBM Netezza SQL 변환 가이드 [https://cloud.google.com/bigquery/docs/migration/netezza-sql?hl=ko]를 참조하세요.
SQL 비교
Netezza 데이터 SQL은 GoogleSQL과 달리 DDL, DML, Netezza 전용 데이터 제어 언어(DCL)로 구성됩니다. GoogleSQL [https://cloud.google.com/bigquery/docs/reference/standard-sql?hl=ko]은 SQL 2011 표준을 준수하며 중첩 및 반복 데이터 쿼리를 지원하는 확장 프로그램을 포함합니다. Legacy SQL을 사용 중인 경우, 이전 SQL 함수 및 연산자 [https://cloud.google.com/bigquery/query-reference?hl=ko]를 참조하세요. Netezza와 BigQuery SQL 및 함수 간의 자세한 비교는 IBM Netezza SQL 변환 가이드 [https://cloud.google.com/bigquery/docs/migration/netezza-sql?hl=ko]를 참조하세요.
SQL 코드 마이그레이션에 도움이 되도록 일괄 SQL 변환 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko]을 사용하여 SQL 코드를 일괄적으로 마이그레이션하거나 대화형 SQL 변환 [https://cloud.google.com/bigquery/docs/interactive-sql-translator?hl=ko]을 통해 임시 쿼리를 변환합니다.
함수 비교
Netezza 함수가 BigQuery 함수에 매핑되는 방식을 이해하는 것이 중요합니다. 예를 들어 Netezza Months_Between 함수는 소수를 출력하지만 BigQuery DateDiff 함수는 정수를 출력합니다. 따라서 맞춤 UDF 함수 [https://cloud.google.com/bigquery/docs/migration/netezza?hl=ko#replacing_months_between]를 사용하여 올바른 데이터 유형을 출력해야 합니다. Netezza SQL과 GoogleSQL 함수를 자세히 비교하려면 IBM Netezza SQL 변환 가이드 [https://cloud.google.com/bigquery/docs/migration/netezza-sql?hl=ko]를 참조하세요.
데이터 이전
Netezza에서 BigQuery로 데이터를 마이그레이션하려면 Netezza에서 데이터를 내보내고, Google Cloud에서 데이터를 전송 및 스테이징한 다음, BigQuery로 데이터를 로드합니다. 이 섹션에서는 데이터 마이그레이션 프로세스에 대한 대략적인 개요를 설명합니다. 데이터 마이그레이션 프로세스에 관한 자세한 설명은 스키마 및 데이터 마이그레이션 프로세스 [https://cloud.google.com/bigquery/docs/migration/schema-data-overview?hl=ko#schema_and_data_migration_process]를 참고하세요. Netezza와 BigQuery에서 지원되는 데이터 유형 간의 자세한 비교는 IBM Netezza SQL 변환 가이드 [https://cloud.google.com/bigquery/docs/migration/netezza-sql?hl=ko]를 참조하세요.
Netezza에서 데이터 내보내기
Netezza 데이터베이스 테이블의 데이터를 살펴보려면 CSV 형식으로 외부 테이블로 내보내는 것이 좋습니다. 자세한 내용은 원격 클라이언트 시스템에서 데이터 로드 취소 [https://www.ibm.com/docs/en/psfa/7.2.1?topic=tables-unloading-data-remote-client-system]를 참조하세요. Informatica(또는 커스텀 ETL)와 같은 서드 파티 시스템을 사용하여 데이터를 읽고 JDBC/ODBC 커넥터를 사용하여 CSV 파일을 생성할 수도 있습니다.
Netezza는 각 테이블에 압축되지 않은 플랫 파일(CSV)의 내보내기만 지원합니다. 하지만 대용량 테이블을 내보내는 경우 압축되지 않은 CSV가 매우 커질 수 있습니다. 가능하다면 CSV를 Parquet, Avro 또는 ORC와 같은 스키마 인식 형식으로 변환하는 것이 좋습니다. 그러면 안정성이 더 높고 크기가 작은 내보내기 파일이 생성됩니다. CSV가 사용할 수 있는 유일한 형식인 경우 Google Cloud에 업로드하기 전에 내보내기 파일을 압축하여 파일 크기를 줄이는 것이 좋습니다. 파일 크기를 줄이면 업로드 속도가 빨라지고 전송의 안정성이 향상됩니다. Cloud Storage로 파일을 전송할 때 gcloud storage cp 명령어 [https://cloud.google.com/sdk/gcloud/reference/storage/cp?hl=ko]에서 --gzip-local 플래그를 사용하면 업로드하기 전에 파일을 압축합니다.
데이터 전송 및 스테이징
데이터를 내보낸 후에는Google Cloud에서 전송하고 스테이징해야 합니다. 전송하는 데이터 양과 사용 가능한 네트워크 대역폭에 따라 여러 가지 데이터 전송 옵션이 있습니다. 자세한 내용은 스키마 및 데이터 전송 개요 [https://cloud.google.com/bigquery/docs/migration/schema-data-overview?hl=ko]를 참고하세요.
Google Cloud CLI를 사용하면 Cloud Storage로의 파일 전송을 자동화하고 병렬화할 수 있습니다. 파일 크기를 4TB(비압축)로 제한하면 BigQuery에 더 빠르게 로드할 수 있습니다. 단, 스키마를 미리 내보내야 합니다. 파티션 나누기 및 클러스터링을 사용하여 BigQuery를 최적화하기에 좋은 기회입니다.
gcloud storage bucket create [https://cloud.google.com/sdk/gcloud/reference/storage/buckets/create?hl=ko]를 사용하여 내보낸 데이터의 스토리지를 위한 스테이징 버킷을 만들고 gcloud storage cp [https://cloud.google.com/sdk/gcloud/reference/storage/cp?hl=ko]를 사용하여 데이터 내보내기 파일을 Cloud Storage 버킷으로 전송합니다.
gcloud CLI는 멀티스레딩과 멀티 프로세싱을 조합하여 복사 작업을 자동으로 실행합니다.
BigQuery에 데이터 로드
Google Cloud에서 데이터가 스테이징된 후에는 BigQuery에 데이터를 로드하는 몇 가지 옵션이 있습니다. 자세한 내용은 BigQuery에 스키마 및 데이터 로드 [https://cloud.google.com/bigquery/docs/migration/schema-data-overview?hl=ko#loading_the_data_into_bigquery]를 참고하세요.
파트너 도구 및 지원
마이그레이션 여정에서 파트너 지원을 받을 수 있습니다. SQL 코드 마이그레이션에 도움이 되도록 일괄 SQL 변환 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko]을 사용하여 SQL 코드를 일괄적으로 마이그레이션할 수 있습니다.
많은 Google Cloud 파트너가 데이터 웨어하우스 이전 서비스를 제공하기도 합니다. 파트너 및 제공되는 솔루션 목록은 BigQuery 전문성을 갖춘 파트너와 협력 [https://cloud.google.com/bigquery?hl=ko#partners-and-integration]을 참조하세요.
게시물 이전
데이터 이전이 완료되면 비즈니스 요구사항을 해결하기 위해Google Cloud 사용을 최적화할 수 있습니다.Google Cloud의 탐색 분석 및 시각화 도구를 사용하여 비즈니스 이해관계자를 위한 유용한 정보를 도출하거나 성능이 낮은 쿼리를 최적화 [https://cloud.google.com/bigquery/docs/best-practices-performance-overview?hl=ko]하거나 사용자 채택을 지원하는 프로그램을 개발할 수 있습니다.
인터넷을 통해 BigQuery API에 연결
다음 다이어그램은 API를 사용하여 외부 애플리케이션을 BigQuery에 연결하는 방법을 보여줍니다.
다이어그램은 다음 단계를 보여줍니다.
Google Cloud에 IAM 권한으로 서비스 계정이 생성됩니다. 서비스 계정 키는 JSON 형식으로 생성되며 프런트엔드 서버(예: MicroStrategy)에 복사됩니다.
이 프런트엔드가 키를 읽고 HTTPS의 Google API에서 OAuth 토큰을 요청합니다.
그런 다음 프런트엔드에서 토큰과 함께 BigQuery 요청을 BigQuery에 전송합니다.
자세한 내용은 API 요청 승인 [https://cloud.google.com/bigquery/docs/authorization?hl=ko]을 참조하세요.
BigQuery에 최적화
GoogleSQL은 SQL 2011 표준을 준수하며 중첩 및 반복 데이터 [https://cloud.google.com/bigquery/docs/arrays?hl=ko#querying_nested_arrays] 쿼리를 지원하는 확장 프로그램을 포함합니다. BigQuery 쿼리 최적화 [https://cloud.google.com/bigquery/docs/best-practices-performance-overview?hl=ko]는 성능 및 응답 시간을 개선하는 데 매우 중요합니다.
BigQuery의 Months_Between 함수를 UDF로 바꾸기
Netezza는 1개월의 날짜 수를 31로 처리합니다. 다음 커스텀 UDF는 근사한 정확도로 Netezza 함수를 다시 만들며, 이 함수를 쿼리를 통해 호출할 수 있습니다.
CREATE TEMP FUNCTION months_between(date_1 DATE, date_2 DATE)
AS (
  CASE
    WHEN date_1 = date_2
      THEN 0
    WHEN EXTRACT(DAY FROM DATE_ADD(date_1, INTERVAL 1 DAY)) = 1
      AND EXTRACT(DAY FROM DATE_ADD(date_2, INTERVAL 1 DAY)) = 1
      THEN date_diff(date_1,date_2, MONTH)
    WHEN EXTRACT(DAY FROM date_1) = 1
      AND EXTRACT(DAY FROM DATE_ADD(date_2, INTERVAL 1 DAY)) = 1
      THEN date_diff(DATE_ADD(date_1, INTERVAL -1 DAY), date_2, MONTH) + 1/31
    ELSE date_diff(date_1, date_2, MONTH) - 1 + ((EXTRACT(DAY FROM date_1) + (31 - EXTRACT(DAY FROM date_2))) / 31)
    END
);
Netezza 저장 프로시저 이전
ETL 워크로드에서 Netezza 저장 프로시저를 사용하여 사실 테이블을 구성하는 경우 이러한 저장 프로시저를 BigQuery 호환 SQL 쿼리로 이전해야 합니다. Netezza는 NZPLSQL 스크립트 언어를 사용하여 저장 프로시져 작업을 수행합니다. NZPLSQL은 Postgres PL/pgSQL 언어를 기반으로 합니다. 자세한 내용은 IBM Netezza SQL 변환 가이드 [https://cloud.google.com/bigquery/docs/migration/netezza-sql?hl=ko]를 참조하세요.
Netezza ASCII를 에뮬레이션하는 맞춤 UDF
다음 BigQuery용 커스텀 UDF는 열의 인코딩 오류를 수정합니다.
CREATE TEMP FUNCTION ascii(X STRING)
AS (TO_CODE_POINTS(x)[ OFFSET (0)]);
다음 단계
전반적인 성능 최적화 및 비용 감소를 위한 워크로드 최적화 [https://cloud.google.com/bigquery/docs/admin-intro?hl=ko#optimize_workloads] 방법 알아보기
BigQuery에서 스토리지 최적화 [https://cloud.google.com/bigquery/docs/best-practices-storage?hl=ko] 방법 알아보기
IBM Netezza SQL 변환 가이드 [https://cloud.google.com/bigquery/docs/migration/netezza-sql?hl=ko] 참조
도움이 되었나요?
의견 보내기