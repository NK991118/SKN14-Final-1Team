Source URL: https://cloud.google.com/bigquery/docs/programmatic-analysis

BigQuery [https://cloud.google.com/bigquery?hl=ko]
Documentation [https://cloud.google.com/bigquery/docs?hl=ko]
가이드 [https://cloud.google.com/bigquery/docs/introduction?hl=ko]
도움이 되었나요?
의견 보내기
이 페이지의 내용
Colab Enterprise 노트북 [https://cloud.google.com/bigquery/docs/programmatic-analysis?hl=ko#colab-notebooks]
BigQuery DataFrames [https://cloud.google.com/bigquery/docs/programmatic-analysis?hl=ko#bigquery-dataframes]
기타 프로그래매틱 분석 솔루션 [https://cloud.google.com/bigquery/docs/programmatic-analysis?hl=ko#other_programmatic_analysis_solutions]
Jupyter 노트북 [https://cloud.google.com/bigquery/docs/programmatic-analysis?hl=ko#jupyter_notebooks]
Apache Zeppelin [https://cloud.google.com/bigquery/docs/programmatic-analysis?hl=ko#apache_zeppelin]
Apache Hadoop, Apache Spark, Apache Hive [https://cloud.google.com/bigquery/docs/programmatic-analysis?hl=ko#apache_hadoop_apache_spark_and_apache_hive]
Apache Beam [https://cloud.google.com/bigquery/docs/programmatic-analysis?hl=ko#apache_beam]
기타 리소스 [https://cloud.google.com/bigquery/docs/programmatic-analysis?hl=ko#other_resources]
프로그래매틱 분석 도구
bookmark_border
이 문서에서는 BigQuery에서 관리되는 데이터를 분석하기 위한 코드를 작성하고 실행하는 여러 방법을 설명합니다.
SQL이 강력한 쿼리 언어이긴 해도 특정 유형의 데이터를 분석하기 위해서는 Python, 자바, R과 같은 프로그래밍 언어에서 제공되는 구문 및 여러 내장된 통계 함수를 사용하는 것이 더 직관적이고 쉬울 수 있습니다.
마찬가지로 스프레드시트가 널리 사용되더라도, 때로는 복잡한 데이터 분석 및 탐색을 수행할 때 메모장과 같은 더 탄력적인 가변형 환경을 이용는 것이 더 유연할 수 있습니다.
Colab Enterprise 노트북
BigQuery에서 Colab Enterprise 노트북 [https://cloud.google.com/bigquery/docs/notebooks-introduction?hl=ko]을 사용하여 SQL, Python, 기타 일반적인 패키지 및 API로 분석 및 머신러닝(ML) 워크플로를 완료할 수 있습니다. 노트북은 다음 옵션을 통한 향상된 공동작업 및 관리를 제공합니다.
Identity and Access Management(IAM)를 사용하여 특정 사용자 및 그룹과 노트북을 공유합니다.
노트북 버전 기록을 검토합니다.
이전 버전의 노트북으로 되돌리거나 브랜치를 만듭니다.
노트북은 Dataform [https://cloud.google.com/dataform/docs/overview?hl=ko]으로 구동되는 BigQuery Studio [https://cloud.google.com/bigquery/docs/query-overview?hl=ko#bigquery-studio] 코드 애셋입니다. 하지만 노트북은 Dataform에 표시되지 않습니다. 저장된 쿼리 [https://cloud.google.com/bigquery/docs/saved-queries-introduction?hl=ko]도 코드 애셋입니다. 모든 코드 애셋은 기본 리전 [https://cloud.google.com/bigquery/docs/programmatic-analysis?hl=ko#supported_regions]에 저장됩니다. 기본 리전을 업데이트하면 해당 시점 이후에 생성된 모든 코드 애셋의 리전이 변경됩니다.
노트북 기능은 Google Cloud 콘솔에서만 사용 가능합니다.
BigQuery의 노트북은 다음과 같은 이점을 제공합니다.
BigQuery DataFrames [https://cloud.google.com/python/docs/reference/bigframes/latest?hl=ko]는 노트북에 통합되므로 설정이 필요하지 않습니다. BigQuery DataFrames는 Pandas DataFrame [https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html] 및 scikit-learn [https://scikit-learn.org/stable/modules/classes.html] API를 사용해 BigQuery 데이터를 대규모로 분석하는 데 사용할 수 있는 Python API입니다.
Gemini 생성형 AI [https://cloud.google.com/bigquery/docs/write-sql-gemini?hl=ko]를 기반으로 하는 보조 코드 개발
노트북 버전을 저장, 공유, 관리하는 기능
워크플로의 어느 시점에서든 matplotlib [https://matplotlib.org/], Seaborn [https://seaborn.pydata.org/], 기타 인기 라이브러리를 사용하여 데이터를 시각화하는 기능
BigQuery DataFrames
BigQuery DataFrames [https://cloud.google.com/bigquery/docs/bigquery-dataframes-introduction?hl=ko]는 익숙한 Python API를 사용하여 BigQuery 데이터 처리를 활용할 수 있는 오픈소스 Python 라이브러리 집합입니다. BigQuery DataFrames는 SQL 변환을 통해 처리를 BigQuery로 내보내 Pandas 및 scikit-learn API를 구현합니다. 이 설계를 통해 BigQuery를 사용하여 Python API로 테라바이트 단위의 데이터를 탐색 및 처리하고 ML 모델을 학습시킬 수도 있습니다.
BigQuery DataFrames는 다음과 같은 이점을 제공합니다.
BigQuery 및 BigQuery ML API로의 투명한 SQL 변환을 통해 구현되는 750개 이상의 Pandas 및 scikit-learn API.
성능 향상을 위한 지연된 쿼리 실행.
클라우드에서 데이터를 처리할 수 있도록 사용자 정의 Python 함수로 데이터 변환을 확장. 이러한 함수는 BigQuery 원격 함수 [https://cloud.google.com/bigquery/docs/remote-functions?hl=ko]로 자동 배포됩니다.
Vertex AI와 통합하여 텍스트 생성에 Gemini 모델을 사용.
기타 프로그래매틱 분석 솔루션
BigQuery에서는 다음과 같은 프로그래매틱 분석 솔루션도 사용할 수 있습니다.
Jupyter 노트북
Jupyter [https://jupyter.org/]는 라이브 코드, 텍스트 설명, 시각화를 포함하는 노트북을 게시하기 위한 오픈소스 웹 기반 애플리케이션입니다. 데이터 과학자, 머신러닝 전문가, 학생들은 데이터 정리 및 변환, 수치 시뮬레이션, 통계적 모델링, 데이터 시각화, ML과 같은 작업에 이 플랫폼을 일반적으로 사용합니다.
Jupyter 노트북은 BigQuery용 IPython Magics [https://cloud.google.com/python/docs/reference/bigquery/latest/magics?hl=ko]를 사용하여 BigQuery와 직접 상호작용할 수 있는 강력한 대화형 셸인 IPython [https://ipython.org/] 커널을 기반으로 작성되었습니다. 또는 무엇이든 사용 가능한 BigQuery 클라이언트 라이브러리 [https://cloud.google.com/bigquery/docs/reference/libraries?hl=ko]를 설치하여 Jupyter 노트북 인스턴스에서 BigQuery에 액세스할 수 있습니다. GeoJSON 확장 프로그램 [https://github.com/jupyterlab/jupyter-renderers/tree/master/packages/geojson-extension]을 통해 Jupyter 메모장으로 BigQuery GIS [https://cloud.google.com/bigquery/docs/gis-intro?hl=ko] 데이터를 시각화할 수 있습니다. BigQuery 통합에 대한 자세한 내용은 Jupyter 노트북에서 BigQuery 데이터 시각화 [https://cloud.google.com/bigquery/docs/visualize-jupyter?hl=ko] 튜토리얼을 참조하세요.
JupyterLab [https://jupyterlab.readthedocs.io/en/stable/]은 Jupyter 노트북, 텍스트 편집기, 터미널, 커스텀 구성요소와 같이 문서 및 활동을 관리하기 위한 웹 기반 사용자 인터페이스입니다. JupyterLab에서는 탭과 분할자를 사용하여 작업 영역에 여러 문서 및 활동을 나란히 배열할 수 있습니다.
다음 제품 중 하나를 사용하여Google Cloud 에 Jupyter 메모장 및 JupyterLab 환경을 배포할 수 있습니다.
Vertex AI Workbench 인스턴스 [https://cloud.google.com/vertex-ai/docs/workbench/instances/introduction?hl=ko]는 머신러닝 개발자와 데이터 과학자가 최신 데이터 과학 및 머신러닝 프레임워크를 사용할 수 있는 통합 JupyterLab 환경을 제공하는 서비스입니다. Vertex AI Workbench는 BigQuery와 같은 다른 Google Cloud 데이터 제품과 통합되어, 데이터 수집으로부터 사전 처리 및 탐색, 모델 학습과 배포로 쉽게 이동할 수 있습니다. 자세한 내용은 Vertex AI Workbench 인스턴스 소개 [https://cloud.google.com/vertex-ai/docs/workbench/instances/introduction?hl=ko]를 참조하세요.
Dataproc [https://cloud.google.com/dataproc?hl=ko]은 간단하고 비용 효율적인 방식으로 Apache Spark [https://spark.apache.org/] 및 Apache Hadoop [https://hadoop.apache.org/] 클러스터를 실행하기 위한 빠르고 사용하기 쉬운 완전 관리형 서비스입니다. Jupyter 선택적 구성요소 [https://cloud.google.com/dataproc/docs/concepts/components/jupyter?hl=ko]를 사용하여 Dataproc 클러스터에 Jupyter 노트북 및 JupyterLab을 설치할 수 있습니다. 이 구성요소는 PySpark [https://pypi.org/project/pyspark/] 코드를 실행하기 위한 Python 커널을 제공합니다. 기본적으로 Dataproc은 Cloud Storage에 저장 [https://github.com/src-d/jgscm]할 노트북을 자동으로 구성하여 다른 클러스터가 동일한 노트북 파일에 액세스할 수 있게 합니다. 기존 노트북을 Dataproc에 마이그레이션할 때는 노트북의 종속 항목이 지원되는 Dataproc 버전 [https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=ko]에 포함되는지 확인하세요. 커스텀 소프트웨어를 설치해야 할 경우 자체 Dataproc 이미지를 만들거나 [https://cloud.google.com/dataproc/docs/guides/dataproc-images?hl=ko] 자체 초기화 작업 [https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/init-actions?hl=ko]을 작성하거나 커스텀 Python 패키지 요구사항을 지정 [https://cloud.google.com/dataproc/docs/tutorials/python-configuration?hl=ko]할 수 있습니다. 시작하려면 Dataproc 클러스터에 Jupyter 노트북 설치 및 실행 [https://cloud.google.com/dataproc/docs/tutorials/jupyter-notebook?hl=ko] 튜토리얼을 참조하세요.
Apache Zeppelin
Apache Zeppelin [https://zeppelin.apache.org/]은 데이터 애널리틱스를 위한 웹 기반 메모장을 제공하는 오픈소스 프로젝트입니다. Zeppelin 선택적 구성요소 [https://cloud.google.com/dataproc/docs/concepts/components/zeppelin?hl=ko]를 설치하여 Dataproc [https://cloud.google.com/dataproc?hl=ko]에 Apache Zeppelin 인스턴스를 배포할 수 있습니다. 기본적으로 노트북은 사용자가 지정하거나 클러스터를 만들 때 자동 생성되는 Cloud Dataproc 스테이징 버킷의 Cloud Storage에 저장됩니다. 클러스터를 만들 때 속성 zeppelin:zeppelin.notebook.gcs.dir을 추가하여 노트북 위치를 변경할 수 있습니다. Apache Zeppelin 설치 및 구성에 관한 자세한 내용은 Zeppelin 구성요소 가이드 [https://cloud.google.com/dataproc/docs/concepts/components/zeppelin?hl=ko]를 참고하세요. 예를 들어 Apache Zeppelin을 위한 BigQuery 인터프리터를 사용하여 BigQuery 데이터 세트 분석 [https://cloud.google.com/blog/products/gcp/analyzing-bigquery-datasets-using-bigquery-interpreter-for-apache-zeppelin?hl=ko]을 참고하세요.
Apache Hadoop, Apache Spark, Apache Hive
데이터 분석 파이프라인 마이그레이션 중에는 데이터 웨어하우스에서 직접 데이터를 처리해야 하는 일부 레거시 Apache Hadoop [https://hadoop.apache.org/], Apache Spark [https://spark.apache.org/] 또는 Apache Hive [https://hive.apache.org/] 작업을 마이그레이션해야 할 수 있습니다. 예를 들어 머신러닝 워크로드를 위한 기능을 추출해야 할 수 있습니다.
Dataproc을 사용하면 효율적이고 비용 효과적인 방식으로 완전 관리형 Hadoop 및 Spark 클러스터를 배포할 수 있습니다. Dataproc은 오픈소스 BigQuery 커넥터 [https://cloud.google.com/dataproc/docs/concepts/connectors/bigquery?hl=ko]와 통합됩니다. 이러한 커넥터는 gRPC를 통해 BigQuery에서 직접 데이터를 병렬로 스트리밍하는 BigQuery Storage API [https://cloud.google.com/bigquery/docs/reference/storage?hl=ko]를 사용합니다.
기존 Hadoop 및 Spark 워크로드를 Dataproc에 마이그레이션할 때는 워크로드의 종속 항목이 지원되는 Dataproc 버전 [https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=ko]에 포함되는지 확인할 수 있습니다. 커스텀 소프트웨어를 설치해야 할 경우 자체 Dataproc 이미지를 만들거나 [https://cloud.google.com/dataproc/docs/guides/dataproc-images?hl=ko] 자체 초기화 작업 [https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/init-actions?hl=ko]을 작성하거나 커스텀 Python 패키지 요구사항을 지정 [https://cloud.google.com/dataproc/docs/tutorials/python-configuration?hl=ko]할 수 있습니다.
시작하려면 Dataproc 빠른 시작 가이드 [https://cloud.google.com/dataproc/docs/quickstarts?hl=ko] 및 BigQuery 커넥터 코드 샘플 [https://cloud.google.com/dataproc/docs/examples/bigquery-example?hl=ko]을 참조하세요.
Apache Beam
Apache Beam [https://beam.apache.org/]은 BigQuery용 커넥터 [https://beam.apache.org/documentation/io/built-in/google-bigquery/]를 포함하여 소스 및 싱크 커넥터의 생태계는 물론 다양한 윈도잉과 세션 분석 기본 도구를 제공하는 오픈소스 프레임워크입니다. Apache Beam은 스트리밍(실시간) 모드와 일괄(기록) 모드에서 신뢰성과 표현 능력을 동일하게 지원하면서 데이터를 변환하고 강화할 수 있게 해줍니다.
Dataflow [https://cloud.google.com/dataflow?hl=ko]는 Apache Beam 작업을 대규모로 실행하기 위한 완전 관리형 서비스입니다. Dataflow 서버리스 접근 방식은 성능, 확장, 가용성, 보안 및 규정 준수가 자동으로 처리되어 운영 오버헤드가 없기 때문에 서버 클러스터 관리 대신 프로그래밍에 집중할 수 있습니다.
Dataflow 작업은 명령줄 인터페이스 [https://cloud.google.com/dataflow/docs/guides/using-command-line-intf?hl=ko], 자바 SDK [https://beam.apache.org/documentation/sdks/java/], Python SDK [https://beam.apache.org/documentation/sdks/python/]를 통해 여러 방법으로 제출할 수 있습니다.
다른 프레임워크에서 Apache Beam 및 Dataflow로 데이터 쿼리 및 파이프라인을 마이그레이션하려면 Apache Beam 프로그래밍 모델 [https://cloud.google.com/dataflow/docs/concepts/beam-programming-model?hl=ko] 및 공식 Dataflow 문서 [https://cloud.google.com/dataflow/docs?hl=ko]를 참조하세요.
기타 리소스
BigQuery는 자바, Go, Python, 자바스크립트, PHP, Ruby와 같은 여러 프로그래밍 언어로 다양한 클라이언트 라이브러리 [https://cloud.google.com/bigquery/docs/reference/libraries?hl=ko]를 제공합니다. Pandas [https://pandas.pydata.org/]와 같은 일부 데이터 분석 프레임워크는 BigQuery와 직접 상호작용하는 플러그인 [https://pandas-gbq.readthedocs.io/en/latest/]을 제공합니다. 일부 실제 예시를 보려면 Jupyter 노트북에서 BigQuery 데이터 시각화 [https://cloud.google.com/bigquery/docs/visualize-jupyter?hl=ko] 튜토리얼을 참조하세요.
마지막으로 셸 환경에서 프로그램을 작성하는 것이 더 좋으면 bq 명령줄 도구 [https://cloud.google.com/bigquery/docs/bq-command-line-tool?hl=ko]를 사용할 수 있습니다.
도움이 되었나요?
의견 보내기