Source URL: https://cloud.google.com/bigquery/docs/datasets

이 페이지는 Cloud Translation API [https://cloud.google.com/translate/?hl=ko]를 통해 번역되었습니다.
Switch to English
BigQuery [https://cloud.google.com/bigquery?hl=ko]
Documentation [https://cloud.google.com/bigquery/docs?hl=ko]
가이드 [https://cloud.google.com/bigquery/docs/introduction?hl=ko]
도움이 되었나요?
의견 보내기
이 페이지의 내용
데이터 세트 제한사항 [https://cloud.google.com/bigquery/docs/datasets?hl=ko#dataset_limitations]
시작하기 전에 [https://cloud.google.com/bigquery/docs/datasets?hl=ko#before_you_begin]
필수 권한 [https://cloud.google.com/bigquery/docs/datasets?hl=ko#required_permissions]
데이터 세트 만들기 [https://cloud.google.com/bigquery/docs/datasets?hl=ko#create-dataset]
데이터 세트 이름 지정 [https://cloud.google.com/bigquery/docs/datasets?hl=ko#dataset-naming]
숨겨진 데이터 세트 [https://cloud.google.com/bigquery/docs/datasets?hl=ko#hidden_datasets]
데이터 세트 보안 [https://cloud.google.com/bigquery/docs/datasets?hl=ko#dataset_security]
다음 단계 [https://cloud.google.com/bigquery/docs/datasets?hl=ko#whats_next]
데이터 세트 만들기
bookmark_border
이 문서에서는 BigQuery에서 데이터 세트를 만드는 방법을 설명합니다.
다음 방법으로 데이터 세트를 만들 수 있습니다.
Google Cloud 콘솔 사용
SQL 쿼리 사용
bq 명령줄 도구에서 bq mk 명령어 사용
datasets.insert [https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/insert?hl=ko] API 메서드 호출
클라이언트 라이브러리 사용
기존 데이터 세트 복사
리전 간 복사를 비롯해 데이터 세트를 복사하는 단계를 알아보려면 데이터 세트 복사 [https://cloud.google.com/bigquery/docs/copying-datasets?hl=ko]를 참조하세요.
데이터 세트 복사는 현재 베타 [https://cloud.google.com/products?hl=ko#product-launch-stages] 버전입니다.
이 문서에서는 BigQuery에 데이터를 저장하는 일반 데이터 세트를 사용하는 방법을 설명합니다. Spanner 외부 데이터 세트 사용 방법을 알아보려면 Spanner 외부 데이터 세트 만들기 [https://cloud.google.com/bigquery/docs/spanner-external-datasets?hl=ko]를 참고하세요. AWS Glue 제휴 데이터 세트를 사용하는 방법을 알아보려면 AWS Glue 제휴 데이터 세트 만들기 [https://cloud.google.com/bigquery/docs/glue-federated-datasets?hl=ko]를 참고하세요.
공개 데이터 세트의 테이블을 쿼리하는 방법을 알아보려면 Google Cloud 콘솔로 공개 데이터 세트 쿼리 [https://cloud.google.com/bigquery/docs/quickstarts/query-public-dataset-console?hl=ko]를 참고하세요.
데이터 세트 제한사항
BigQuery 데이터 세트에는 다음과 같은 제한사항이 적용됩니다.
데이터 세트 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]는 생성 당시에만 설정할 수 있습니다. 데이터 세트를 만든 후에는 위치를 변경할 수 없습니다.
쿼리에서 참조하는 모든 테이블은 같은 위치의 데이터 세트에 저장해야 합니다.
외부 데이터 세트는 테이블 만료, 복제본, 시간 이동, 기본 콜레이션, 기본 반올림 모드 또는 대소문자를 구분하지 않는 테이블 이름을 사용 설정하거나 사용 중지하는 옵션을 지원하지 않습니다.
테이블을 복사 [https://cloud.google.com/bigquery/docs/managing-tables?hl=ko#copy-table]할 때 소스 테이블과 대상 테이블을 포함하는 데이터 세트는 같은 위치에 있어야 합니다.
프로젝트마다 데이터 세트 이름이 달라야 합니다.
데이터 세트의 스토리지 청구 모델 [https://cloud.google.com/bigquery/docs/datasets?hl=ko#dataset_storage_billing_models]을 변경한 경우 스토리지 청구 모델을 다시 변경할 수 있으려면 14일을 기다려야 합니다.
데이터 세트와 동일한 리전에 있는 기존 레거시 정액제 슬롯 약정 [https://cloud.google.com/bigquery/docs/reservations-commitments-legacy?hl=ko]이 있으면 물리적 스토리지 청구에 데이터 세트를 등록할 수 없습니다.
시작하기 전에
사용자에게 이 문서의 각 작업을 수행하는 데 필요한 권한을 부여하는 Identity and Access Management(IAM) 역할을 부여합니다.
필수 권한
데이터 세트를 만들려면 bigquery.datasets.create IAM 권한이 필요합니다.
다음과 같은 사전 정의된 각 IAM 역할에는 데이터 세트를 만드는 데 필요한 권한이 포함되어 있습니다.
roles/bigquery.dataEditor
roles/bigquery.dataOwner
roles/bigquery.user
roles/bigquery.admin
BigQuery에서 IAM 역할에 대한 자세한 내용은 사전 정의된 역할 및 권한 [https://cloud.google.com/bigquery/docs/access-control?hl=ko]을 참조하세요.
참고: 데이터 세트 생성자에게는 해당 데이터 세트에 대한 BigQuery 데이터 소유자(roles/bigquery.dataOwner) 역할 [https://cloud.google.com/bigquery/docs/access-control?hl=ko#bigquery.dataOwner]이 자동으로 할당됩니다. 따라서 데이터 세트를 생성할 수 있는 사용자 또는 서비스 계정은 해당 권한이 명시적으로 부여되지 않은 경우에도 이를 삭제할 수도 있습니다.
데이터 세트 만들기
데이터 세트를 만들려면 다음 안내를 따르세요.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/datasets?hl=ko#%EC%BD%98%EC%86%94] ---
Google Cloud 콘솔에서 BigQuery 페이지를 엽니다.
  BigQuery 페이지로 이동 [https://console.cloud.google.com/bigquery?hl=ko]
탐색기 패널에서 데이터 세트를 만들 프로젝트를 선택합니다.
more_vert
  작업 보기 옵션을 펼치고 데이터 세트 만들기를 클릭합니다.
  
데이터 세트 만들기 페이지에서 다음을 실행합니다.

  데이터 세트 ID에 고유한 데이터 세트 이름 [https://cloud.google.com/bigquery/docs/datasets?hl=ko#dataset-naming]을 입력합니다.
  위치 유형에서 데이터 세트의 지리적 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]를 선택합니다. 데이터 세트가 생성된 후에는 위치를 변경할 수 없습니다.
      참고: 데이터 세트 위치에 대해 EU 또는 EU 기반 리전을 선택하면 핵심 BigQuery 고객 데이터가 EU에 저장됩니다. 핵심 BigQuery 고객 데이터는 서비스별 약관 [https://cloud.google.com/terms/service-terms?hl=ko#13-google-bigquery-service]에 정의되어 있습니다.
  선택사항: 외부 데이터 세트 [https://cloud.google.com/bigquery/docs/spanner-external-datasets?hl=ko]를 만드는 경우 외부 데이터 세트에 연결을 선택합니다.
  태그 및 테이블 만료와 같은 추가 옵션을 구성할 필요가 없는 경우 데이터 세트 만들기를 클릭합니다. 그렇지 않으면 다음 섹션을 펼쳐 추가 데이터 세트 옵션을 구성합니다.



데이터 세트의 추가 옵션


선택사항: 태그 섹션을 펼쳐 데이터 세트에 태그 [https://cloud.google.com/bigquery/docs/tags?hl=ko#attach_tags_when_you_create_a_new_dataset]를 추가합니다.
기존 태그를 적용하려면 다음 단계를 따르세요.
  
    범위 선택 옆에 있는 드롭다운 화살표를 클릭하고 현재 범위(현재 조직 선택 또는 현재 프로젝트 선택)을 선택합니다.
        또는 범위 선택을 클릭하여 리소스를 검색하거나 현재 리소스 목록을 확인합니다.
      키 1 및 값 1의 경우 목록에서 적절한 값을 선택합니다.
  
새 태그를 수동으로 입력하려면 다음 단계를 따르세요.
  
    범위 선택 옆에 있는 드롭다운 화살표를 클릭하고 ID 수동 입력 > 조직, 프로젝트 또는 태그를 선택합니다.
    프로젝트 또는 조직의 태그를 만드는 경우 대화상자에서 PROJECT_ID 또는 ORGANIZATION_ID를 입력한 다음 저장을 클릭합니다.
    키 1 및 값 1의 경우 목록에서 적절한 값을 선택합니다.
    표에 태그를 추가하려면 태그 추가를 클릭하고 이전 단계를 따릅니다.
  
선택사항: 고급 옵션 섹션을 펼쳐 다음 옵션을 하나 이상 구성합니다.
  
    암호화 옵션을 변경하여 Cloud Key Management Service [https://cloud.google.com/kms/docs/key-management-service?hl=ko]로 자체 암호화 키를 사용하려면 Cloud KMS 키를 선택합니다.
    대소문자를 구분하지 않는 테이블 이름을 사용하려면 대소문자를 구분하지 않는 테이블 이름 사용 설정을 선택합니다.
    기본 콜레이션
        사양 [https://cloud.google.com/bigquery/docs/reference/standard-sql/collation-concepts?hl=ko#collate_spec_details]을 변경하려면 목록에서 콜레이션 유형을 선택합니다.
    데이터 세트의 테이블 만료를 설정하려면 테이블 만료 시간 사용 설정을 선택한 다음 기본 최대 테이블 기간을(일 단위) 지정합니다.
        참고: 프로젝트가 결제 계정과 연결되지 않은 경우 BigQuery는 사용자가 프로젝트에서 만드는 데이터 세트에 대해 기본 테이블 만료 시간을 자동으로 설정합니다. 데이터 세트에 대해 더 짧은 기본 테이블 만료 시간을 지정할 수 있지만 더 긴 기본 테이블 만료 시간은 지정할 수 없습니다.
    기본 반올림 모드 [https://cloud.google.com/bigquery/docs/reference/rest/v2/RoundingMode?hl=ko]를 설정하려면 목록에서 반올림 모드를 선택합니다.
    물리적 스토리지 청구 모델 [https://cloud.google.com/bigquery/docs/datasets-intro?hl=ko#dataset_storage_billing_models]을 사용 설정하려면 목록에서 청구 모델을 선택합니다.
    데이터 세트의 청구 모델을 변경하면 변경사항이 적용되는 데 24시간 정도 걸립니다.
    데이터 세트의 스토리지 청구 모델을 변경한 후에는 스토리지 청구 모델을 다시 변경할 수 있으려면 14일을 기다려야 합니다.
    데이터 세트의 시간 이동 기간 [https://cloud.google.com/bigquery/docs/time-travel?hl=ko#time_travel]을 설정하려면 목록에서 기간 크기를 선택합니다.
  
  데이터 세트 만들기를 클릭합니다.

--- 탭: SQL [https://cloud.google.com/bigquery/docs/datasets?hl=ko#sql] ---
CREATE SCHEMA 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#create_schema_statement]을 사용합니다.

기본 프로젝트가 아닌 다른 프로젝트에서 데이터 세트를 만들려면 해당 프로젝트 ID를 PROJECT_ID.DATASET_ID 형식으로 데이터 세트 ID에 추가합니다.






 Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.

BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko] 
쿼리 편집기에서 다음 문을 입력합니다.

CREATE SCHEMA PROJECT_ID.DATASET_ID
  OPTIONS (
    default_kms_key_name = 'KMS_KEY_NAME',
    default_partition_expiration_days = PARTITION_EXPIRATION,
    default_table_expiration_days = TABLE_EXPIRATION,
    description = 'DESCRIPTION',
    labels = [('KEY_1','VALUE_1'),('KEY_2','VALUE_2')],
    location = 'LOCATION',
    max_time_travel_hours = HOURS,
    storage_billing_model = BILLING_MODEL);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 사용자가 만들려는 데이터 세트 ID
  KMS_KEY_NAME: 이 데이터 세트에서 새로 생성된 테이블을 보호하는 데 사용되는 기본 Cloud Key Management Service 키의 이름. 생성 시 다른 키가 제공되면 그 이름을 사용합니다. 이 매개변수를 설정하여 데이터 세트에 Google 암호화 테이블을 만들 수 없습니다.
  PARTITION_EXPIRATION: 새로 생성된 파티션을 나눈 테이블의 파티션 기본 수명(일)입니다.
    기본 파티션 만료 시간에는 최솟값이 없습니다. 만료 시간은 파티션의 날짜와 정수 값을 더한 값입니다. 데이터 세트의 파티션을 나눈 테이블에서 생성된 모든 파티션은 파티션 날짜로부터 PARTITION_EXPIRATION일 후에 삭제됩니다. 파티션을 나눈 테이블을 만들거나 업데이트할 때 time_partitioning_expiration 옵션을 지정하면 테이블 수준의 파티션 만료 시간이 데이터 세트 수준의 기본 파티션 만료 시간보다 우선 적용됩니다.
  TABLE_EXPIRATION: 새로 생성된 테이블의 기본 수명(일)입니다. 최솟값은 0.042일(1시간)입니다. 만료 시간은 현재 시간과 정수 값을 더한 값으로 계산됩니다. 데이터 세트에서 생성된 모든 테이블은 생성 시간 TABLE_EXPIRATION일 후에 삭제됩니다.
    테이블을 만들 때 [https://cloud.google.com/bigquery/docs/tables?hl=ko#create-table] 테이블 만료 시간을 설정하지 않으면 이 값이 적용됩니다.
  DESCRIPTION: 데이터 세트에 대한 설명
  KEY_1:VALUE_1: 이 데이터 세트의 첫 번째 라벨로 설정하려는 키-값 쌍
  KEY_2:VALUE_2: 두 번째 라벨로 설정하려는 키-값 쌍
  LOCATION: 데이터 세트의 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]. 데이터 세트가 생성된 후에는 위치를 변경할 수 없습니다.
    참고: 데이터 세트 위치에 대해 EU 또는 EU 기반 리전을 선택하면 핵심 BigQuery 고객 데이터가 EU에 저장됩니다. 핵심 BigQuery 고객 데이터는 서비스별 약관 [https://cloud.google.com/terms/service-terms?hl=ko#13-google-bigquery-service]에 정의되어 있습니다.
  HOURS: 새 데이터 세트의 시간 이동 창의 시간 지정.
    HOURS 값은 24(48, 72, 96, 120, 144, 168)의 배수로 표현된 48(2일)에서 168(7일) 사이의 정수여야 합니다. 이 옵션을 지정하지 않으면 168시간이 기본값입니다.
    BILLING_MODEL: 데이터 세트의 스토리지 청구 모델 [https://cloud.google.com/bigquery/docs/datasets-intro?hl=ko#dataset_storage_billing_models]을 설정합니다. BILLING_MODEL 값을 PHYSICAL로 설정하여 스토리지 요금을 계산할 때 물리적 바이트를 사용하거나 LOGICAL로 설정하여 논리 바이트를 사용합니다.
 기본값은 LOGICAL입니다.
 데이터 세트의 청구 모델을 변경하면 변경사항이 적용되는 데 24시간 정도 걸립니다.

 데이터 세트의 스토리지 청구 모델을 변경한 후에는 스토리지 청구 모델을 다시 변경할 수 있으려면 14일을 기다려야 합니다.
 


play_circle 실행을 클릭합니다.




쿼리를 실행하는 방법에 대한 자세한 내용은 대화형 쿼리 실행 [https://cloud.google.com/bigquery/docs/running-queries?hl=ko#queries]을 참조하세요.

--- 탭: bq [https://cloud.google.com/bigquery/docs/datasets?hl=ko#bq] ---
새 데이터 세트를 만들려면 --location 플래그와 함께 bq mk [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#mk-dataset] 명령어를 실행합니다. 사용할 수 있는 전체 파라미터 목록은 bq mk --dataset 명령어 [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#mk-dataset] 참조를 확인하세요.

기본 프로젝트가 아닌 다른 프로젝트에서 데이터 세트를 만들려면 해당 프로젝트 ID를 PROJECT_ID:DATASET_ID 형식으로 데이터 세트 이름에 추가합니다.

bq --location=LOCATION mk \
    --dataset \
    --default_kms_key=KMS_KEY_NAME \
    --default_partition_expiration=PARTITION_EXPIRATION \
    --default_table_expiration=TABLE_EXPIRATION \
    --description="DESCRIPTION" \
    --label=KEY_1:VALUE_1 \
    --label=KEY_2:VALUE_2 \
    --add_tags=KEY_3:VALUE_3[,...] \
    --max_time_travel_hours=HOURS \
    --storage_billing_model=BILLING_MODEL \
    PROJECT_ID:DATASET_ID

다음을 바꿉니다.


LOCATION: 데이터 세트의 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko].
데이터 세트가 생성된 후에는 위치를 변경할 수 없습니다. .bigqueryrc파일 [https://cloud.google.com/bigquery/docs/bq-command-line-tool?hl=ko#setting_default_values_for_command-line_flags]을 사용하여 위치 기본값을 설정할 수 있습니다.

참고: 데이터 세트 위치로 EU를 선택할 경우 핵심 BigQuery 고객 데이터가 EU에 저장됩니다. 핵심 BigQuery 고객 데이터는 서비스별 약관 [https://cloud.google.com/terms/service-terms?hl=ko#13-google-bigquery-service]에 정의되어 있습니다.
KMS_KEY_NAME: 이 데이터 세트에서 새로 생성된 테이블을 보호하는 데 사용되는 기본 Cloud Key Management Service 키의 이름. 생성 시 다른 키가 제공되면 그 이름을 사용합니다. 이 매개변수를 설정하여 데이터 세트에 Google 암호화 테이블을 만들 수 없습니다.
PARTITION_EXPIRATION: 새로 생성된 파티션을 나눈 테이블의 파티션 기본 수명(초). 기본 파티션 만료 시간에는 최솟값이 없습니다. 만료 시간은 파티션의 날짜와 정수 값을 더한 값입니다. 데이터 세트의 파티션을 나눈 테이블에서 생성된 모든 파티션은 파티션 날짜로부터 PARTITION_EXPIRATION초 후에 삭제됩니다. 파티션을 나눈 테이블을 만들거나 업데이트할 때 --time_partitioning_expiration 플래그를 지정하면 테이블 수준의 파티션 만료 시간이 데이터 세트 수준의 기본 파티션 만료보다 우선 적용됩니다.
TABLE_EXPIRATION: 새로 생성된 테이블의 기본 수명(초). 최솟값은 3,600초(1시간)입니다. 만료 시간은 현재 시간과 정수 값을 더한 값으로 계산됩니다. 데이터 세트에서 생성된 모든 테이블은 생성 시간 TABLE_EXPIRATION초 후에 삭제됩니다. 테이블이 생성될 때 [https://cloud.google.com/bigquery/docs/tables?hl=ko#create-table] 테이블 만료 시간을 설정하지 않은 경우에 이 값이 적용됩니다.
DESCRIPTION: 데이터 세트에 대한 설명
KEY_1:VALUE_1: 이 데이터 세트의 첫 번째 라벨로 설정하려는 키-값 쌍. KEY_2:VALUE_2는 두 번째 라벨로 설정하려는 키-값 쌍입니다.
KEY_3:VALUE_3: 데이터 세트의 태그로 설정하려는 키-값 쌍입니다. 키-값 쌍 사이 쉼표를 사용하여 동일한 플래그 아래에 여러 태그를 추가합니다.
HOURS: 새 데이터 세트의 시간 이동 창의 시간 지정.
HOURS 값은 24(48, 72, 96, 120, 144, 168)의 배수로 표현된 48(2일)에서 168(7일) 사이의 정수여야 합니다. 이 옵션을 지정하지 않으면 168시간이 기본값입니다.
BILLING_MODEL: 데이터 세트의 스토리지 청구 모델 [https://cloud.google.com/bigquery/docs/datasets-intro?hl=ko#dataset_storage_billing_models]을 설정합니다. BILLING_MODEL 값을 PHYSICAL로 설정하여 스토리지 요금을 계산할 때 물리적 바이트를 사용하거나 LOGICAL로 설정하여 논리 바이트를 사용합니다.
기본값은 LOGICAL입니다.

데이터 세트의 청구 모델을 변경하면 변경사항이 적용되는 데 24시간 정도 걸립니다.

데이터 세트의 스토리지 청구 모델을 변경한 후에는 스토리지 청구 모델을 다시 변경할 수 있으려면 14일을 기다려야 합니다.
PROJECT_ID: 프로젝트 ID
DATASET_ID: 사용자가 만들려는 데이터 세트 ID


예를 들어 다음 명령어를 실행하면 데이터 위치가 US, 기본 테이블 만료 시간이 3,600초(1시간), 설명이 This is my dataset로 설정되고 이름이 mydataset인 데이터 세트가 생성됩니다. --dataset 플래그를 사용하는 대신 이 명령어는 -d 단축키를 사용합니다. -d와 --dataset를 생략할 경우 이 명령어는 기본적으로 데이터 세트를 만듭니다.

bq --location=US mk -d \
    --default_table_expiration 3600 \
    --description "This is my dataset." \
    mydataset

데이터 세트가 생성되었는지 확인하려면 bq ls 명령어를 입력합니다. 또한 bq mk -t dataset.table 형식을 사용하여 새 데이터 세트를 만들 때 테이블을 만들 수 있습니다.
테이블 만들기에 대한 자세한 내용은 테이블 만들기 [https://cloud.google.com/bigquery/docs/tables?hl=ko#create-table]를 참조하세요.

--- 탭: Terraform [https://cloud.google.com/bigquery/docs/datasets?hl=ko#terraform] ---
google_bigquery_dataset [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset] 리소스를 사용합니다.
참고: Terraform을 사용하여 BigQuery 객체를 만들려면 Cloud Resource Manager API를 사용 설정해야 합니다.
BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다. 자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.

데이터 세트 만들기

다음 예시에서는 이름이 mydataset인 데이터 세트를 만듭니다.






















  





  
    
  
  



















  




  



  


  resource "google_bigquery_dataset" "default" {
  dataset_id                      = "mydataset"
  default_partition_expiration_ms = 2592000000  # 30 days
  default_table_expiration_ms     = 31536000000 # 365 days
  description                     = "dataset description"
  location                        = "US"
  max_time_travel_hours           = 96 # 4 days

  labels = {
    billing_group = "accounting",
    pii           = "sensitive"
  }
}





























google_bigquery_dataset 리소스를 사용하여 데이터 세트를 만들면 프로젝트 수준의 기본 역할 [https://cloud.google.com/iam/docs/understanding-roles?hl=ko#basic]의 구성원인 모든 계정에 데이터 세트에 대한 액세스 권한이 자동으로 부여됩니다.
데이터 세트를 만든 후 terraform show 명령어 [https://developer.hashicorp.com/terraform/cli/commands/show]를 실행하면 데이터 세트의 access 블록 [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset#nested_access]이 다음과 유사하게 표시됩니다.

 

데이터 세트에 대한 액세스 권한을 부여하려면 google_bigquery_iam 리소스 [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset_iam] 중 하나를 사용하는 것이 좋습니다. 단, 데이터 세트 내 승인된 뷰 [https://cloud.google.com/bigquery/docs/authorized-views?hl=ko]와 같은 승인된 객체를 만들려는 경우는 예외입니다.
이 경우 google_bigquery_dataset_access 리소스 [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset_access]를 사용합니다. 예시는 해당 문서를 참조하세요.

데이터 세트 만들기 및 액세스 권한 부여

다음 예시에서는 mydataset라는 테이블을 만든 후 google_bigquery_dataset_iam_policy [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset_iam#google_bigquery_dataset_iam_policy] 리소스를 사용해서 액세스 권한을 부여합니다.
참고: 이 데이터 세트에 승인된 뷰 [https://cloud.google.com/bigquery/docs/authorized-views?hl=ko]와 같은 승인된 객체를 사용하려면 이 방법을 사용하지 마세요. 이 경우 google_bigquery_dataset_access 리소스를 사용합니다. 예를 들어 google_bigquery_dataset_access [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset_access]를 참조하세요.





















  





  
    
  
  



















  




  



  


  resource "google_bigquery_dataset" "default" {
  dataset_id                      = "mydataset"
  default_partition_expiration_ms = 2592000000  # 30 days
  default_table_expiration_ms     = 31536000000 # 365 days
  description                     = "dataset description"
  location                        = "US"
  max_time_travel_hours           = 96 # 4 days

  labels = {
    billing_group = "accounting",
    pii           = "sensitive"
  }
}

# Update the user, group, or service account
# provided by the members argument with the
# appropriate principals for your organization.
data "google_iam_policy" "default" {
  binding {
    role = "roles/bigquery.dataOwner"
    members = [
      "user:raha@altostrat.com",
    ]
  }
  binding {
    role = "roles/bigquery.admin"
    members = [
      "user:raha@altostrat.com",
    ]
  }
  binding {
    role = "roles/bigquery.user"
    members = [
      "group:analysts@altostrat.com",
    ]
  }
  binding {
    role = "roles/bigquery.dataViewer"
    members = [
      "serviceAccount:bqcx-1234567891011-abcd@gcp-sa-bigquery-condel.iam.gserviceaccount.com",
    ]
  }
}

resource "google_bigquery_dataset_iam_policy" "default" {
  dataset_id  = google_bigquery_dataset.default.dataset_id
  policy_data = data.google_iam_policy.default.policy_data
}





























고객 관리 암호화 키로 데이터 세트 만들기

다음 예시에서는 mydataset라는 데이터 세트를 만들고 google_kms_crypto_key [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/kms_crypto_key] 및 google_kms_key_ring [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/kms_key_ring] 리소스를 사용하여 데이터 세트의 Cloud Key Management Service 키를 지정합니다. 이 예시를 실행하기 전에 Cloud Key Management Service API를 사용 설정 [https://console.cloud.google.com/flows/enableapi?apiid=cloudkms.googleapis.com&%3Bredirect=https%3A%2F%2Fconsole.cloud.google.com&hl=ko]해야 합니다.






















  





  
    
  
  



















  




  



  


  resource "google_bigquery_dataset" "default" {
  dataset_id                      = "mydataset"
  default_partition_expiration_ms = 2592000000  # 30 days
  default_table_expiration_ms     = 31536000000 # 365 days
  description                     = "dataset description"
  location                        = "US"
  max_time_travel_hours           = 96 # 4 days

  default_encryption_configuration {
    kms_key_name = google_kms_crypto_key.crypto_key.id
  }

  labels = {
    billing_group = "accounting",
    pii           = "sensitive"
  }
  depends_on = [google_project_iam_member.service_account_access]
}

resource "google_kms_crypto_key" "crypto_key" {
  name     = "example-key"
  key_ring = google_kms_key_ring.key_ring.id
}

resource "random_id" "default" {
  byte_length = 8
}

resource "google_kms_key_ring" "key_ring" {
  name     = "${random_id.default.hex}-example-keyring"
  location = "us"
}

# Enable the BigQuery service account to encrypt/decrypt Cloud KMS keys
data "google_project" "project" {
}

resource "google_project_iam_member" "service_account_access" {
  project = data.google_project.project.project_id
  role    = "roles/cloudkms.cryptoKeyEncrypterDecrypter"
  member  = "serviceAccount:bq-${data.google_project.project.number}@bigquery-encryption.iam.gserviceaccount.com"
}





























프로젝트에 Terraform 구성을 적용하려면 Google Cloud 다음 섹션의 단계를 완료하세요.
Cloud Shell 준비

  Cloud Shell [https://shell.cloud.google.com/?hl=ko]을 실행합니다.
  
    Terraform 구성을 적용할 기본 Google Cloud 프로젝트를 설정합니다.
    이 명령어는 프로젝트당 한 번만 실행하면 되며 어떤 디렉터리에서도 실행할 수 있습니다.
    export GOOGLE_CLOUD_PROJECT=PROJECT_ID
    Terraform 구성 파일에서 명시적 값을 설정하면 환경 변수가 재정의됩니다.
  

디렉터리 준비
각 Terraform 구성 파일에는 자체 디렉터리(루트 모듈이라고도 함)가 있어야 합니다.

  
    Cloud Shell [https://shell.cloud.google.com/?hl=ko]에서 디렉터리를 만들고 해당 디렉터리 내에 새 파일을 만드세요. 파일 이름에는 .tf 확장자가 있어야 합니다(예: main.tf). 이 튜토리얼에서는 파일을 main.tf라고 합니다.
    mkdir DIRECTORY && cd DIRECTORY && touch main.tf
  
  
    튜토리얼을 따라 하는 경우 각 섹션이나 단계에서 샘플 코드를 복사할 수 있습니다.
    샘플 코드를 새로 만든 main.tf에 복사합니다.
    필요한 경우 GitHub에서 코드를 복사합니다. 이는 Terraform 스니펫이 엔드 투 엔드 솔루션의 일부인 경우에 권장됩니다.
    
  
  환경에 적용할 샘플 파라미터를 검토하고 수정합니다.
  변경사항을 저장합니다.
  
    Terraform을 초기화합니다. 이 작업은 디렉터리당 한 번만 수행하면 됩니다.
    terraform init
    원하는 경우 최신 Google 공급업체 버전을 사용하려면 -upgrade 옵션을 포함합니다.
    
    terraform init -upgrade
  

변경사항 적용

  
    구성을 검토하고 Terraform에서 만들거나 업데이트할 리소스가 예상과 일치하는지 확인합니다.
    terraform plan
    필요에 따라 구성을 수정합니다.
  
  
    다음 명령어를 실행하고 프롬프트에 yes를 입력하여 Terraform 구성을 적용합니다.
    terraform apply
    Terraform에 '적용 완료' 메시지가 표시될 때까지 기다립니다.
  
  결과를 보려면 Google Cloud 프로젝트 [https://console.cloud.google.com/?hl=ko]를 엽니다. Google Cloud 콘솔에서 UI의 리소스로 이동하여 Terraform이 리소스를 만들었거나 업데이트했는지 확인합니다.
  

참고: Terraform 샘플은 일반적으로 필요한 API가 Google Cloud 프로젝트에서 사용 설정되었다고 가정합니다.

--- 탭: tabpanel-api ---
데이터 세트 리소스 [https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets?hl=ko]가 정의된 datasets.insert [https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/insert?hl=ko] 메서드를 호출합니다.

--- 탭: tabpanel-c ---
이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 C# 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery C# API 참고 문서 [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  
using Google.Apis.Bigquery.v2.Data;
using Google.Cloud.BigQuery.V2 [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.html?hl=ko];

public class BigQueryCreateDataset
{
    public BigQueryDataset CreateDataset(
        string projectId = "your-project-id",
        string location = "US"
    )
    {
        BigQueryClient [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko] client = BigQueryClient [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko].Create [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko#Google_Cloud_BigQuery_V2_BigQueryClient_Create_System_String_Google_Apis_Auth_OAuth2_GoogleCredential_](projectId);
        var dataset = new Dataset
        {
            // Specify the geographic location where the dataset should reside.
            Location = location
        };
        // Create the dataset
        return client.CreateDataset [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko#Google_Cloud_BigQuery_V2_BigQueryClient_CreateDataset_Google_Apis_Bigquery_v2_Data_DatasetReference_Google_Apis_Bigquery_v2_Data_Dataset_Google_Cloud_BigQuery_V2_CreateDatasetOptions_](
            datasetId: "your_new_dataset_id", dataset);
    }
}

--- 탭: tabpanel-go ---
이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Go 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Go API 참고 문서 [https://godoc.org/cloud.google.com/go/bigquery]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  import (
	"context"
	"fmt"

	"cloud.google.com/go/bigquery"
)

// createDataset demonstrates creation of a new dataset using an explicit destination location.
func createDataset(projectID, datasetID string) error {
	// projectID := "my-project-id"
	// datasetID := "mydataset"
	ctx := context.Background()

	client, err := bigquery.NewClient(ctx, projectID)
	if err != nil {
		return fmt.Errorf("bigquery.NewClient: %v", err)
	}
	defer client.Close()

	meta := &bigquery.DatasetMetadata [https://cloud.google.com/go/docs/reference/cloud.google.com/go/bigquery/latest/index.html?hl=ko#cloud_google_com_go_bigquery_DatasetMetadata]{
		Location: "US", // See https://cloud.google.com/bigquery/docs/locations
	}
	if err := client.Dataset(datasetID).Create(ctx, meta); err != nil {
		return err
	}
	return nil
}

--- 탭: tabpanel-자바 ---
이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Java 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Java API 참고 문서 [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/overview?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  import com.google.cloud.bigquery.BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko];
import com.google.cloud.bigquery.BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko];
import com.google.cloud.bigquery.BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko];
import com.google.cloud.bigquery.Dataset [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Dataset.html?hl=ko];
import com.google.cloud.bigquery.DatasetInfo [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.DatasetInfo.html?hl=ko];

public class CreateDataset {

  public static void runCreateDataset() {
    // TODO(developer): Replace these variables before running the sample.
    String datasetName = "MY_DATASET_NAME";
    createDataset(datasetName);
  }

  public static void createDataset(String datasetName) {
    try {
      // Initialize client that will be used to send requests. This client only needs to be created
      // once, and can be reused for multiple requests.
      BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko] bigquery = BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko].getDefaultInstance().getService();

      DatasetInfo [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.DatasetInfo.html?hl=ko] datasetInfo = DatasetInfo [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.DatasetInfo.html?hl=ko].newBuilder(datasetName).build();

      Dataset [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Dataset.html?hl=ko] newDataset = bigquery.create [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko#com_google_cloud_bigquery_BigQuery_create_com_google_cloud_bigquery_DatasetInfo_com_google_cloud_bigquery_BigQuery_DatasetOption____](datasetInfo);
      String newDatasetName = newDataset.getDatasetId().getDataset();
      System.out.println(newDatasetName + " created successfully");
    } catch (BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko] e) {
      System.out.println("Dataset was not created. \n" + e.toString());
    }
  }
}

--- 탭: tabpanel-node.js ---
이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Node.js 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Node.js API 참고 문서 [https://googleapis.dev/nodejs/bigquery/latest/index.html]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  // Import the Google Cloud client library and create a client
const {BigQuery} = require('@google-cloud/bigquery [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/overview.html?hl=ko]');
const bigquery = new BigQuery [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/bigquery/bigquery.html?hl=ko]();

async function createDataset() {
  // Creates a new dataset named "my_dataset".

  /**
   * TODO(developer): Uncomment the following lines before running the sample.
   */
  // const datasetId = "my_new_dataset";

  // Specify the geographic location where the dataset should reside
  const options = {
    location: 'US',
  };

  // Create a new dataset
  const [dataset] = await bigquery.createDataset [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/bigquery/bigquery.html?hl=ko](datasetId, options);
  console.log(`Dataset ${dataset.id} created.`);
}
createDataset();

--- 탭: tabpanel-php ---
이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 PHP 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery PHP API 참고 문서 [https://cloud.google.com/php/docs/reference/cloud-bigquery/latest/BigQueryClient?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  use Google\Cloud\BigQuery\BigQueryClient;

/** Uncomment and populate these variables in your code */
// $projectId = 'The Google project ID';
// $datasetId = 'The BigQuery dataset ID';

$bigQuery = new BigQueryClient([
    'projectId' => $projectId,
]);
$dataset = $bigQuery->createDataset($datasetId);
printf('Created dataset %s' . PHP_EOL, $datasetId);

--- 탭: tabpanel-python ---
이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Python 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Python API 참고 문서 [https://cloud.google.com/python/docs/reference/bigquery/latest?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  from google.cloud import bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko]

# Construct a BigQuery client object.
client = bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko].Client [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client.html?hl=ko]()

# TODO(developer): Set dataset_id to the ID of the dataset to create.
# dataset_id = "{}.your_dataset".format(client.project)

# Construct a full Dataset object to send to the API.
dataset = bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko].Dataset [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.dataset.Dataset.html?hl=ko](dataset_id)

# TODO(developer): Specify the geographic location where the dataset should reside.
dataset.location = "US"

# Send the dataset to the API for creation, with an explicit timeout.
# Raises google.api_core.exceptions.Conflict if the Dataset already
# exists within the project.
dataset = client.create_dataset [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client.html?hl=ko#google_cloud_bigquery_client_Client_create_dataset](dataset, timeout=30)  # Make an API request.
print("Created dataset {}.{}".format(client.project, dataset.dataset_id))

--- 탭: tabpanel-ruby ---
이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Ruby 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Ruby API 참고 문서 [https://googleapis.dev/ruby/google-cloud-bigquery/latest/Google/Cloud/Bigquery.html]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  require "google/cloud/bigquery"

def create_dataset dataset_id = "my_dataset", location = "US"
  bigquery = Google::Cloud::Bigquery [https://cloud.google.com/ruby/docs/reference/google-cloud-bigquery-analytics_hub/latest/Google-Cloud-Bigquery.html?hl=ko].new [https://cloud.google.com/ruby/docs/reference/google-cloud-bigquery/latest/Google-Cloud-Bigquery.html?hl=ko]

  # Create the dataset in a specified geographic location
  bigquery.create_dataset [https://cloud.google.com/ruby/docs/reference/google-cloud-bigquery/latest/Google-Cloud-Bigquery-Project.html?hl=ko] dataset_id, location: location

  puts "Created dataset: #{dataset_id}"
end
데이터 세트 이름 지정
BigQuery에서 데이터 세트를 만들 때 데이터 세트 이름은 프로젝트마다 고유해야 합니다. 데이터 세트 이름은 다음을 포함할 수 있습니다.
최대 1,024자(영문 기준)
문자(대문자 또는 소문자), 숫자, 밑줄
기본적으로 데이터 세트 이름은 대소문자를 구분합니다. mydataset 및 MyDataset는 둘 중 하나의 대소문자 구분이 사용 중지되지 않는 한 동일한 프로젝트에 공존할 수 있습니다. 예를 보려면 대소문자 구분이 없는 데이터 세트 만들기 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#creating_a_case-insensitive_dataset] 및 리소스: 데이터 세트 [https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets?hl=ko#resource:-dataset]를 참고하세요.
데이터 세트 이름에는 -, &, @, %와 같은 공백이나 특수문자를 사용할 수 없습니다.
숨겨진 데이터 세트
숨겨진 데이터 세트는 이름이 밑줄로 시작하는 데이터 세트입니다. 다른 데이터 세트와 마찬가지로 숨겨진 데이터 세트의 테이블과 뷰를 쿼리할 수 있습니다. 숨겨진 데이터 세트에는 다음과 같은 제한사항이 있습니다.
Google Cloud 콘솔의 탐색기 패널에는 숨겨져 있습니다.
INFORMATION_SCHEMA 뷰에는 표시되지 않습니다.
연결된 데이터 세트 [https://cloud.google.com/bigquery/docs/analytics-hub-introduction?hl=ko#linked_datasets]와 함께 사용할 수 없습니다.
다음 승인된 리소스와 함께 소스 데이터 세트로 사용할 수 없습니다.
승인된 데이터 세트 [https://cloud.google.com/bigquery/docs/authorized-datasets?hl=ko]
승인된 루틴 [https://cloud.google.com/bigquery/docs/authorized-routines?hl=ko]
승인된 뷰 [https://cloud.google.com/bigquery/docs/authorized-views?hl=ko]
Data Catalog (지원 중단됨) 또는 Dataplex 범용 카탈로그에는 표시되지 않습니다.
데이터 세트 보안
BigQuery에서 데이터 세트에 대한 액세스를 제어하려면 데이터 세트에 대한 액세스 제어 [https://cloud.google.com/bigquery/docs/control-access-to-resources-iam?hl=ko]를 참조하세요. 데이터 암호화에 대한 자세한 내용은 저장 데이터 암호화 [https://cloud.google.com/bigquery/docs/encryption-at-rest?hl=ko]를 참조하세요.
다음 단계
프로젝트의 데이터 세트 나열에 대한 자세한 내용은 데이터 세트 나열 [https://cloud.google.com/bigquery/docs/listing-datasets?hl=ko]을 참조하세요.
데이터 세트 메타데이터에 대한 자세한 내용은 데이터 세트 정보 가져오기 [https://cloud.google.com/bigquery/docs/dataset-metadata?hl=ko]를 참조하세요.
데이터 세트 속성 변경에 대한 자세한 내용은 데이터 세트 업데이트 [https://cloud.google.com/bigquery/docs/updating-datasets?hl=ko]를 참조하세요.
라벨 만들기 및 관리에 대한 자세한 내용은 라벨 만들기 및 관리 [https://cloud.google.com/bigquery/docs/labels?hl=ko]를 참조하세요.
직접 사용해 보기
Google Cloud를 처음 사용하는 경우 계정을 만들어 실제 시나리오에서 BigQuery의 성능을 평가할 수 있습니다. 신규 고객에게는 워크로드를 실행, 테스트, 배포하는 데 사용할 수 있는 $300의 무료 크레딧이 제공됩니다.
BigQuery 무료로 사용해 보기 [https://console.cloud.google.com/freetrial?hl=ko]
도움이 되었나요?
의견 보내기