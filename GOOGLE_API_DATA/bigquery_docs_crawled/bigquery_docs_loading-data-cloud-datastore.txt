Source URL: https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore

BigQuery [https://cloud.google.com/bigquery?hl=ko]
Documentation [https://cloud.google.com/bigquery/docs?hl=ko]
가이드 [https://cloud.google.com/bigquery/docs/introduction?hl=ko]
도움이 되었나요?
의견 보내기
이 페이지의 내용
제한사항 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#limitations]
시작하기 전에 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#before_you_begin]
필수 권한 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#required_permissions]
Cloud Storage에서 데이터를 로드할 수 있는 권한 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#permissions-load-data-from-cloud-storage]
Datastore 내보내기 서비스 데이터 로드 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#loading_cloud_datastore_export_service_data]
Datastore 데이터로 테이블 추가 또는 덮어쓰기 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#appending_to_or_overwriting_a_table_with_cloud_datastore_data]
Datastore 옵션 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#cloud_datastore_options]
데이터 유형 변환 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#data_type_conversion]
Datastore 내보내기에서 데이터로드
bookmark_border
BigQuery는 Datastore 관리형 가져오기 및 내보내기 서비스를 사용하여 만든 Datastore [https://cloud.google.com/datastore?hl=ko] 내보내기에서 데이터를 로드하는 기능을 지원합니다. 관리형 가져오기 및 내보내기 서비스를 사용하여 Datastore 항목을 Cloud Storage 버킷으로 내보낼 수 있습니다. 그런 다음 내보내기를 BigQuery에 테이블로 로드할 수 있습니다.
Datastore 내보내기 파일을 만드는 방법은 Datastore 문서에서 항목 내보내기 및 가져오기 [https://cloud.google.com/datastore/docs/export-import-entities?hl=ko]를 참조하세요. 내보내기 예약에 대한 자세한 내용은 내보내기 예약 [https://cloud.google.com/datastore/docs/schedule-export?hl=ko]을 참조하세요.
참고: Datastore 내보내기를 BigQuery에 로드하려면 내보내기 명령어 [https://cloud.google.com/datastore/docs/export-import-entities?hl=ko#exporting_entities]에 항목 필터를 지정해야 합니다. 항목 필터를 지정하지 않고 내보낸 데이터는 BigQuery에 로드할 수 없습니다.
API에서 projectionFields 속성 [https://cloud.google.com/bigquery/docs/reference/rest/v2/Job?hl=ko#JobConfigurationLoad.FIELDS.projection_fields]을 설정하거나 bq 명령줄 도구에서 --projection_fields 플래그를 사용하여 BigQuery에서 로드할 속성을 제어할 수 있습니다.
로드 프로세스를 건너뛰려면 내보내기를 외부 데이터 소스로 설정하여 직접 쿼리합니다. 자세한 내용은 외부 데이터 소스 [https://cloud.google.com/bigquery/external-data-sources?hl=ko]를 참조하세요.
Cloud Storage에서 BigQuery 테이블로 데이터를 로드하는 경우 테이블을 포함하고 있는 데이터 세트는 Cloud Storage 버킷과 같은 리전이나 멀티 리전에 있어야 합니다.
제한사항
Datastore 내보내기에서 BigQuery로 데이터를 로드할 때는 다음 제한사항에 유의하세요.
Datastore 내보내기 파일을 지정할 때 Cloud Storage URI에 와일드 카드를 사용할 수 없습니다.
Datastore 내보내기에서 데이터를 로드할 때 Cloud Storage URI를 하나만 지정할 수 있습니다.
Datastore 내보내기 데이터를 정의된 스키마가 있는 기존 테이블에 추가할 수 없습니다.
Datastore 내보내기를 올바르게 로드하려면 내보내기 데이터의 항목이 고유한 속성 이름이 10,000개 미만인 일관된 스키마를 공유해야 합니다.
항목 필터를 지정하지 않고 내보낸 데이터는 BigQuery에 로드할 수 없습니다. 내보내기 요청의 항목 필터에는 종류 이름이 한 개 이상 포함되어야 합니다.
Datastore 내보내기의 최대 필드 크기는 64KB입니다. Datastore 내보내기를 로드할 때 64KB보다 큰 필드는 모두 잘립니다.
시작하기 전에
사용자에게 이 문서의 각 작업을 수행하는 데 필요한 권한을 부여하는 Identity and Access Management(IAM) 역할을 부여합니다.
필수 권한
데이터를 BigQuery로 로드하려면 로드 작업을 실행하고 데이터를 BigQuery 테이블과 파티션으로 로드할 수 있는 IAM 권한이 필요합니다. Cloud Storage에서 데이터를 로드할 경우 데이터가 포함된 버킷에 액세스할 수 있는 IAM 권한도 필요합니다.
데이터를 BigQuery로 로드할 수 있는 권한
데이터를 새 BigQuery 테이블이나 파티션으로 로드하거나 기존 테이블 또는 파티션을 추가하거나 덮어쓰려면 다음 IAM 권한이 필요합니다.
bigquery.tables.create
bigquery.tables.updateData
bigquery.tables.update
bigquery.jobs.create
다음과 같이 사전 정의된 각 IAM 역할에는 데이터를 BigQuery 테이블이나 파티션에 로드하기 위해 필요한 권한이 포함되어 있습니다.
roles/bigquery.dataEditor
roles/bigquery.dataOwner
roles/bigquery.admin(bigquery.jobs.create 권한 포함)
bigquery.user(bigquery.jobs.create 권한 포함)
bigquery.jobUser(bigquery.jobs.create 권한 포함)
또한 bigquery.datasets.create 권한이 있으면 만들 데이터 세트에서 로드 작업을 사용하여 테이블을 만들고 업데이트할 수 있습니다.
BigQuery의 IAM 역할과 권한에 대한 자세한 내용은 사전 정의된 역할 및 권한 [https://cloud.google.com/bigquery/access-control?hl=ko]을 참조하세요.
Cloud Storage에서 데이터를 로드할 수 있는 권한
Cloud Storage 버킷에서 데이터를 로드하는 데 필요한 권한을 얻으려면 관리자에게 버킷의 스토리지 관리자 [https://cloud.google.com/iam/docs/roles-permissions/storage?hl=ko#storage.admin](roles/storage.admin) IAM 역할을 부여해 달라고 요청하세요. 역할 부여에 대한 자세한 내용은 프로젝트, 폴더, 조직에 대한 액세스 관리 [https://cloud.google.com/iam/docs/granting-changing-revoking-access?hl=ko]를 참조하세요.
이 사전 정의된 역할에는 Cloud Storage 버킷에서 데이터를 로드하는 데 필요한 권한이 포함되어 있습니다. 필요한 정확한 권한을 보려면 필수 권한 섹션을 펼치세요.
필수 권한
커스텀 역할 [https://cloud.google.com/iam/docs/creating-custom-roles?hl=ko]이나 다른 사전 정의된 역할 [https://cloud.google.com/iam/docs/roles-overview?hl=ko#predefined]을 사용하여 이 권한을 부여받을 수도 있습니다.
Datastore 내보내기 서비스 데이터 로드
Datastore 내보내기 메타데이터 파일에서 데이터를 로드하려면 다음 안내를 따르세요.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#%EC%BD%98%EC%86%94] ---
Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.
    BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko]

탐색기 창에서 프로젝트를 펼친 후 데이터 세트를 선택합니다.
데이터 세트 정보 섹션에서 add_box 테이블 만들기를 클릭합니다.
 테이블 만들기 패널에서 다음 세부정보를 지정합니다. 


  



소스 섹션의 다음 항목으로 테이블 만들기 목록에서 Google Cloud Storage를 선택합니다.
  그런 후 다음 작업을 수행합니다.
  
    Cloud Storage 버킷에서 파일을 선택하거나 Cloud Storage URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri]를 입력합니다.
              Google Cloud 콘솔에는 URI 여러 개가 포함될 수 없지만 와일드 카드 [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#load-wildcards]는 지원됩니다. Cloud Storage 버킷은 생성, 추가 또는 덮어쓰려는 테이블이 포함된 데이터 세트와 동일한 위치에 있어야 합니다.
       Datastore 내보내기 파일의 URI는 KIND_NAME.export_metadata 또는 export[NUM].export_metadata로 끝나야 합니다.
      예를 들어 default_namespace_kind_Book.export_metadata에서 Book은 종류 이름이고 default_namespace_kind_Book은 Datastore에서 생성된 파일 이름입니다.
      

      





    파일 형식으로 Cloud Datastore 백업을 선택합니다.
      
  

    





대상 섹션에서 다음 세부정보를 지정합니다.데이터 세트에서 테이블을 만들 데이터 세트를 선택합니다.
  테이블 필드에 만들려는 테이블의 이름을 입력합니다.
  테이블 유형 필드가 기본 테이블로 설정되어 있는지 확인합니다.
  




    스키마 섹션은 그대로 놔둡니다. 스키마는 Datastore 내보내기에 대해 유추됩니다.




  
  



  
  (선택사항) 파티션 및 클러스터 설정을 지정합니다. 자세한 내용은 파티션을 나눈 테이블 만들기 [https://cloud.google.com/bigquery/docs/creating-partitioned-tables?hl=ko] 및 클러스터링된 테이블 만들기 및 사용 [https://cloud.google.com/bigquery/docs/creating-clustered-tables?hl=ko]을 참조하세요.
    
  



   




고급 옵션을 클릭하고 다음을 수행합니다.





  
  쓰기 환경설정에서 비어 있으면 쓰기를 선택한 상태로 둡니다. 이 옵션은 새 테이블을 만들어 데이터를 로드합니다.
  

  

  테이블 스키마에 없는 행의 값을 무시하려면 알 수 없는 값을 선택합니다.

  
  Cloud Key Management Service 키 [https://cloud.google.com/bigquery/docs/customer-managed-encryption?hl=ko]를 사용하려면 암호화에서 고객 관리 키를 클릭합니다.
        Google-managed key 설정을 그대로 두면 BigQuery에서 저장 데이터를 암호화 [https://cloud.google.com/security/encryption/default-encryption?hl=ko]합니다.

  사용 가능한 옵션에 대한 자세한 내용은 Datastore 옵션 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#cloud_datastore_options]을 참조하세요.
  
  



테이블 만들기를 클릭합니다.

--- 탭: bq [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#bq] ---
source_format이 DATASTORE_BACKUP으로 설정된 bq load 명령어를 사용합니다.
--location 플래그를 지정하고 값을 사용자 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]로 설정합니다.
bq --location=LOCATION load \
--source_format=FORMAT \
DATASET.TABLE \
PATH_TO_SOURCE

다음을 바꿉니다.


LOCATION: 사용자 위치입니다. --location 플래그는 선택사항입니다. 예를 들어 도쿄 리전에서 BigQuery를 사용한다면 플래그 값을 asia-northeast1로 설정할 수 있습니다. .bigqueryrc 파일 [https://cloud.google.com/bigquery/docs/bq-command-line-tool?hl=ko#setting_default_values_for_command-line_flags]을 사용하여 위치 기본값을 설정할 수 있습니다.
FORMAT: DATASTORE_BACKUP.
DATASET: 데이터를 로드할 테이블이 포함된 데이터 세트입니다.
TABLE: 데이터를 로드할 대상 테이블입니다.
테이블이 없는 경우에는 만들어집니다.
PATH_TO_SOURCE: Cloud Storage URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri]입니다.


예를 들어 다음 명령어는 Datastore 내보내기 파일 gs://mybucket/20180228T1256/default_namespace/kind_Book/default_namespace_kind_Book.export_metadata를 book_data라는 테이블로 로드합니다.
mybucket과 mydataset는 US 멀티 리전 위치에서 생성되었습니다.
bq --location=US load \
--source_format=DATASTORE_BACKUP \
mydataset.book_data \
gs://mybucket/20180228T1256/default_namespace/kind_Book/default_namespace_kind_Book.export_metadata

--- 탭: API [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#api] ---
API [https://cloud.google.com/bigquery/docs/reference/v2?hl=ko]를 사용하여 Datastore 내보내기 데이터를 로드하려면 다음 속성을 설정합니다.


Cloud Storage의 소스 데이터를 가리키는 로드 작업 [https://cloud.google.com/bigquery/docs/reference/rest/v2/Job?hl=ko#jobconfigurationload]을 만듭니다.
작업 리소스 [https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs?hl=ko]의 jobReference 섹션에 있는 location 속성에 사용자 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]를 지정합니다.
소스 URI [https://cloud.google.com/bigquery/docs/reference/rest/v2/Job?hl=ko#JobConfigurationLoad.FIELDS.source_uris]는 gs://[BUCKET]/[OBJECT] 형식으로 정규화되어야 합니다. 파일(객체) 이름은 [KIND_NAME].export_metadata로 끝나야 합니다. Datastore 내보내기에는 URI 한 개만 허용되며, 와일드 카드를 사용할 수 없습니다.
JobConfigurationLoad.sourceFormat 속성 [https://cloud.google.com/bigquery/docs/reference/rest/v2/Job?hl=ko#JobConfigurationLoad.FIELDS.source_format]을 DATASTORE_BACKUP으로 설정하여 데이터 형식을 지정합니다.
Datastore 데이터로 테이블 추가 또는 덮어쓰기
Datastore 내보내기 데이터를 BigQuery로 로드할 때 데이터를 저장할 새 테이블을 만들거나 기존 테이블을 덮어쓸 수 있습니다. Datastore 내보내기 데이터를 기존 테이블에 추가할 수는 없습니다.
Datastore 내보내기 데이터를 기존 테이블에 추가하려고 하면 Cannot append a datastore backup to a table that already has a schema. Try using the WRITE_TRUNCATE write disposition to replace the existing table 오류가 발생합니다.
기존 테이블을 Datastore 내보내기 데이터로 덮어쓰려면 다음 안내를 따르세요.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#%EC%BD%98%EC%86%94] ---
Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.
    BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko]

탐색기 창에서 프로젝트를 펼친 후 데이터 세트를 선택합니다.
데이터 세트 정보 섹션에서 add_box 테이블 만들기를 클릭합니다.
 테이블 만들기 패널에서 다음 세부정보를 지정합니다. 


  



소스 섹션의 다음 항목으로 테이블 만들기 목록에서 Google Cloud Storage를 선택합니다.
  그런 후 다음 작업을 수행합니다.
  
    Cloud Storage 버킷에서 파일을 선택하거나 Cloud Storage URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri]를 입력합니다.
              Google Cloud 콘솔에는 URI 여러 개가 포함될 수 없지만 와일드 카드 [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#load-wildcards]는 지원됩니다. Cloud Storage 버킷은 생성, 추가 또는 덮어쓰려는 테이블이 포함된 데이터 세트와 동일한 위치에 있어야 합니다.
       Datastore 내보내기 파일의 URI는 KIND_NAME.export_metadata 또는 export[NUM].export_metadata로 끝나야 합니다.
      예를 들어 default_namespace_kind_Book.export_metadata에서 Book은 종류 이름이고 default_namespace_kind_Book은 Datastore에서 생성된 파일 이름입니다.
      

      





    파일 형식으로 Cloud Datastore 백업을 선택합니다.
      
  

    
    참고: 테이블을 추가하거나 덮어쓸 때 해당 테이블 스키마를 수정할 수 있습니다. 로드 작업 시 지원되는 스키마 변경에 대한 자세한 내용은 테이블 스키마 수정 [https://cloud.google.com/bigquery/docs/managing-table-schemas?hl=ko]을 참조하세요.
  
  





대상 섹션에서 다음 세부정보를 지정합니다.데이터 세트에서 테이블을 만들 데이터 세트를 선택합니다.
  테이블 필드에 만들려는 테이블의 이름을 입력합니다.
  테이블 유형 필드가 기본 테이블로 설정되어 있는지 확인합니다.
  




    스키마 섹션은 그대로 놔둡니다. 스키마는 Datastore 내보내기에 대해 유추됩니다.




  
   참고: 테이블을 추가하거나 덮어쓸 때 해당 테이블 스키마를 수정할 수 있습니다. 로드 작업 시 지원되는 스키마 변경에 대한 자세한 내용은 테이블 스키마 수정 [https://cloud.google.com/bigquery/docs/managing-table-schemas?hl=ko]을 참조하세요.
     
  
  



  
  (선택사항) 파티션 및 클러스터 설정을 지정합니다. 자세한 내용은 파티션을 나눈 테이블 만들기 [https://cloud.google.com/bigquery/docs/creating-partitioned-tables?hl=ko] 및 클러스터링된 테이블 만들기 및 사용 [https://cloud.google.com/bigquery/docs/creating-clustered-tables?hl=ko]을 참조하세요.
     추가하거나 덮어쓰는 방법으로 파티션을 나눈 테이블 또는 클러스터링된 테이블로 변환할 수 없습니다. Google Cloud 콘솔은 로드 작업에서 파티션을 나눈 테이블 또는 클러스터링된 테이블 추가 또는 덮어쓰기를 지원하지 않습니다. 
  



   




고급 옵션을 클릭하고 다음을 수행합니다.





  
  쓰기 환경설정에서 테이블에 추가 또는 테이블 덮어쓰기를 선택합니다.
  

  

  테이블 스키마에 없는 행의 값을 무시하려면 알 수 없는 값을 선택합니다.

  
  Cloud Key Management Service 키 [https://cloud.google.com/bigquery/docs/customer-managed-encryption?hl=ko]를 사용하려면 암호화에서 고객 관리 키를 클릭합니다.
        Google-managed key 설정을 그대로 두면 BigQuery에서 저장 데이터를 암호화 [https://cloud.google.com/security/encryption/default-encryption?hl=ko]합니다.

  사용 가능한 옵션에 대한 자세한 내용은 Datastore 옵션 [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#cloud_datastore_options]을 참조하세요.
  
  



테이블 만들기를 클릭합니다.

--- 탭: bq [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#bq] ---
--replace 플래그가 지정되고 source_format이 DATASTORE_BACKUP으로 설정된 bq load 명령어를 사용합니다. --location 플래그를 지정하고 값을 사용자 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]로 설정합니다.
bq --location=LOCATION load \
--source_format=FORMAT \
--replace \
DATASET.TABLE \
PATH_TO_SOURCE

다음을 바꿉니다.


LOCATION: 사용자 위치입니다. --location 플래그는 선택사항입니다. 예를 들어 도쿄 리전에서 BigQuery를 사용한다면 플래그 값을 asia-northeast1로 설정할 수 있습니다. .bigqueryrc 파일 [https://cloud.google.com/bigquery/docs/bq-command-line-tool?hl=ko#setting_default_values_for_command-line_flags]을 사용하여 위치 기본값을 설정할 수 있습니다.
FORMAT: DATASTORE_BACKUP.
DATASET: 데이터를 로드할 테이블이 포함된 데이터 세트입니다.
TABLE: 덮어쓰려는 테이블입니다.
PATH_TO_SOURCE: Cloud Storage URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri]입니다.


예를 들어 다음 명령어는 Datastore 내보내기 파일 gs://mybucket/20180228T1256/default_namespace/kind_Book/default_namespace_kind_Book.export_metadata를 로드하여 book_data라는 테이블을 덮어씁니다.
bq load --source_format=DATASTORE_BACKUP \
--replace \
mydataset.book_data \
gs://mybucket/20180228T1256/default_namespace/kind_Book/default_namespace_kind_Book.export_metadata

--- 탭: API [https://cloud.google.com/bigquery/docs/loading-data-cloud-datastore?hl=ko#api] ---
API [https://cloud.google.com/bigquery/docs/reference/v2?hl=ko]에서 데이터를 로드하려면 속성을 다음과 같이 설정합니다.


Cloud Storage의 소스 데이터를 가리키는 로드 작업 [https://cloud.google.com/bigquery/docs/reference/rest/v2/Job?hl=ko#jobconfigurationload]을 만듭니다.
작업 리소스 [https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs?hl=ko]의 jobReference 섹션에 있는 location 속성에 사용자 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]를 지정합니다.
소스 URI [https://cloud.google.com/bigquery/docs/reference/rest/v2/Job?hl=ko#JobConfigurationLoad.FIELDS.source_uris]는 gs://[BUCKET]/[OBJECT] 형식으로 정규화되어야 합니다. 파일(객체) 이름은 [KIND_NAME].export_metadata로 끝나야 합니다. Datastore 내보내기에는 URI 한 개만 허용되며, 와일드 카드를 사용할 수 없습니다.
JobConfigurationLoad.sourceFormat 속성 [https://cloud.google.com/bigquery/docs/reference/rest/v2/Job?hl=ko#JobConfigurationLoad.FIELDS.source_format]을 DATASTORE_BACKUP으로 설정하여 데이터 형식을 지정합니다.
JobConfigurationLoad.writeDisposition 속성 [https://cloud.google.com/bigquery/docs/reference/rest/v2/Job?hl=ko#JobConfigurationLoad.FIELDS.write_disposition]을 WRITE_TRUNCATE로 설정하여 쓰기 방식을 지정합니다.
Datastore 옵션
BigQuery가 Datastore 내보내기 데이터를 파싱하는 방법을 변경하려면 다음 옵션을 지정합니다.
Console 옵션 bq 도구 플래그 BigQuery API 속성 설명
사용 불가 --projection_fields projectionFields [https://cloud.google.com/bigquery/docs/reference/rest/v2/Job?hl=ko#JobConfigurationLoad.FIELDS.projection_fields] Datastore 내보내기에서 BigQuery로 로드할 항목 속성을 나타내는 쉼표로 구분된 목록입니다. 속성 이름은 대소문자를 구분하며 최상위 수준 속성이어야 합니다. 속성을 지정하지 않으면 BigQuery가 모든 속성을 로드합니다. Datastore 내보내기에서 지정된 속성을 찾을 수 없으면 작업 결과에 잘못된 오류가 반환됩니다. 기본값은 ''입니다.
데이터 유형 변환
BigQuery는 Datastore 내보내기 파일에 있는 각 항목의 데이터를 BigQuery 데이터 유형 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko]으로 변환합니다. 다음 표에서는 데이터 유형 간의 변환을 설명합니다.
Datastore 데이터 유형 BigQuery 데이터 유형
배열 ARRAY
Blob BYTES
Boolean BOOLEAN
날짜 및 시간 TIMESTAMP
내장 항목 RECORD
부동 소수점 수 FLOAT
지리적 지점
RECORD
[{"lat","DOUBLE"},
 {"long","DOUBLE"}]
        
정수 INTEGER
키 RECORD
Null STRING
텍스트 문자열 STRING(64KB로 자름)
Datastore 키 속성
Datastore의 각 항목에는 네임스페이스, 경로와 같은 정보가 포함된 고유한 키가 있습니다. BigQuery는 다음 표와 같이 각 정보의 중첩된 필드와 함께 키의 RECORD 데이터 유형을 만듭니다.
키 속성 설명 BigQuery 데이터 유형
__key__.app Datastore 앱 이름입니다. STRING
__key__.id 항목의 ID이거나 __key__.name이 설정된 경우에는 null입니다. 정수
__key__.kind 항목의 종류입니다. STRING
__key__.name 항목의 이름이거나 __key__.id가 설정된 경우에는 null입니다. STRING
__key__.namespace Datastore 앱에서 커스텀 네임스페이스를 사용하는 경우 항목의 네임스페이스입니다. 그렇지 않으면 기본 네임스페이스가 빈 문자열로 표시됩니다. STRING
__key__.path 평면화된 항목의 상위 경로 [https://cloud.google.com/appengine/docs/java/datastore/entities?hl=ko#Java_Ancestor_paths]이며, 루트 항목에서 항목 자체까지의 일련의 종류 식별자 쌍으로 구성됩니다. 예를 들면 "Country", "USA", "PostalCode", 10011, "Route", 1234입니다. STRING
도움이 되었나요?
의견 보내기