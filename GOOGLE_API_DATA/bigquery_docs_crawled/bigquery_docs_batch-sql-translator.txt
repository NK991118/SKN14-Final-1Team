Source URL: https://cloud.google.com/bigquery/docs/batch-sql-translator

BigQuery [https://cloud.google.com/bigquery?hl=ko]
Documentation [https://cloud.google.com/bigquery/docs?hl=ko]
가이드 [https://cloud.google.com/bigquery/docs/introduction?hl=ko]
도움이 되었나요?
의견 보내기
이 페이지의 내용
시작하기 전에 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#before_you_begin]
필수 권한 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#required_permissions]
BigQuery Migration API 사용 설정 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#enable_the]
소스 파일 수집 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#collect_source_files]
메타데이터 파일 만들기 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#create_metadata_files]
일괄 SQL 변환기를 사용하여 코드 마이그레이션
bookmark_border
참고: 새 일괄 변환을 포함한 API 기반 변환의 경우 BigQuery Migration API [https://cloud.google.com/bigquery/docs/api-sql-translator?hl=ko]를 사용하여 SQL 스크립트를 변환하는 것이 좋습니다. BigQuery Migration API는 일괄 SQL 변환기와 매우 유사하게 작동하지만 클라이언트 코드를 설치하거나 사용할 필요가 없습니다.
이 문서에서는 BigQuery의 일괄 SQL 변환기를 사용하여 다른 SQL 언어로 작성된 스크립트를 GoogleSQL 쿼리로 변환하는 방법을 설명합니다. 이 문서는 Google Cloud 콘솔 [https://cloud.google.com/bigquery/docs/bigquery-web-ui?hl=ko]에 익숙한 사용자를 대상으로 작성되었습니다.
시작하기 전에
변환 작업을 제출하기 전에 다음 단계를 완료하세요.
필요한 모든 권한이 있는지 확인합니다.
BigQuery Migration API를 사용 설정합니다.
변환할 SQL 스크립트와 쿼리가 포함된 소스 파일을 수집합니다.
선택사항. 메타데이터 파일을 만들어 변환의 정확도를 높입니다.
선택사항. 소스 파일의 SQL 객체 이름을 BigQuery의 새 이름으로 매핑해야 하는지 결정합니다. 필요한 경우 사용할 이름 매핑 규칙을 결정합니다.
변환 작업을 제출하는 데 사용할 메서드를 결정합니다.
Cloud Storage에 소스 파일 업로드
필수 권한
BigQuery Migration Service를 사용 설정하려면 프로젝트에 대해 다음 권한이 있어야 합니다.
resourcemanager.projects.get
serviceusage.services.enable
serviceusage.services.get
BigQuery Migration Service를 액세스하고 사용하려면 프로젝트에 대해 다음 권한이 필요합니다.
bigquerymigration.workflows.create
bigquerymigration.workflows.get
bigquerymigration.workflows.list
bigquerymigration.workflows.delete
bigquerymigration.subtasks.get
bigquerymigration.subtasks.list
또는 다음 역할을 사용하여 동일한 권한을 얻을 수 있습니다.
bigquerymigration.viewer - 읽기 전용 액세스
bigquerymigration.editor - 읽기/쓰기 액세스
입력 및 출력 파일에 대해 Cloud Storage 버킷에 액세스하려면 다음 권한이 있어야 합니다.
소스 Cloud Storage 버킷에서 storage.objects.get
소스 Cloud Storage 버킷에서 storage.objects.list
대상 Cloud Storage 버킷에서 storage.objects.create
다음 역할에서 위에 표시된 모든 필요한 Cloud Storage 권한을 지정할 수 있습니다.
roles/storage.objectAdmin
roles/storage.admin
BigQuery Migration API 사용 설정
Google Cloud CLI 프로젝트가 2022년 2월 15일 이전에 생성된 경우 다음과 같이 BigQuery Migration API를 사용 설정합니다.
Google Cloud 콘솔에서 BigQuery Migration API 페이지로 이동합니다.
BigQuery Migration API로 이동 [https://console.cloud.google.com/apis/api/bigquerymigration.googleapis.com/overview?hl=ko]
사용 설정을 클릭합니다.
참고: 2022년 2월 15일 이후에 생성된 프로젝트에는 이 API가 자동으로 사용 설정됩니다.
소스 파일 수집
소스 파일은 소스 언어에 유효한 SQL이 포함된 텍스트 파일이어야 합니다. 소스 파일에는 주석이 포함될 수도 있습니다. 사용 가능한 모든 방법을 사용하여 SQL이 유효한지 확인합니다.
메타데이터 파일 만들기
서비스에서 보다 정확한 변환 결과를 생성할 수 있도록 메타데이터 파일을 제공하는 것이 좋습니다. 그러나 필수는 아닙니다.
dwh-migration-dumper 명령줄 추출 도구를 사용하여 메타데이터 정보를 생성하거나 사용자의 자체 메타데이터 파일을 제공하면 됩니다. 메타데이터 파일이 준비되면 변환 소스 폴더에 소스 파일과 함께 포함할 수 있습니다. 변환기는 자동으로 메타데이터를 감지하고 소스 파일을 변환하는 데 활용하므로 이를 사용 설정하기 위해 추가 설정을 구성할 필요가 없습니다.
dwh-migration-dumper 도구를 사용하여 메타데이터 정보를 생성하려면 변환용 메타데이터 생성 [https://cloud.google.com/bigquery/docs/generate-metadata?hl=ko]을 참조하세요.
자체 메타데이터를 제공하려면 소스 시스템의 SQL 객체에 대한 데이터 정의 언어(DDL) 문을 별도의 텍스트 파일로 수집합니다.
변환 작업 제출 방법 결정
일괄 변환 작업을 제출하는 방법은 3가지입니다.
일괄 변환 클라이언트: 구성 파일에서 설정을 변경하여 작업을 구성하고 명령줄을 사용하여 작업을 제출합니다. 이 방식에서는 소스 파일을 수동으로 Cloud Storage에 업로드할 필요가 없습니다. 클라이언트는 변환 작업을 처리하는 동안 여전히 Cloud Storage를 사용하여 파일을 저장합니다.
기존의 일괄 변환 클라이언트는 오픈소스 Python 클라이언트이며 이를 사용하면 로컬 머신에 있는 소스 파일을 변환하고 변환된 파일을 로컬 디렉터리로 출력할 수 있습니다. 구성 파일에서 몇 가지 설정을 변경하여 클라이언트를 기본 용도로 구성합니다. 원하는 경우 클라이언트에서 매크로 대체, 변환 입력과 출력의 사전 및 사후 처리와 같은 더욱 복잡한 태스크를 처리하도록 구성할 수도 있습니다. 자세한 내용은 일괄 변환 클라이언트 리드미 [https://github.com/google/dwh-migration-tools/blob/main/client/README.md]를 참조하세요.
Google Cloud 콘솔: 사용자 인터페이스를 사용하여 작업을 구성하고 제출합니다. 이 방식을 사용하려면 소스 파일을 Cloud Storage에 업로드해야 합니다.
구성 YAML 파일 만들기
선택적으로 구성 YAML 파일 [https://cloud.google.com/bigquery/docs/config-yaml-translation?hl=ko] 구성을 만들고 사용해서 일괄 변환을 맞춤설정할 수 있습니다. 이러한 파일은 여러 방식으로 변환 출력을 변환하는 데 사용할 수 있습니다. 예를 들어 변환 중 SQL 객체의 대소문자를 변경하도록 구성 YAML 파일을 만들 [https://cloud.google.com/bigquery/docs/config-yaml-translation?hl=ko#change_object-name_case] 수 있습니다.
일괄 변환 작업에 Google Cloud 콘솔 또는 BigQuery Migration API를 사용하려면 소스 파일이 포함된 Cloud Storage 버킷에 구성 YAML 파일을 업로드 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#upload-files]하면 됩니다.
일괄 변환 클라이언트를 사용하려면 구성 YAML 파일을 로컬 번역 입력 폴더에 배치하면 됩니다.
Cloud Storage에 입력 파일 업로드
콘솔 또는 BigQuery Migration API를 사용하여 변환 작업을 수행하려면 Google Cloud 로 변환할 쿼리와 스크립트가 포함된 소스 파일을 업로드해야 합니다. 소스 파일이 포함된 동일한 Cloud Storage 버킷에 메타데이터 파일 [https://cloud.google.com/bigquery/docs/generate-metadata?hl=ko] 또는 구성 YAML 파일 [https://cloud.google.com/bigquery/docs/config-yaml-translation?hl=ko]을 업로드할 수도 있습니다. 버킷 생성 및 Cloud Storage에 파일 업로드에 대한 자세한 내용은 버킷 만들기 [https://cloud.google.com/storage/docs/creating-buckets?hl=ko] 및 파일 시스템에서 객체 업로드 [https://cloud.google.com/storage/docs/uploading-objects?hl=ko]를 참조하세요.
지원되는 SQL 언어
일괄 SQL 변환기는 BigQuery Migration Service의 일부입니다. 일괄 SQL 변환기를 통해 GoogleSQL로 변환할 수 있는 SQL 언어:
Amazon Redshift SQL
Apache HiveQL 및 Beeline CLI
IBM Netezza SQL 및 NZPLSQL
Teradata 및 Teradata Vantage
SQL
Basic Teradata Query(BTEQ)
Teradata Parallel Transport(TPT)
또한 프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages]에서 다음 SQL 언어 변환이 지원됩니다.
Apache Spark SQL
Azure Synapse T-SQL
Greenplum SQL
IBM DB2 SQL
MySQL SQL
Oracle SQL, PL/SQL, Exadata
PostgreSQL SQL
Trino 또는 PrestoSQL
Snowflake SQL
SQL Server T-SQL
SQLite
Vertica SQL
중요: 변환은 최선의 노력을 다하는 기준(best effort basis)으로 수행됩니다. 변환 성공은 소스 스크립트에서 SQL 문의 고유성과 복잡성에 따라 달라질 수 있습니다. 일부 스크립트는 수동으로 변환해야 할 수 있습니다. Google Cloud 콘솔 출력 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#output]의 작업 탭을 사용하여 변환 문제를 진단하고 수정합니다.
도우미 UDF로 지원되지 않는 SQL 함수 처리
소스 언어에서 BigQuery로 SQL을 변환할 때 일부 함수에는 직접적인 대응 항목이 없을 수 있습니다. 이 문제를 해결하기 위해 BigQuery 이전 서비스(및 더 큰 BigQuery 커뮤니티)에서는 이러한 지원되지 않는 소스 방언 함수의 동작을 복제하는 도우미 사용자 정의 함수(UDF)를 제공합니다.
이러한 UDF는 bqutil 공개 데이터 세트에 있는 경우가 많으므로 변환된 쿼리는 처음에 bqutil.<dataset>.<function>() 형식을 사용하여 이를 참조할 수 있습니다. 예를 들면 bqutil.fn.cw_count()입니다.
프로덕션 환경의 중요 고려사항:
bqutil은 초기 변환 및 테스트를 위해 이러한 도우미 UDF에 편리하게 액세스할 수 있도록 제공하지만 프로덕션 워크로드에 bqutil을 직접 사용하는 것은 다음과 같은 몇 가지 이유로 권장되지 않습니다.
버전 제어: bqutil 프로젝트는 이러한 UDF의 최신 버전을 호스팅하므로 시간이 지남에 따라 정의가 변경될 수 있습니다. bqutil을 직접 사용하면 UDF 로직이 업데이트될 경우 프로덕션 쿼리에서 예기치 않은 동작이나 중단 변경사항이 발생할 수 있습니다.
종속 항목 격리: 자체 프로젝트에 UDF를 배포하면 프로덕션 환경이 외부 변경사항으로부터 격리됩니다.
맞춤설정: 특정 비즈니스 로직이나 성능 요구사항에 더 적합하도록 이러한 UDF를 수정하거나 최적화해야 할 수 있습니다. 이는 내 프로젝트 내에 있는 경우에만 가능합니다.
보안 및 거버넌스: 조직의 보안 정책에 따라 프로덕션 데이터 처리를 위해 bqutil과 같은 공개 데이터 세트에 대한 직접 액세스가 제한될 수 있습니다. UDF를 제어된 환경에 복사하는 것은 이러한 정책에 부합합니다.
프로젝트에 도우미 UDF 배포
안정적인 프로덕션 사용을 위해 이러한 도우미 UDF를 자체 프로젝트 및 데이터 세트에 배포해야 합니다. 이렇게 하면 버전, 맞춤설정, 액세스를 완전히 제어할 수 있습니다. 이러한 UDF를 배포하는 방법에 관한 자세한 안내는 GitHub의 UDF 배포 가이드 [https://github.com/GoogleCloudPlatform/bigquery-utils/tree/master/udfs#deploying-the-udfs]를 참고하세요. 이 가이드에서는 UDF를 환경에 복사하는 데 필요한 스크립트와 단계를 제공합니다.
위치
일괄 SQL 변환기는 다음 처리 위치에서 제공됩니다.
리전 설명 리전 이름 세부정보
아시아 태평양
델리 asia-south2
홍콩 asia-east2
자카르타 asia-southeast2
멜버른 australia-southeast2
뭄바이 asia-south1
오사카 asia-northeast2
서울 asia-northeast3
싱가포르 asia-southeast1
시드니 australia-southeast1
타이완 asia-east1
도쿄 asia-northeast1
유럽
벨기에 europe-west1 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
베를린 europe-west10 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
EU 멀티 리전 eu
핀란드 europe-north1 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
프랑크푸르트 europe-west3
런던 europe-west2 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
마드리드 europe-southwest1 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
밀라노 europe-west8
네덜란드 europe-west4 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
파리 europe-west9 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
스톡홀름 europe-north2 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
토리노 europe-west12
바르샤바 europe-central2
취리히 europe-west6 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
미주
오하이오 주 콜럼부스 us-east5
Dallas us-south1 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
아이오와 us-central1 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
라스베이거스 us-west4
로스앤젤레스 us-west2
멕시코 northamerica-south1
북버지니아 us-east4
오리건 us-west1 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
퀘벡 northamerica-northeast1 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
상파울루 southamerica-east1 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
솔트레이크시티 us-west3
산티아고 southamerica-west1 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
사우스캐롤라이나 us-east1
토론토 northamerica-northeast2 낮은 CO2 [https://cloud.google.com/sustainability/region-carbon?hl=ko#region-picker]
미국 멀티 리전 us
아프리카
요하네스버그 africa-south1
MiddleEast
담맘 me-central2
도하 me-central1
이스라엘 me-west1
변환 작업 제출
변환 작업을 시작하고, 진행 상황을 확인하고, 결과를 확인하려면 다음 단계를 따르세요.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#%EC%BD%98%EC%86%94] ---
이러한 단계에서는 소스 파일이 Cloud Storage 버킷에 이미 업로드되었다고 가정합니다.


 Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.

BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko] 
탐색 메뉴에서 도구 및 가이드를 클릭합니다.
SQL 변환 패널에서 변환 > 일괄 변환을 클릭합니다.
변환 구성 페이지가 열립니다. 다음 세부정보를 입력합니다.


표시 이름에 변환 작업 이름을 입력합니다. 이름에는 문자, 숫자 또는 밑줄을 사용할 수 있습니다.
처리 위치에서 변환 작업을 실행할 위치를 선택합니다. 예를 들어 개발자가 유럽에 있고 데이터가 위치 경계를 넘어가지 않게 하려면 eu 리전을 선택합니다. 변환 작업은 소스 파일 버킷과 동일한 위치를 선택할 때 최고의 성능을 발휘합니다.
소스 언어에서 변환할 SQL 언어를 선택합니다.
대상 언어에서 BigQuery를 선택합니다.

다음을 클릭합니다.
소스 위치에 변환할 파일이 포함된 Cloud Storage 폴더의 경로를 지정합니다. 경로를 bucket_name/folder_name/ 형식으로 입력하거나 찾아보기 옵션을 사용할 수 있습니다.
다음을 클릭합니다.
대상 위치에서 변환된 파일의 대상 Cloud Storage 폴더 경로를 지정합니다. 경로를 bucket_name/folder_name/ 형식으로 입력하거나 찾아보기 옵션을 사용할 수 있습니다.
기본 객체 이름이나 소스-대상 이름 매핑을 지정할 필요가 없는 변환을 수행하는 경우 11단계로 건너뜁니다. 그렇지 않으면 다음을 클릭합니다.
필요한 설정(선택사항)을 입력합니다.


선택사항. 기본 데이터베이스에 소스 파일에서 사용할 기본 데이터베이스 이름 [https://cloud.google.com/bigquery/docs/output-name-mapping?hl=ko#default_database]을 입력합니다. 변환기는 이 기본 데이터베이스 이름을 사용하여 데이터베이스 이름이 누락된 SQL 객체의 정규화된 이름 [https://cloud.google.com/bigquery/docs/output-name-mapping?hl=ko#name_parts]을 확인합니다.
선택사항. 메타데이터 캐싱의 경우 메타데이터 캐싱 사용 설정 체크박스를 클릭하여 BigQuery 백엔드에서 dwh-migration-dumper 도구로 생성된 메타데이터 ZIP 파일 [https://cloud.google.com/bigquery/docs/generate-metadata?hl=ko]의 정보를 저장합니다. 메타데이터 파일이 큰 작업의 경우 이 프로세스를 통해 후속 요청의 변환 지연 시간이 크게 줄어듭니다. 캐시된 메타데이터는 최대 7일 동안 활성 상태입니다. 이 기능은 프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages] 상태입니다. 이 기능에 대한 지원을 요청하거나 의견을 제공하려면 bq-edw-migration-support@google.com [mailto:%20bq-edw-migration-support@google.com]으로 문의하세요.
선택사항. 스키마 검색 경로의 경우, 변환기가 스키마 이름이 누락된 소스 파일에서 SQL 객체의 정규화된 이름 [https://cloud.google.com/bigquery/docs/output-name-mapping?hl=ko#name_parts]을 확인해야 하는 경우에 검색할 스키마를 지정합니다. 소스 파일에서 여러 스키마 이름을 사용하는 경우 스키마 이름 추가를 클릭하고 참조될 수 있는 각 스키마의 값을 추가합니다.

변환기는 제공된 메타데이터 파일을 검색하여 스키마 이름으로 테이블의 유효성을 검사합니다. 메타데이터에서 명확한 옵션을 결정할 수 없으면 입력한 첫 번째 스키마 이름이 기본값으로 사용됩니다. 기본 스키마 이름이 사용되는 방법에 대한 자세한 내용은 기본 스키마 [https://cloud.google.com/bigquery/docs/output-name-mapping?hl=ko#default_schema]를 참조하세요.
선택사항. 변환 중에 소스 시스템과 BigQuery 간에 SQL 객체 이름을 변경하도록 이름 매핑 규칙 [https://cloud.google.com/bigquery/docs/output-name-mapping?hl=ko]을 지정하려면 이름 매핑 쌍이 있는 JSON 파일 [https://cloud.google.com/bigquery/docs/output-name-mapping?hl=ko#json_file_format]을 제공하거나Google Cloud 콘솔을 사용하여 매핑할 값을 지정하면 됩니다.

JSON 파일을 사용하려면 다음 안내를 따르세요.


이름 매핑용 JSON 파일 업로드를 클릭합니다.
적절한 형식 [https://cloud.google.com/bigquery/docs/output-name-mapping?hl=ko#json_file_format]으로 된 이름 매핑 파일의 위치를 찾아 선택하고 열기를 클릭합니다.

파일 크기는 5MB 미만이어야 합니다.


 Google Cloud 콘솔을 사용하려면 다음 안내를 따르세요.


이름 매핑 쌍 추가를 클릭합니다.
소스 열의 데이터베이스, 스키마, 관계, 속성 필드에 소스 객체 이름의 적절한 부분을 추가합니다.
대상 열의 필드에 BigQuery의 대상 객체 이름 부분을 추가합니다.
유형에 매핑하려는 객체를 설명하는 객체 유형을 선택합니다.
필요한 이름 매핑 쌍을 모두 지정할 때까지 1~4단계를 반복합니다. Google Cloud 콘솔을 사용할 때 이름 매핑 쌍을 최대 25개까지만 지정할 수 있습니다.

선택사항. Gemini 모델을 사용하여 번역 AI 추천을 생성하려면 Gemini AI 추천 체크박스를 선택합니다. 추천은 .ai_config.yaml로 끝나고 Cloud Storage 디렉터리에 위치한 구성 YAML 파일을 기반으로 합니다. 각 유형의 추천 출력은 이름 패턴이 REWRITETARGETSUGGESTION_TYPE_suggestion인 출력 폴더 내 자체 하위 디렉터리에 저장됩니다.
예를 들어 Gemini로 향상된 타겟 SQL 맞춤설정에 관한 추천은 target_sql_query_customization_suggestion에 저장되고 Gemini에서 생성된 변환 설명은 translation_explanation_suggestion에 저장됩니다.
AI 추천을 위한 구성 YAML 파일을 작성하는 방법을 알아보려면 Gemini 기반 구성 YAML 파일 만들기 [https://cloud.google.com/bigquery/docs/config-yaml-translation?hl=ko#ai_yaml_guidelines]를 참고하세요.

만들기를 클릭하여 변환 작업을 시작합니다.


변환 작업이 생성되면 변환 작업 목록에서 상태를 확인할 수 있습니다.

--- 탭: 일괄 변환 클라이언트 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#%EC%9D%BC%EA%B4%84-%EB%B3%80%ED%99%98-%ED%81%B4%EB%9D%BC%EC%9D%B4%EC%96%B8%ED%8A%B8] ---
참고: 새 변환의 경우 일괄 변환 클라이언트 대신 BigQuery Migration API [https://cloud.google.com/bigquery/docs/api-sql-translator?hl=ko]를 사용하는 것이 좋습니다.

일괄 변환 클라이언트 및 Google Cloud CLI를 설치합니다 [https://github.com/google/dwh-migration-tools/blob/main/client/README.md#installation].
gcloud CLI 사용자 인증 정보 파일을 생성합니다 [https://github.com/google/dwh-migration-tools/blob/main/client/README.md#optional-gcloud-login-and-authentication].
일괄 변환 클라이언트 설치 디렉터리에서 원하는 텍스트 편집기를 사용하여 config.yaml 파일을 열고 다음 설정을 수정합니다.


project_number: 일괄 변환 작업에 사용할 프로젝트의 프로젝트 번호를 입력합니다. 프로젝트의 Google Cloud 콘솔 시작 페이지 [https://console.cloud.google.com/welcome?hl=ko]에 있는 프로젝트 정보 창에서 찾을 수 있습니다.
gcs_bucket: 일괄 변환 클라이언트가 변환 작업 처리 중에 파일을 저장하는 데 사용할 Cloud Storage 버킷의 이름을 입력합니다.
input_directory: 소스 파일과 모든 메타데이터 파일이 있는 디렉터리의 절대 또는 상대 경로를 입력합니다.
output_directory: 변환된 파일의 대상 디렉터리에 대한 절대 또는 상대 경로를 입력합니다.

변경사항을 저장하고 config.yaml 파일을 닫습니다.
소스 파일과 메타데이터 파일을 입력 디렉터리에 저장합니다.
다음 명령어를 사용하여 일괄 변환 클라이언트를 실행합니다.
bin/dwh-migration-client

변환 작업이 생성되면 Google Cloud 콘솔의 변환 작업 목록에서 상태를 확인할 수 있습니다.
선택사항. 변환 작업이 완료되면 스토리지 비용이 방지되도록 작업이 지정한 Cloud Storage 버킷에 만든 파일을 삭제합니다.
변환 출력 살펴보기
변환 작업을 실행하면 Google Cloud 콘솔에서 작업에 대한 정보를 확인할 수 있습니다. Google Cloud 콘솔을 사용하여 작업을 실행한 경우 지정한 대상 Cloud Storage 버킷에서 작업 결과를 확인할 수 있습니다. 일괄 변환 클라이언트를 사용하여 작업을 실행한 경우 지정한 출력 디렉터리에서 작업 결과를 확인할 수 있습니다. 일괄 SQL 변환기는 다음 파일을 지정된 대상으로 출력합니다.
변환된 파일
CSV 형식의 변환 요약 보고서
JSON 형식의 사용된 출력 이름 매핑
AI 추천 파일
Google Cloud 콘솔 출력
변환 작업 세부정보를 보려면 다음 단계를 따르세요.
Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.
BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko]
탐색 메뉴에서 SQL 변환을 클릭합니다.
변환 작업 목록에서 변환 세부정보를 보려는 작업을 찾습니다. 그런 다음 번역 작업 이름을 클릭합니다. 작업의 전반적인 품질, 코드 입력 줄 수(공백 줄 및 주석 제외), 변환 프로세스 중에 발생한 문제 목록을 보여주는 흐름 차트 시각화를 확인할 수 있습니다. 왼쪽에서 오른쪽으로 수정사항의 우선순위를 지정해야 합니다. 초기 단계의 문제는 후속 단계에서 추가 문제를 일으킬 수 있습니다.
오류 또는 경고 막대 위로 포인터를 가져가 제안사항을 검토하여 번역 작업을 디버그하기 위한 다음 단계를 결정합니다.
로그 요약 탭을 선택하여 문제 카테고리, 추천 작업, 각 문제의 발생 빈도 등 번역 문제의 요약을 확인합니다. 흐름 시각화 막대를 클릭하여 문제를 필터링할 수 있습니다. 또한 문제 카테고리를 선택하여 해당 문제 카테고리와 연결된 로그 메시지를 볼 수 있습니다.
로그 메시지 탭을 선택하여 문제 카테고리, 특정 문제 메시지, 문제가 발생한 파일의 링크 등 각 번역 문제에 관한 세부정보를 확인합니다. 흐름 시각화 막대를 클릭하여 문제를 필터링할 수 있습니다. 로그 메시지 탭에서 문제를 선택하여 적용 가능한 경우 입력 및 출력 파일을 표시하는 코드 탭 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#code-tab]을 열 수 있습니다.
작업 세부정보 탭을 클릭하여 변환 작업 구성 세부정보를 확인합니다.
요약 보고서
요약 보고서는 변환 작업 중에 발생한 모든 경고 및 오류 메시지 테이블을 포함하는 CSV 파일입니다.
Google Cloud 콘솔에서 요약 파일을 보려면 다음 단계를 따르세요.
Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.
BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko]
탐색 메뉴에서 SQL 변환을 클릭합니다.
변환 작업 목록에서 원하는 작업을 찾은 후 작업 이름을 클릭하거나 옵션 더보기 > 세부정보 표시를 클릭합니다.
작업 세부정보 탭의 변환 보고서 섹션에서 translation_report.csv를 클릭합니다.
객체 세부정보 페이지에서 인증된 URL 행의 값을 클릭하여 브라우저에서 파일을 확인합니다.
다음 테이블에서는 요약 파일 열을 설명합니다.
열 설명
타임스탬프 문제가 발생한 타임스탬프입니다.
FilePath 문제와 연결된 소스 파일의 경로입니다.
FileName 문제와 연결된 소스 파일의 이름입니다.
ScriptLine 문제가 발생한 줄 번호입니다.
ScriptColumn 문제가 발생한 열 번호입니다.
TranspilerComponent 경고나 오류가 발생한 변환 엔진 내부 구성요소입니다. 이 열은 비어 있을 수 있습니다.
환경 경고 또는 오류와 관련된 변환 언어 환경입니다. 이 열은 비어 있을 수 있습니다.
ObjectName 경고 또는 오류와 관련된 소스 파일의 SQL 객체입니다. 이 열은 비어 있을 수 있습니다.
심각도 문제 심각도로, 경고나 오류입니다.
카테고리 변환 문제 카테고리입니다.
SourceType 이 문제의 원인입니다. 이 열의 값은 입력 SQL 파일의 문제를 나타내는 SQL 또는 메타데이터 패키지의 문제를 나타내는 METADATA일 수 있습니다.
메시지 변환 문제 경고 또는 오류 메시지입니다.
ScriptContext 문제와 연결된 소스 파일의 SQL 스니펫입니다.
작업 문제를 해결하기 위한 권장한 조치입니다.
코드 탭
코드 탭을 사용하면 특정 번역 작업의 입력 파일과 출력 파일에 관한 추가 정보를 검토할 수 있습니다. 코드 탭에서 변환 작업에 사용되는 파일을 조사하고, 입력 파일과 번역의 부정확성을 나란히 비교하고, 로그 요약과 메시지를 볼 수 있습니다. 변경할 수 있습니다.
코드 탭에 액세스하려면 다음 단계를 따르세요.
Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.
BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko]
탐색 메뉴에서 SQL 변환을 클릭합니다.
변환 작업 목록에서 원하는 작업을 찾은 후 작업 이름을 클릭하거나 옵션 더보기 > 세부정보 표시를 클릭합니다.
코드 탭을 선택합니다. 코드 탭은 다음 패널로 구성됩니다.
파일 탐색기: 변환에 사용되는 모든 SQL 파일이 포함되어 있습니다. 파일을 클릭하여 번역 입력 및 출력과 번역의 번역 문제를 확인합니다.
Gemini로 향상된 입력: 변환 엔진에서 변환한 입력 SQL입니다. Gemini 구성 [https://cloud.google.com/bigquery/docs/config-yaml-translation?hl=ko#ai_yaml_guidelines]에서 소스 SQL에 Gemini 맞춤설정 규칙을 지정한 경우 변환기는 먼저 원래 입력을 변환한 다음 Gemini로 향상된 입력을 변환합니다. 원본 입력을 보려면 원본 입력 보기를 클릭합니다.
번역 출력: 번역 결과입니다. Gemini 구성 [https://cloud.google.com/bigquery/docs/config-yaml-translation?hl=ko#ai_yaml_guidelines]에서 대상 SQL에 Gemini 맞춤설정 규칙을 지정한 경우 변환은 변환된 결과에 Gemini로 향상된 출력으로 적용됩니다. Gemini 개선 출력을 사용할 수 있는 경우 Gemini 추천 버튼을 클릭하여 Gemini 개선 출력을 검토할 수 있습니다.
(선택사항) BigQuery 대화형 SQL 변환기 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#debug-interactive-translator]에서 입력 파일과 출력 파일을 보려면 수정을 클릭합니다. 파일을 수정하고 출력 파일을 Cloud Storage에 다시 저장할 수 있습니다.
참고: 결과 페이지 [https://cloud.google.com/bigquery/docs/batch-sql-translator?hl=ko#explore_the_translation_output]
에서 전체 번역 작업의 로그 요약과 메시지를 확인할 수 있습니다.
구성 탭
구성 탭에서 구성 YAML 파일을 추가, 이름 변경, 보기 또는 수정할 수 있습니다.스키마 탐색기에는 구성 YAML 파일을 작성하는 데 도움이 되는 지원되는 구성 유형에 관한 문서가 표시됩니다. 구성 YAML 파일을 수정한 후 작업을 다시 실행하여 새 구성을 사용할 수 있습니다.
구성 탭에 액세스하려면 다음 단계를 따르세요.
Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.
BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko]
탐색 메뉴에서 SQL 변환을 클릭합니다.
변환 작업 목록에서 원하는 작업을 찾은 후 작업 이름을 클릭하거나 옵션 더보기 > 세부정보 표시를 클릭합니다.
번역 세부정보 창에서 구성 탭을 클릭합니다.
새 구성 파일을 추가하려면 다음 단계를 따르세요.
more_vert 옵션 더보기 > 구성 YAML 파일 만들기를 클릭합니다.
새 구성 YAML 파일의 유형, 위치, 이름을 선택할 수 있는 패널이 표시됩니다.
만들기를 클릭합니다.
기존 구성 파일을 수정하려면 다음 단계를 따르세요.
구성 YAML 파일을 클릭합니다.
파일을 수정한 다음 저장을 클릭합니다.
다시 실행을 클릭하여 수정된 구성 YAML 파일을 사용하는 새 번역 작업을 실행합니다.
more_vert 옵션 더보기 > 이름 바꾸기를 클릭하여 기존 구성 파일의 이름을 바꿀 수 있습니다.
소비된 출력 이름 매핑 파일
이 JSON 파일에는 변환 작업에 사용된 출력 이름 매핑 규칙이 포함되어 있습니다. 이 파일의 규칙은 이름 매핑 규칙 충돌이나 변환 중에 식별된 SQL 객체에 대한 이름 매핑 규칙 부족으로 인해 변환 작업에 지정한 출력 이름 매핑 [https://cloud.google.com/bigquery/docs/output-name-mapping?hl=ko] 규칙과 다를 수 있습니다. 이 파일을 검토하여 이름 매핑 규칙을 수정해야 하는지 여부를 결정합니다. 수정한 경우 식별된 모든 문제를 해결하는 새로운 출력 이름 매핑 규칙을 만들고 새 변환 작업을 실행합니다.
변환된 파일
각 소스 파일에 대해 해당 출력 파일이 대상 경로에 생성됩니다. 출력 파일에는 변환된 쿼리가 포함됩니다.
중요: 변환은 최선의 노력을 다하는 기준(best effort basis)으로 수행됩니다. 가능하면 변환된 쿼리의 유효성을 검사합니다.
대화형 SQL 변환기를 사용하여 일괄 변환된 SQL 쿼리 디버깅
BigQuery 대화형 SQL 변환기를 사용하여 소스 데이터베이스와 동일한 메타데이터 또는 객체 매핑 정보를 사용하여 SQL 쿼리를 검토하거나 디버그할 수 있습니다. 일괄 번역 작업을 완료하면 BigQuery는 쿼리에 해당하는 작업의 메타데이터, 객체 매핑 또는 스키마 검색 경로에 관한 정보가 포함된 번역 구성 ID를 생성합니다. 대화형 SQL 변환기와 함께 일괄 변환 구성 ID를 사용하여 지정된 구성으로 SQL 쿼리를 실행합니다.
일괄 변환 구성 ID를 사용하여 대화형 SQL 변환을 시작하려면 다음 단계를 따르세요.
Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.
BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko]
탐색 메뉴에서 SQL 변환을 클릭합니다.
변환 작업 목록에서 원하는 작업을 찾은 후 more_vert 옵션 더보기 > 대화형 변환 열기를 클릭합니다.
이제 BigQuery 대화형 SQL 변환기가 해당하는 일괄 변환 구성 ID로 열립니다. 대화형 변환의 변환 구성 ID를 보려면 대화형 SQL 변환기에서 더보기 > 변환 설정을 클릭합니다.
대화형 SQL 변환기에서 일괄 변환 파일을 디버그하려면 다음 단계를 따르세요.
Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.
BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko]
탐색 메뉴에서 SQL 변환을 클릭합니다.
변환 작업 목록에서 원하는 작업을 찾은 후 작업 이름을 클릭하거나 옵션 더보기 > 세부정보 표시를 클릭합니다.
번역 세부정보 창에서 코드 탭을 클릭합니다.
파일 탐색기에서 파일 이름을 클릭하여 파일을 엽니다.
출력 파일 이름 옆에 있는 수정을 클릭하여 대화형 SQL 변환기(프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages])에서 파일을 엽니다.
이제 대응하는 일괄 변환 구성 ID를 사용하는 대화형 SQL 변환기에 입력 파일과 출력 파일이 채워집니다.
수정된 출력 파일을 Cloud Storage에 다시 저장하려면 대화형 SQL 변환기에서 저장 > GCS에 저장을 클릭합니다.
제한사항
변환기는 SQL 이외의 언어에서 사용자 정의 함수(UDF)를 변환할 수 없습니다. 입력 및 출력 데이터 유형을 결정하기 위해 파싱할 수 없기 때문입니다. 이렇게 하면 이러한 UDF를 참조하는 SQL 문 변환이 부정확해질 수 있습니다. 변환 중에 SQL이 아닌 UDF를 올바르게 참조하게 하려면 유효한 SQL을 사용하여 동일한 서명으로 자리표시자 UDF를 만듭니다.
예를 들어 C로 작성된 UDF가 두 정수의 합을 계산한다고 가정해 보겠습니다. 이 UDF를 참조하는 SQL 문이 올바르게 변환되게 하려면 다음 예시와 같이 C UDF와 동일한 서명을 공유하는 자리표시자 SQL UDF를 만듭니다.
CREATE FUNCTION Test.MySum (a INT, b INT)
  RETURNS INT
  LANGUAGE SQL
  RETURN a + b;
이 자리표시자 UDF를 텍스트 파일로 저장하고 해당 파일을 변환 작업의 소스 파일 중 하나로 포함합니다. 이렇게 하면 변환기가 UDF 정의를 학습하고 예상 입력 및 출력 데이터 유형을 식별할 수 있습니다.
할당량 및 한도
BigQuery Migration API 할당량 [https://cloud.google.com/bigquery/quotas?hl=ko#migration-api-limits]이 적용됩니다.
프로젝트마다 활성 변환 태스크를 최대 10개까지 있을 수 있습니다.
소스 파일과 메타데이터 파일의 총 수에는 엄격한 제한이 없지만 우수한 성능을 위해 파일 수를 1000개 미만으로 유지하는 것이 좋습니다.
변환 오류 문제 해결
RelationNotFound 또는 AttributeNotFound 변환 문제
변환은 메타데이터 DDL에서 가장 잘 작동합니다. SQL 객체 정의를 찾을 수 없으면 변환 엔진이 RelationNotFound 또는 AttributeNotFound 문제를 일으킵니다. 모든 객체 정의가 제공되도록 하려면 메타데이터 추출자를 사용해서 메타데이터 패키지를 생성하는 것이 좋습니다. 메타데이터 부족으로 인해 간접적으로 발생하는 많은 기타 오류를 해결할 수 있으므로, 대부분의 변환 오류를 해결하기 위해서는 우선 메타데이터를 추가하는 것이 좋습니다.
자세한 내용은 변환 및 평가를 위한 메타데이터 생성 [https://cloud.google.com/bigquery/docs/generate-metadata?hl=ko]을 참조하세요.
가격 책정
일괄 SQL 변환기를 사용하는 데에는 요금이 부과되지 않습니다. 그러나 입력 및 출력 파일을 저장하는 데 사용되는 스토리지에는 일반 요금이 발생합니다. 자세한 내용은 스토리지 가격 책정 [https://cloud.google.com/bigquery/pricing?hl=ko#storage]을 참조하세요.
다음 단계
데이터 웨어하우스 마이그레이션의 다음 단계를 자세히 알아보세요.
마이그레이션 개요 [https://cloud.google.com/bigquery/docs/migration/migration-overview?hl=ko]
마이그레이션 평가 [https://cloud.google.com/bigquery/docs/migration-assessment?hl=ko]
스키마 및 데이터 전송 개요 [https://cloud.google.com/bigquery/docs/migration/schema-data-overview?hl=ko]
데이터 파이프라인 [https://cloud.google.com/bigquery/docs/migration/pipelines?hl=ko]
대화형 SQL 변환 [https://cloud.google.com/bigquery/docs/interactive-sql-translator?hl=ko]
데이터 보안 및 거버넌스 [https://cloud.google.com/bigquery/docs/data-governance?hl=ko]
데이터 검증 도구 [https://github.com/GoogleCloudPlatform/professional-services-data-validator#data-validation-tool]
도움이 되었나요?
의견 보내기