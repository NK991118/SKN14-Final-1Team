Source URL: https://cloud.google.com/bigquery/docs/tables

BigQuery [https://cloud.google.com/bigquery?hl=ko]
Documentation [https://cloud.google.com/bigquery/docs?hl=ko]
가이드 [https://cloud.google.com/bigquery/docs/introduction?hl=ko]
도움이 되었나요?
의견 보내기
이 페이지의 내용
시작하기 전에 [https://cloud.google.com/bigquery/docs/tables?hl=ko#before_you_begin]
테이블 이름 지정 [https://cloud.google.com/bigquery/docs/tables?hl=ko#table_naming]
테이블 만들기 [https://cloud.google.com/bigquery/docs/tables?hl=ko#create-table]
필수 권한 [https://cloud.google.com/bigquery/docs/tables?hl=ko#required_permissions]
스키마 정의가 있는 빈 테이블 만들기 [https://cloud.google.com/bigquery/docs/tables?hl=ko#create_an_empty_table_with_a_schema_definition]
스키마 정의가 없는 빈 테이블 만들기 [https://cloud.google.com/bigquery/docs/tables?hl=ko#create_an_empty_table_without_a_schema_definition]
쿼리 결과에서 테이블 만들기 [https://cloud.google.com/bigquery/docs/tables?hl=ko#create_a_table_from_a_query_result]
외부 데이터 소스를 참조하는 테이블 만들기 [https://cloud.google.com/bigquery/docs/tables?hl=ko#create_a_table_that_references_an_external_data_source]
테이블 만들기 및 사용
bookmark_border
이 문서에서는 BigQuery에서 표준(기본 제공) 테이블 [https://cloud.google.com/bigquery/docs/tables-intro?hl=ko#standard-tables]을 만들고 사용하는 방법을 설명합니다. 다른 테이블 유형 만들기에 대한 자세한 내용은 다음을 참고하세요.
파티션을 나눈 테이블 만들기 [https://cloud.google.com/bigquery/docs/creating-partitioned-tables?hl=ko]
클러스터링된 테이블 만들기 및 사용 [https://cloud.google.com/bigquery/docs/creating-clustered-tables?hl=ko]
테이블을 만든 후에는 다음 작업을 할 수 있습니다.
테이블 데이터에 대한 액세스 제어
테이블에 대한 정보 가져오기
데이터 세트의 테이블 나열
테이블 메타데이터 가져오기
테이블 속성 업데이트, 테이블 복사, 테이블 삭제를 비롯하여 테이블 관리에 대한 자세한 내용은 테이블 관리 [https://cloud.google.com/bigquery/docs/managing-tables?hl=ko]를 참조하세요.
시작하기 전에
BigQuery에서 테이블을 만들기 전에 먼저 다음을 수행하세요.
BigQuery 샌드박스 [https://cloud.google.com/bigquery/docs/sandbox?hl=ko]에서 프로젝트를 설정합니다.
BigQuery 데이터세트 만들기 [https://cloud.google.com/bigquery/docs/datasets?hl=ko]
원할 경우 테이블 소개 [https://cloud.google.com/bigquery/docs/tables-intro?hl=ko]를 참조하여 테이블 제한사항, 할당량, 가격을 이해합니다.
테이블 이름 지정
BigQuery에서 테이블을 만들 때 테이블 이름은 데이터 세트별로 고유해야 합니다. 테이블 이름을 지정하는 규칙은 다음과 같습니다.
최대 총 1,024 UTF-8 바이트의 문자를 포함합니다.
L(문자), M(표시), N(숫자), Pc(밑줄 포함 커넥터), Pd(대시), Zs(공백) 카테고리의 유니코드를 포함합니다. 자세한 내용은 일반 카테고리 [https://wikipedia.org/wiki/Unicode_character_property#General_Category]를 참조하세요.
table 01, ग्राहक, 00_お客様, étudiant-01은 모두 유효한 테이블 이름 예시입니다.
주의사항:
기본적으로 테이블 이름은 대소문자를 구분합니다. mytable 및 MyTable은 대소문자 구분이 사용 중지된 데이터 세트 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#creating_a_case-insensitive_dataset]에 속하지 않는 한 동일한 데이터 세트에 공존할 수 있습니다.
일부 테이블 이름과 테이블 이름 프리픽스가 예약되어 있습니다. 테이블 이름 또는 프리픽스가 예약되어 있다는 오류가 표시되면 다른 이름을 선택한 후 다시 시도하세요.
시퀀스에 점 연산자(.)를 여러 개 포함하면 중복된 연산자가 암시적으로 삭제됩니다.
예를 들어 원래 문법이 project_name....dataset_name..table_name이면
문법이 project_name.dataset_name.table_name으로 바뀝니다.
테이블 만들기
다음 방법으로 BigQuery에서 테이블을 만들 수 있습니다.
Google Cloud 콘솔 또는 bq 명령줄 도구 bq mk [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_mk] 명령어를 사용하여 수동으로 만들기
tables.insert [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/insert?hl=ko] API 메서드를 호출하여 프로그래매틱 방식으로 만들기
클라이언트 라이브러리를 사용하여 만들기
쿼리 결과에서 만들기
외부 데이터 소스를 참조하는 테이블을 정의하여 만들기
데이터를 로드할 때 만들기
CREATE TABLE [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#creating_a_new_table] 데이터 정의 언어(DDL) 문을 사용하여 만듭니다.
필수 권한
테이블을 만들려면 다음 IAM 권한이 필요합니다.
bigquery.tables.create
bigquery.tables.updateData
bigquery.jobs.create
또한 테이블에 기록하는 데이터에 액세스하기 위해 bigquery.tables.getData 권한이 필요할 수 있습니다.
다음과 같은 사전 정의된 각 IAM 역할에는 테이블을 만드는 데 필요한 권한이 포함되어 있습니다.
roles/bigquery.dataEditor
roles/bigquery.dataOwner
roles/bigquery.admin(bigquery.jobs.create 권한 포함)
roles/bigquery.user(bigquery.jobs.create 권한 포함)
roles/bigquery.jobUser(bigquery.jobs.create 권한 포함)
또한 bigquery.datasets.create 권한이 있으면 만들 데이터 세트에서 테이블을 만들고 업데이트할 수 있습니다.
BigQuery의 IAM 역할과 권한에 대한 자세한 내용은 사전 정의된 역할 및 권한 [https://cloud.google.com/bigquery/docs/access-control?hl=ko]을 참조하세요.
스키마 정의가 있는 빈 테이블 만들기
다음 방법으로 스키마 정의가 있는 빈 테이블을 만들 수 있습니다.
Google Cloud 콘솔을 사용하여 스키마를 입력합니다.
bq 명령줄 도구를 사용하여 스키마를 인라인으로 제공합니다.
bq 명령줄 도구를 사용하여 JSON 스키마 파일을 제출합니다.
API의 tables.insert 메서드 [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/insert?hl=ko]를 호출할 때 테이블 리소스 [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables?hl=ko#resource:-table]에 스키마를 제공합니다.
테이블 스키마 지정에 대한 자세한 내용은 스키마 지정 [https://cloud.google.com/bigquery/docs/schemas?hl=ko]을 참조하세요.
테이블을 만든 후에는 테이블에 데이터를 로드 [https://cloud.google.com/bigquery/docs/loading-data?hl=ko]하거나 쿼리 결과를 쓰는 [https://cloud.google.com/bigquery/docs/writing-results?hl=ko] 방법으로 테이블을 채울 수 있습니다.
스키마 정의가 있는 빈 테이블을 만들려면 다음 안내를 따르세요.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/tables?hl=ko#%EC%BD%98%EC%86%94] ---
Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.
    BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko]

탐색기 창에서 프로젝트를 펼친 후 데이터 세트를 선택합니다.
데이터 세트 정보 섹션에서 add_box 테이블 만들기를 클릭합니다.
 테이블 만들기 패널에서 다음 세부정보를 지정합니다. 


  



소스 섹션의 다음 항목으로 테이블 만들기 목록에서 빈 테이블을 선택합니다.







대상 섹션에서 다음 세부정보를 지정합니다.

  데이터 세트에서 테이블을 만들 데이터 세트를 선택합니다.
  테이블 필드에 만들려는 테이블의 이름을 입력합니다.
  테이블 유형 필드가 기본 테이블로 설정되어 있는지 확인합니다.
  





스키마 섹션에 스키마 [https://cloud.google.com/bigquery/docs/schemas?hl=ko] 정의를 입력합니다.
  



  

  다음 방법 중 하나를 사용하여 스키마 정보를 직접 입력할 수 있습니다.

      선택사항 1: 텍스트로 수정을 클릭하고 스키마를 JSON 배열 형식으로 붙여넣습니다. JSON 배열을 사용하는 경우 JSON 스키마 파일 만들기 [https://cloud.google.com/bigquery/docs/schemas?hl=ko#specifying_a_json_schema_file]와 동일한 프로세스를 수행하여 스키마를 생성합니다.
        다음 명령어를 입력하면 기존 테이블의 스키마를 JSON 형식으로 볼 수 있습니다.
        bq show [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_show] --format=prettyjson dataset.table
    
    
      선택사항 2: add_box 필드 추가를 클릭하고 테이블 스키마를 입력합니다. 각 필드의 이름, 유형 [https://cloud.google.com/bigquery/docs/schemas?hl=ko#standard_sql_data_types], 모드 [https://cloud.google.com/bigquery/docs/schemas?hl=ko#modes]를 지정합니다.
 



  
  



  
  선택사항: 파티션 및 클러스터 설정을 지정합니다. 자세한 내용은 파티션을 나눈 테이블 만들기 [https://cloud.google.com/bigquery/docs/creating-partitioned-tables?hl=ko] 및 클러스터링된 테이블 만들기 및 사용 [https://cloud.google.com/bigquery/docs/creating-clustered-tables?hl=ko]을 참조하세요.
    
  



   



선택사항: 고급 옵션 섹션에서 고객 관리 암호화 키를 사용하려면 고객 관리 암호화 키(CMEK) 사용 옵션을 선택합니다. 기본적으로 BigQuery는 Google-owned and Google-managed encryption key를 사용하여 비활성 상태로 저장된 고객 콘텐츠를 암호화 [https://cloud.google.com/security/encryption/default-encryption?hl=ko]합니다.




테이블 만들기를 클릭합니다.


참고: Google Cloud 콘솔을 사용하여 빈 테이블을 만들 때는 라벨, 설명, 만료 시간을 추가할 수 없습니다. 테이블을 만들 때 bq 명령줄 도구 또는 API를 사용하여 이러한 선택적 속성을 추가할 수 있습니다.
 Google Cloud 콘솔에서 테이블을 만든 후에 만료 시간, 설명, 라벨을 추가할 수 있습니다.

--- 탭: SQL [https://cloud.google.com/bigquery/docs/tables?hl=ko#sql] ---
다음 예시에서는 2023년 1월 1일에 만료되는 newtable라는 테이블을 만듭니다.




 Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.

BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko] 
쿼리 편집기에서 다음 문을 입력합니다.

CREATE TABLE mydataset.newtable (
  x INT64 OPTIONS (description = 'An optional INTEGER field'),
  y STRUCT <
    a ARRAY <STRING> OPTIONS (description = 'A repeated STRING field'),
    b BOOL
  >
) OPTIONS (
    expiration_timestamp = TIMESTAMP '2023-01-01 00:00:00 UTC',
    description = 'a table that expires in 2023',
    labels = [('org_unit', 'development')]);


play_circle 실행을 클릭합니다.




쿼리를 실행하는 방법에 대한 자세한 내용은 대화형 쿼리 실행 [https://cloud.google.com/bigquery/docs/running-queries?hl=ko#queries]을 참조하세요.

--- 탭: bq [https://cloud.google.com/bigquery/docs/tables?hl=ko#bq] ---
In the Google Cloud console, activate Cloud Shell.
    Activate Cloud Shell [https://console.cloud.google.com/?cloudshell=true&hl=ko]
    
      At the bottom of the Google Cloud console, a
      Cloud Shell [https://cloud.google.com/shell/docs/how-cloud-shell-works?hl=ko]
      session starts and displays a command-line prompt. Cloud Shell is a shell environment
      with the Google Cloud CLI
      already installed and with values already set for
      your current project. It can take a few seconds for the session to initialize.
    
    
  










--table 또는 -t 플래그와 함께 bq mk 명령어 [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_mk]를 사용합니다. 인라인으로 또는 JSON 스키마 파일을 사용하여 테이블 스키마 정보를 제공할 수 있습니다. 전체 파라미터 목록은 bq mk --table 참조 [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#mk-table]를 확인하세요.
선택적 파라미터는 다음과 같습니다.


--expiration
--description
--time_partitioning_field
--time_partitioning_type
--range_partitioning
--clustering_fields
--destination_kms_key
--label


여기서는 --time_partitioning_field, --time_partitioning_type, --range_partitioning, --clustering_fields, --destination_kms_key를 설명하지 않습니다. 이러한 선택적 매개변수에 대한 자세한 내용은 다음 링크를 참조하세요.


--time_partitioning_field, --time_partitioning_type, --range_partitioning에 대한 자세한 내용은 파티션을 나눈 테이블 [https://cloud.google.com/bigquery/docs/creating-partitioned-tables?hl=ko]을 참조하세요.
--clustering_fields에 대한 자세한 내용은 클러스터링된 테이블 [https://cloud.google.com/bigquery/docs/creating-clustered-tables?hl=ko]을 참조하세요.
--destination_kms_key에 대한 자세한 내용은 고객 관리 암호화 키 [https://cloud.google.com/bigquery/docs/customer-managed-encryption?hl=ko]를 참조하세요.


기본 프로젝트가 아닌 다른 프로젝트에서 테이블을 만드는 경우 프로젝트 ID를 project_id:dataset 형식으로 데이터 세트에 추가합니다.

기존 데이터 세트에 스키마 정의가 있는 빈 테이블을 만들려면 다음을 입력합니다.

bq mk [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_mk] \
--table \
--expiration=integer \
--description=description \
--label=key_1:value_1 \
--label=key_2:value_2 \
--add_tags=key_3:value_3[,...] \
project_id:dataset.table \
schema

다음을 바꿉니다.


integer은 테이블의 기본 수명(단위: 초)입니다. 최솟값은 3,600초(1시간)입니다. 만료 시간은 현재 UTC 시간과 정수 값을 더한 값으로 계산됩니다. 테이블을 만들 때 만료 시간을 설정하면 데이터 세트의 기본 테이블 만료 시간 설정이 무시됩니다.
description은 따옴표로 묶은 테이블 설명입니다.
key_1:value_1 및 key_2:value_2는 라벨 [https://cloud.google.com/bigquery/docs/labels?hl=ko]을 지정하는 키-값 쌍입니다.
key_3:value_3는 태그 [https://cloud.google.com/bigquery/docs/tags?hl=ko]를 지정하는 키-값 쌍입니다. 키-값 쌍 사이 쉼표를 사용하여 동일한 플래그 아래에 여러 태그를 추가합니다.
project_id는 프로젝트 ID입니다.
dataset는 프로젝트의 데이터 세트입니다.
table은 만드는 테이블의 이름입니다.
schema는 field:data_type,field:data_type 형식의 인라인 스키마 정의이거나 로컬 머신의 JSON 스키마 파일 경로입니다.


명령줄에서 스키마를 지정할 때는 RECORD(STRUCT [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko#struct_type]) 유형을 포함하거나, 열 설명을 포함하거나, 열 모드를 지정할 수 없습니다. 모든 모드는 기본적으로 NULLABLE로 설정됩니다. 설명, 모드, RECORD 유형을 포함하려면 대신 JSON 스키마 파일을 지정 [https://cloud.google.com/bigquery/docs/schemas?hl=ko#specifying_a_json_schema_file]해야 합니다.

예를 들면 다음과 같습니다.

인라인 스키마 정의를 사용하여 테이블을 만들려면 다음 명령어를 입력합니다. 이 명령어는 기본 프로젝트의 mydataset에 mytable이라는 테이블을 만듭니다. 테이블 만료는 3,600초(1시간)로, 설명은 This is my table로, 라벨은 organization:development로 설정됩니다. 이 명령어는 --table 대신 단축형 -t를 사용합니다. 스키마는 qtr:STRING,sales:FLOAT,year:STRING과 같이 인라인으로 지정됩니다.

bq mk [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_mk] \
 -t \
 --expiration 3600 \
 --description "This is my table" \
 --label organization:development \
 mydataset.mytable \
 qtr:STRING,sales:FLOAT,year:STRING

JSON 스키마 파일을 사용하여 테이블을 만들려면 다음 명령어를 입력합니다. 이 명령어는 기본 프로젝트의 mydataset에 mytable이라는 테이블을 만듭니다. 테이블 만료는 3,600초(1시간)로, 설명은 This is my table로, 라벨은 organization:development로 설정됩니다. 스키마 파일의 경로는 /tmp/myschema.json입니다.

bq mk [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_mk] \
 --table \
 --expiration 3600 \
 --description "This is my table" \
 --label organization:development \
 mydataset.mytable \
 /tmp/myschema.json

JSON 스키마 파일을 사용하여 테이블을 만들려면 다음 명령어를 입력합니다.
이 명령어는 myotherproject의 mydataset에 mytable이라는 테이블을 만듭니다. 테이블 만료는 3,600초(1시간)로, 설명은 This is my table로, 라벨은 organization:development로 설정됩니다. 스키마 파일의 경로는 /tmp/myschema.json입니다.

bq mk [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_mk] \
 --table \
 --expiration 3600 \
 --description "This is my table" \
 --label organization:development \
 myotherproject:mydataset.mytable \
 /tmp/myschema.json

테이블을 만든 후 테이블의 만료 시간, 설명, 라벨을 업데이트 [https://cloud.google.com/bigquery/docs/managing-tables?hl=ko]할 수 있습니다. 또한 스키마 정의를 수정 [https://cloud.google.com/bigquery/docs/managing-table-schemas?hl=ko]할 수 있습니다.

Terraformgoogle_bigquery_table [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_table] 리소스를 사용합니다.
참고: Terraform을 사용해서 BigQuery 객체를 만들려면 Cloud Resource Manager API를 사용 설정해야 합니다.
BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다. 자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.

테이블 만들기

다음 예시에서는 mytable이라는 테이블을 만듭니다.






















  





  
    
  
  



















  




  



  


  resource "google_bigquery_dataset" "default" {
  dataset_id                      = "mydataset"
  default_partition_expiration_ms = 2592000000  # 30 days
  default_table_expiration_ms     = 31536000000 # 365 days
  description                     = "dataset description"
  location                        = "US"
  max_time_travel_hours           = 96 # 4 days

  labels = {
    billing_group = "accounting",
    pii           = "sensitive"
  }
}

resource "google_bigquery_table" "default" {
  dataset_id          = google_bigquery_dataset.default.dataset_id
  table_id            = "mytable"
  deletion_protection = false # set to "true" in production

  schema = <<EOF
[
  {
    "name": "ID",
    "type": "INT64",
    "mode": "NULLABLE",
    "description": "Item ID"
  },
  {
    "name": "Item",
    "type": "STRING",
    "mode": "NULLABLE"
  }
]
EOF

}





























테이블 만들기 및 액세스 권한 부여

다음 예시에서는 mytable이라는 테이블을 만든 후 google_bigquery_table_iam_policy [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_table_iam#google_bigquery_table_iam_policy] 리소스를 사용해서 액세스 권한을 부여합니다. 테이블이 있는 데이터 세트에 액세스 권한이 없는 주 구성원에게 테이블 액세스 권한을 부여하려는 경우에만 이 단계를 수행합니다.






















  





  
    
  
  



















  




  



  


  resource "google_bigquery_dataset" "default" {
  dataset_id                      = "mydataset"
  default_partition_expiration_ms = 2592000000  # 30 days
  default_table_expiration_ms     = 31536000000 # 365 days
  description                     = "dataset description"
  location                        = "US"
  max_time_travel_hours           = 96 # 4 days

  labels = {
    billing_group = "accounting",
    pii           = "sensitive"
  }
}

resource "google_bigquery_table" "default" {
  dataset_id          = google_bigquery_dataset.default.dataset_id
  table_id            = "mytable"
  deletion_protection = false # set to "true" in production

  schema = <<EOF
[
  {
    "name": "ID",
    "type": "INT64",
    "mode": "NULLABLE",
    "description": "Item ID"
  },
  {
    "name": "Item",
    "type": "STRING",
    "mode": "NULLABLE"
  }
]
EOF

}

data "google_iam_policy" "default" {
  binding {
    role = "roles/bigquery.dataOwner"
    members = [
      "user:raha@altostrat.com",
    ]
  }
}

resource "google_bigquery_table_iam_policy" "policy" {
  dataset_id  = google_bigquery_table.default.dataset_id
  table_id    = google_bigquery_table.default.table_id
  policy_data = data.google_iam_policy.default.policy_data
}





























고객 관리 암호화 키로 테이블 만들기

다음 예시에서는 mytable이라는 테이블을 만들고 google_kms_crypto_key [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/kms_crypto_key] 및 google_kms_key_ring [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/kms_key_ring] 리소스도 사용해서 테이블에 대해 Cloud Key Management Service 키 [https://cloud.google.com/bigquery/docs/customer-managed-encryption?hl=ko]를 지정합니다. 이 예시를 실행하기 전에 Cloud Key Management Service API를 사용 설정 [https://console.cloud.google.com/flows/enableapi?apiid=cloudkms.googleapis.com&%3Bredirect=https%3A%2F%2Fconsole.cloud.google.com&hl=ko]해야 합니다.






















  





  
    
  
  



















  




  



  


  resource "google_bigquery_dataset" "default" {
  dataset_id                      = "mydataset"
  default_partition_expiration_ms = 2592000000  # 30 days
  default_table_expiration_ms     = 31536000000 # 365 days
  description                     = "dataset description"
  location                        = "US"
  max_time_travel_hours           = 96 # 4 days

  labels = {
    billing_group = "accounting",
    pii           = "sensitive"
  }
}

resource "google_bigquery_table" "default" {
  dataset_id          = google_bigquery_dataset.default.dataset_id
  table_id            = "mytable"
  deletion_protection = false # set to "true" in production

  schema = <<EOF
[
  {
    "name": "ID",
    "type": "INT64",
    "mode": "NULLABLE",
    "description": "Item ID"
  },
  {
    "name": "Item",
    "type": "STRING",
    "mode": "NULLABLE"
  }
]
EOF

  encryption_configuration {
    kms_key_name = google_kms_crypto_key.crypto_key.id
  }

  depends_on = [google_project_iam_member.service_account_access]
}

resource "google_kms_crypto_key" "crypto_key" {
  name     = "example-key"
  key_ring = google_kms_key_ring.key_ring.id
}

resource "random_id" "default" {
  byte_length = 8
}

resource "google_kms_key_ring" "key_ring" {
  name     = "${random_id.default.hex}-example-keyring"
  location = "us"
}

# Enable the BigQuery service account to encrypt/decrypt Cloud KMS keys
data "google_project" "project" {
}

resource "google_project_iam_member" "service_account_access" {
  project = data.google_project.project.project_id
  role    = "roles/cloudkms.cryptoKeyEncrypterDecrypter"
  member  = "serviceAccount:bq-${data.google_project.project.number}@bigquery-encryption.iam.gserviceaccount.com"
}





























프로젝트에 Terraform 구성을 적용하려면 Google Cloud 다음 섹션의 단계를 완료하세요.
Cloud Shell 준비

  Cloud Shell [https://shell.cloud.google.com/?hl=ko]을 실행합니다.
  
    Terraform 구성을 적용할 기본 Google Cloud 프로젝트를 설정합니다.
    이 명령어는 프로젝트당 한 번만 실행하면 되며 어떤 디렉터리에서도 실행할 수 있습니다.
    export GOOGLE_CLOUD_PROJECT=PROJECT_ID
    Terraform 구성 파일에서 명시적 값을 설정하면 환경 변수가 재정의됩니다.
  

디렉터리 준비
각 Terraform 구성 파일에는 자체 디렉터리(루트 모듈이라고도 함)가 있어야 합니다.

  
    Cloud Shell [https://shell.cloud.google.com/?hl=ko]에서 디렉터리를 만들고 해당 디렉터리 내에 새 파일을 만드세요. 파일 이름에는 .tf 확장자가 있어야 합니다(예: main.tf). 이 튜토리얼에서는 파일을 main.tf라고 합니다.
    mkdir DIRECTORY && cd DIRECTORY && touch main.tf
  
  
    튜토리얼을 따라 하는 경우 각 섹션이나 단계에서 샘플 코드를 복사할 수 있습니다.
    샘플 코드를 새로 만든 main.tf에 복사합니다.
    필요한 경우 GitHub에서 코드를 복사합니다. 이는 Terraform 스니펫이 엔드 투 엔드 솔루션의 일부인 경우에 권장됩니다.
    
  
  환경에 적용할 샘플 파라미터를 검토하고 수정합니다.
  변경사항을 저장합니다.
  
    Terraform을 초기화합니다. 이 작업은 디렉터리당 한 번만 수행하면 됩니다.
    terraform init
    원하는 경우 최신 Google 공급업체 버전을 사용하려면 -upgrade 옵션을 포함합니다.
    
    terraform init -upgrade
  

변경사항 적용

  
    구성을 검토하고 Terraform에서 만들거나 업데이트할 리소스가 예상과 일치하는지 확인합니다.
    terraform plan
    필요에 따라 구성을 수정합니다.
  
  
    다음 명령어를 실행하고 프롬프트에 yes를 입력하여 Terraform 구성을 적용합니다.
    terraform apply
    Terraform에 '적용 완료' 메시지가 표시될 때까지 기다립니다.
  
  결과를 보려면 Google Cloud 프로젝트 [https://console.cloud.google.com/?hl=ko]를 엽니다. Google Cloud 콘솔에서 UI의 리소스로 이동하여 Terraform이 리소스를 만들었거나 업데이트했는지 확인합니다.
  

참고: Terraform 샘플은 일반적으로 필요한 API가 Google Cloud 프로젝트에서 사용 설정되었다고 가정합니다.

 API 테이블 리소스 [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables?hl=ko]가 정의된 tables.insert [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/insert?hl=ko] 메서드를 호출합니다.
 C# 









  
  
  
  





  
  
  
    
  




  



  









  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 C# 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery C# API 참고 문서 [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  
using Google.Cloud.BigQuery.V2 [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.html?hl=ko];

public class BigQueryCreateTable
{
    public BigQueryTable CreateTable(
        string projectId = "your-project-id",
        string datasetId = "your_dataset_id"
    )
    {
        BigQueryClient [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko] client = BigQueryClient [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko].Create [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko#Google_Cloud_BigQuery_V2_BigQueryClient_Create_System_String_Google_Apis_Auth_OAuth2_GoogleCredential_](projectId);
        var dataset = client.GetDataset [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko#Google_Cloud_BigQuery_V2_BigQueryClient_GetDataset_Google_Apis_Bigquery_v2_Data_DatasetReference_Google_Cloud_BigQuery_V2_GetDatasetOptions_](datasetId);
        // Create schema for new table.
        var schema = new TableSchemaBuilder [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.TableSchemaBuilder.html?hl=ko]
        {
            { "full_name", BigQueryDbType [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryDbType.html?hl=ko].String [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryDbType.html?hl=ko#Google_Cloud_BigQuery_V2_BigQueryDbType_String] },
            { "age", BigQueryDbType [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryDbType.html?hl=ko].Int64 [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryDbType.html?hl=ko#Google_Cloud_BigQuery_V2_BigQueryDbType_Int64] }
        }.Build();
        // Create the table
        return dataset.CreateTable(tableId: "your_table_id", schema: schema);
    }
}




























  
  



  
  
  
  
  
  
  
  
  
  

Go









  
  
  
  





  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Go 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Go API 참고 문서 [https://godoc.org/cloud.google.com/go/bigquery]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  import (
	"context"
	"fmt"
	"time"

	"cloud.google.com/go/bigquery"
)

// createTableExplicitSchema demonstrates creating a new BigQuery table and specifying a schema.
func createTableExplicitSchema(projectID, datasetID, tableID string) error {
	// projectID := "my-project-id"
	// datasetID := "mydatasetid"
	// tableID := "mytableid"
	ctx := context.Background()

	client, err := bigquery.NewClient(ctx, projectID)
	if err != nil {
		return fmt.Errorf("bigquery.NewClient: %v", err)
	}
	defer client.Close()

	sampleSchema := bigquery.Schema [https://cloud.google.com/go/docs/reference/cloud.google.com/go/bigquery/latest/index.html?hl=ko#cloud_google_com_go_bigquery_Schema]{
		{Name: "full_name", Type: bigquery.StringFieldType [https://cloud.google.com/go/docs/reference/cloud.google.com/go/bigquery/latest/index.html?hl=ko#cloud_google_com_go_bigquery_StringFieldType_BytesFieldType_IntegerFieldType_FloatFieldType_BooleanFieldType_TimestampFieldType_RecordFieldType_DateFieldType_TimeFieldType_DateTimeFieldType_NumericFieldType_GeographyFieldType_BigNumericFieldType_IntervalFieldType_JSONFieldType_RangeFieldType]},
		{Name: "age", Type: bigquery.IntegerFieldType [https://cloud.google.com/go/docs/reference/cloud.google.com/go/bigquery/latest/index.html?hl=ko#cloud_google_com_go_bigquery_StringFieldType_BytesFieldType_IntegerFieldType_FloatFieldType_BooleanFieldType_TimestampFieldType_RecordFieldType_DateFieldType_TimeFieldType_DateTimeFieldType_NumericFieldType_GeographyFieldType_BigNumericFieldType_IntervalFieldType_JSONFieldType_RangeFieldType]},
	}

	metaData := &bigquery.TableMetadata [https://cloud.google.com/go/docs/reference/cloud.google.com/go/bigquery/latest/index.html?hl=ko#cloud_google_com_go_bigquery_TableMetadata]{
		Schema:         sampleSchema,
		ExpirationTime: time.Now().AddDate(1, 0, 0), // Table will be automatically deleted in 1 year.
	}
	tableRef := client.Dataset(datasetID).Table(tableID)
	if err := tableRef.Create(ctx, metaData); err != nil {
		return err
	}
	return nil
}





























  
  



  
  
  
  
  
  
  
  
  
  

 Java 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Java 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Java API 참고 문서 [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/overview?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  import com.google.cloud.bigquery.BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko];
import com.google.cloud.bigquery.BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko];
import com.google.cloud.bigquery.BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko];
import com.google.cloud.bigquery.Field [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Field.html?hl=ko];
import com.google.cloud.bigquery.Schema [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Schema.html?hl=ko];
import com.google.cloud.bigquery.StandardSQLTypeName [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.StandardSQLTypeName.html?hl=ko];
import com.google.cloud.bigquery.StandardTableDefinition [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.StandardTableDefinition.html?hl=ko];
import com.google.cloud.bigquery.TableDefinition [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableDefinition.html?hl=ko];
import com.google.cloud.bigquery.TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko];
import com.google.cloud.bigquery.TableInfo [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableInfo.html?hl=ko];

public class CreateTable {

  public static void runCreateTable() {
    // TODO(developer): Replace these variables before running the sample.
    String datasetName = "MY_DATASET_NAME";
    String tableName = "MY_TABLE_NAME";
    Schema [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Schema.html?hl=ko] schema =
        Schema [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Schema.html?hl=ko].of(
            Field [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Field.html?hl=ko].of("stringField", StandardSQLTypeName [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.StandardSQLTypeName.html?hl=ko].STRING),
            Field [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Field.html?hl=ko].of("booleanField", StandardSQLTypeName [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.StandardSQLTypeName.html?hl=ko].BOOL));
    createTable(datasetName, tableName, schema);
  }

  public static void createTable(String datasetName, String tableName, Schema [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Schema.html?hl=ko] schema) {
    try {
      // Initialize client that will be used to send requests. This client only needs to be created
      // once, and can be reused for multiple requests.
      BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko] bigquery = BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko].getDefaultInstance().getService();

      TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko] tableId = TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko].of(datasetName, tableName);
      TableDefinition [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableDefinition.html?hl=ko] tableDefinition = StandardTableDefinition [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.StandardTableDefinition.html?hl=ko].of(schema);
      TableInfo [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableInfo.html?hl=ko] tableInfo = TableInfo [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableInfo.html?hl=ko].newBuilder(tableId, tableDefinition).build();

      bigquery.create [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko#com_google_cloud_bigquery_BigQuery_create_com_google_cloud_bigquery_DatasetInfo_com_google_cloud_bigquery_BigQuery_DatasetOption____](tableInfo);
      System.out.println("Table created successfully");
    } catch (BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko] e) {
      System.out.println("Table was not created. \n" + e.toString());
    }
  }
}




























  
  



  
  
  
  
  
  
  
  
  
  

 Node.js 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Node.js 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Node.js API 참고 문서 [https://googleapis.dev/nodejs/bigquery/latest/index.html]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  // Import the Google Cloud client library and create a client
const {BigQuery} = require('@google-cloud/bigquery [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/overview.html?hl=ko]');
const bigquery = new BigQuery [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/bigquery/bigquery.html?hl=ko]();

async function createTable() {
  // Creates a new table named "my_table" in "my_dataset".

  /**
   * TODO(developer): Uncomment the following lines before running the sample.
   */
  // const datasetId = "my_dataset";
  // const tableId = "my_table";
  // const schema = 'Name:string, Age:integer, Weight:float, IsMagic:boolean';

  // For all options, see https://cloud.google.com/bigquery/docs/reference/v2/tables#resource
  const options = {
    schema: schema,
    location: 'US',
  };

  // Create a new table in the dataset
  const [table] = await bigquery
    .dataset(datasetId)
    .createTable [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/bigquery/dataset.html?hl=ko](tableId, options);

  console.log(`Table ${table.id} created.`);
}




























  
  



  
  
  
  
  
  
  
  
  
  

PHP









  
  
  
  





  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 PHP 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery PHP API 참고 문서 [https://cloud.google.com/php/docs/reference/cloud-bigquery/latest/BigQueryClient?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  use Google\Cloud\BigQuery\BigQueryClient;

/** Uncomment and populate these variables in your code */
// $projectId = 'The Google project ID';
// $datasetId = 'The BigQuery dataset ID';
// $tableId = 'The BigQuery table ID';
// $fields = [
//    [
//        'name' => 'field1',
//        'type' => 'string',
//        'mode' => 'required'
//    ],
//    [
//        'name' => 'field2',
//        'type' => 'integer'
//    ],
//];

$bigQuery = new BigQueryClient([
    'projectId' => $projectId,
]);
$dataset = $bigQuery->dataset($datasetId);
$schema = ['fields' => $fields];
$table = $dataset->createTable($tableId, ['schema' => $schema]);
printf('Created table %s' . PHP_EOL, $tableId);




























  
  



  
  
  
  
  
  
  
  
  
  

 Python 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Python 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Python API 참고 문서 [https://cloud.google.com/python/docs/reference/bigquery/latest?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  from google.cloud import bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko]

# Construct a BigQuery client object.
client = bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko].Client [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client.html?hl=ko]()

# TODO(developer): Set table_id to the ID of the table to create.
# table_id = "your-project.your_dataset.your_table_name"

schema = [
    bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko].SchemaField [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.schema.SchemaField.html?hl=ko]("full_name", "STRING", mode="REQUIRED"),
    bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko].SchemaField [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.schema.SchemaField.html?hl=ko]("age", "INTEGER", mode="REQUIRED"),
]

table = bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko].Table [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.table.Table.html?hl=ko](table_id, schema=schema)
table = client.create_table [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client.html?hl=ko#google_cloud_bigquery_client_Client_create_table](table)  # Make an API request.
print(
    "Created table {}.{}.{}".format(table.project, table.dataset_id, table.table_id)
)




























  
  



  
  
  
  
  
  
  
  
  
  

 Ruby 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Ruby 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Ruby API 참고 문서 [https://googleapis.dev/ruby/google-cloud-bigquery/latest/Google/Cloud/Bigquery.html]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  require "google/cloud/bigquery"

def create_table dataset_id = "my_dataset"
  bigquery = Google::Cloud::Bigquery [https://cloud.google.com/ruby/docs/reference/google-cloud-bigquery-analytics_hub/latest/Google-Cloud-Bigquery.html?hl=ko].new [https://cloud.google.com/ruby/docs/reference/google-cloud-bigquery/latest/Google-Cloud-Bigquery.html?hl=ko]
  dataset  = bigquery.dataset dataset_id
  table_id = "my_table"

  table = dataset.create_table table_id do |updater|
    updater.string  "full_name", mode: :required
    updater.integer "age",       mode: :required
  end

  puts "Created table: #{table_id}"
end
스키마 정의가 없는 빈 테이블 만들기
--- 탭: Java [https://cloud.google.com/bigquery/docs/tables?hl=ko#java] ---
이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Java 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Java API 참고 문서 [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/overview?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  import com.google.cloud.bigquery.BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko];
import com.google.cloud.bigquery.BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko];
import com.google.cloud.bigquery.BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko];
import com.google.cloud.bigquery.Schema [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Schema.html?hl=ko];
import com.google.cloud.bigquery.StandardTableDefinition [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.StandardTableDefinition.html?hl=ko];
import com.google.cloud.bigquery.TableDefinition [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableDefinition.html?hl=ko];
import com.google.cloud.bigquery.TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko];
import com.google.cloud.bigquery.TableInfo [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableInfo.html?hl=ko];

// Sample to create a table without schema
public class CreateTableWithoutSchema {

  public static void main(String[] args) {
    // TODO(developer): Replace these variables before running the sample.
    String datasetName = "MY_DATASET_NAME";
    String tableName = "MY_TABLE_NAME";
    createTableWithoutSchema(datasetName, tableName);
  }

  public static void createTableWithoutSchema(String datasetName, String tableName) {
    try {
      // Initialize client that will be used to send requests. This client only needs to be created
      // once, and can be reused for multiple requests.
      BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko] bigquery = BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko].getDefaultInstance().getService();

      TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko] tableId = TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko].of(datasetName, tableName);
      TableDefinition [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableDefinition.html?hl=ko] tableDefinition = StandardTableDefinition [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.StandardTableDefinition.html?hl=ko].of(Schema [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Schema.html?hl=ko].of());
      TableInfo [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableInfo.html?hl=ko] tableInfo = TableInfo [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableInfo.html?hl=ko].newBuilder(tableId, tableDefinition).build();

      bigquery.create [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko#com_google_cloud_bigquery_BigQuery_create_com_google_cloud_bigquery_DatasetInfo_com_google_cloud_bigquery_BigQuery_DatasetOption____](tableInfo);
      System.out.println("Table created successfully");
    } catch (BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko] e) {
      System.out.println("Table was not created. \n" + e.toString());
    }
  }
}
쿼리 결과에서 테이블 만들기
쿼리 결과에서 테이블을 만들려면 결과를 대상 테이블에 써야 합니다.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/tables?hl=ko#%EC%BD%98%EC%86%94] ---
Google Cloud 콘솔에서 BigQuery 페이지를 엽니다.

BigQuery 페이지로 이동 [https://console.cloud.google.com/bigquery?hl=ko] 
탐색기 패널에서 프로젝트를 확장하고 데이터 세트를 선택합니다.
유효한 SQL 쿼리를 입력하세요.
더보기를 클릭한 다음 쿼리 옵션을 선택합니다.

 
쿼리 결과의 대상 테이블 설정 옵션을 선택합니다.

 
대상 섹션에서 테이블을 만들 데이터 세트를 선택한 다음 테이블 ID를 선택합니다.
대상 테이블 쓰기 환경설정 섹션에서 다음 중 하나를 선택합니다.


비어 있으면 쓰기 — 테이블이 비어 있는 경우에만 쿼리 결과를 테이블에 씁니다.
테이블에 추가 — 쿼리 결과를 기존 테이블에 추가합니다.
테이블 덮어쓰기 — 쿼리 결과를 사용하여 기존 테이블을 같은 이름으로 덮어씁니다.

(선택사항) 데이터 위치에서 해당 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]를 선택합니다.
쿼리 설정을 업데이트하려면 저장을 클릭합니다.
실행을 클릭합니다. 그러면 지정한 테이블에 쿼리 결과를 쓰는 쿼리 작업이 생성됩니다.


또는 쿼리를 실행하기 전에 대상 테이블 지정을 잊은 경우 편집기 위의 결과 저장 [https://cloud.google.com/bigquery/docs/tables?hl=ko#save-query-results] 버튼을 클릭하여 캐시된 결과 테이블을 영구 테이블에 복사할 수 있습니다.

--- 탭: SQL [https://cloud.google.com/bigquery/docs/tables?hl=ko#sql] ---
다음 예시에서는 CREATE TABLE 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#create_table_statement]을 사용하여 공개 bikeshare_trips 테이블의 데이터로부터 trips 테이블을 만듭니다.




 Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.

BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko] 
쿼리 편집기에서 다음 문을 입력합니다.

CREATE TABLE mydataset.trips AS (
  SELECT
    bike_id,
    start_time,
    duration_minutes
  FROM
    bigquery-public-data.austin_bikeshare.bikeshare_trips
);


play_circle 실행을 클릭합니다.




쿼리를 실행하는 방법에 대한 자세한 내용은 대화형 쿼리 실행 [https://cloud.google.com/bigquery/docs/running-queries?hl=ko#queries]을 참조하세요.

자세한 내용은 기존 테이블에서 새 테이블 만들기 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#creating_a_new_table_from_an_existing_table]를 참조하세요.

--- 탭: bq [https://cloud.google.com/bigquery/docs/tables?hl=ko#bq] ---
In the Google Cloud console, activate Cloud Shell.
    Activate Cloud Shell [https://console.cloud.google.com/?cloudshell=true&hl=ko]
    
      At the bottom of the Google Cloud console, a
      Cloud Shell [https://cloud.google.com/shell/docs/how-cloud-shell-works?hl=ko]
      session starts and displays a command-line prompt. Cloud Shell is a shell environment
      with the Google Cloud CLI
      already installed and with values already set for
      your current project. It can take a few seconds for the session to initialize.
    
    
  










bq query [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_query] 명령어를 입력하고 --destination_table 플래그를 지정하여 쿼리 결과에 기반한 영구 테이블을 만듭니다. GoogleSQL 문법을 사용하려면 use_legacy_sql=false 플래그를 지정합니다. 기본 프로젝트에 없는 테이블에 쿼리 결과를 쓰려면 프로젝트 ID를 project_id:dataset 형식으로 데이터 세트 이름에 추가합니다.

(선택사항) --location 플래그를 지정하고 값을 사용자 위치 [https://cloud.google.com/bigquery/docs/dataset-locations?hl=ko]로 설정합니다.

기존 대상 테이블의 쓰기 처리를 제어하려면 다음 플래그 옵션 중 하나를 지정합니다.


--append_table: 대상 테이블이 있으면 쿼리 결과가 테이블에 추가됩니다.
--replace: 대상 테이블이 있으면 쿼리 결과로 테이블을 덮어씁니다.

bq --location=location query \
--destination_table project_id:dataset.table \
--use_legacy_sql=false 'query'

다음을 바꿉니다.
location은 쿼리 처리에 사용되는 위치의 이름입니다. --location 플래그는 선택사항입니다. 예를 들어 도쿄 리전에서 BigQuery를 사용하는 경우에는 플래그 값을 asia-northeast1로 설정하면 됩니다. .bigqueryrc 파일 [https://cloud.google.com/bigquery/docs/bq-command-line-tool?hl=ko#setting_default_values_for_command-line_flags]을 사용하여 위치 기본값을 설정할 수 있습니다.
project_id는 프로젝트 ID입니다.
dataset는 쿼리 결과를 쓸 테이블이 포함된 데이터 세트의 이름입니다.
table은 쿼리 결과를 쓸 테이블의 이름입니다.
query는 GoogleSQL 문법의 쿼리입니다.

쓰기 처리 플래그를 지정하지 않으면 비어 있는 경우에만 테이블에 결과를 쓰는 것이 기본 동작입니다. 테이블이 있지만 비어 있지 않으면 다음 오류가 반환됩니다.
BigQuery error in query operation: Error processing job
project_id:bqjob_123abc456789_00000e1234f_1: Already
Exists: Table project_id:dataset.table.

예를 들면 다음과 같습니다.
참고: 이 예시에서는 미국 기반의 공개 데이터 세트를 쿼리합니다. 공개 데이터 세트가 미국의 멀티 리전 위치에 저장되기 때문에, 대상 테이블을 포함하는 데이터 세트도 미국에 있어야 합니다. 한 위치에서 데이터 세트를 쿼리하고 결과를 다른 위치에 있는 대상 테이블에 기록할 수는 없습니다.
mydataset에 있는 mytable이라는 대상 테이블에 쿼리 결과를 쓰려면 다음 명령어를 입력합니다. 데이터 세트는 기본 프로젝트에 있습니다.
명령어에 쓰기 처리 플래그가 지정되지 않았으므로 테이블은 새 테이블이거나 비어 있어야 합니다. 그렇지 않으면 Already exists 오류가 반환됩니다. 쿼리는 USA Name Data 공개 데이터 세트 [https://console.cloud.google.com/marketplace/product/social-security-administration/us-names?hl=ko]에서 데이터를 검색합니다.

bq query [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_query] \
--destination_table mydataset.mytable \
--use_legacy_sql=false \
'SELECT
name,
number
FROM
`bigquery-public-data`.usa_names.usa_1910_current
WHERE
gender = "M"
ORDER BY
number DESC'

쿼리 결과를 사용하여 mydataset에 있는 mytable이라는 대상 테이블을 덮어쓰려면 다음 명령어를 입력합니다. 데이터 세트는 기본 프로젝트에 있습니다. 이 명령어는 --replace 플래그를 사용하여 대상 테이블을 덮어씁니다.

bq query [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_query] \
--destination_table mydataset.mytable \
--replace \
--use_legacy_sql=false \
'SELECT
name,
number
FROM
`bigquery-public-data`.usa_names.usa_1910_current
WHERE
gender = "M"
ORDER BY
number DESC'

mydataset에 있는 mytable이라는 대상 테이블에 쿼리 결과를 추가하려면 다음 명령어를 입력합니다. 데이터 세트는 기본 프로젝트가 아닌 my-other-project에 있습니다. 이 명령어는 --append_table 플래그를 사용하여 쿼리 결과를 대상 테이블에 추가합니다.

bq query [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_query] \
--append_table \
--use_legacy_sql=false \
--destination_table my-other-project:mydataset.mytable \
'SELECT
name,
number
FROM
`bigquery-public-data`.usa_names.usa_1910_current
WHERE
gender = "M"
ORDER BY
number DESC'

이러한 각 예시의 출력은 다음과 같습니다. 읽기 편하도록 출력 일부는 잘려 있습니다.

Waiting on bqjob_r123abc456_000001234567_1 ... (2s) Current status: DONE
+---------+--------+
|  name   | number |
+---------+--------+
| Robert  |  10021 |
| John    |   9636 |
| Robert  |   9297 |
| ...              |
+---------+--------+




  



  
  
  
  
  
  
  
  
  
  





 API 














  




  









  
    
  





  
  
  
  

쿼리 결과를 영구 테이블에 저장하려면 jobs.insert [https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/insert?hl=ko] 메서드를 호출하고, query 작업을 구성하고, destinationTable 속성의 값을 포함합니다. 기존 대상 테이블의 쓰기 처리를 제어하려면 writeDisposition 속성을 구성합니다.

쿼리 작업의 처리 위치를 제어하려면 작업 리소스 [https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs?hl=ko]의 jobReference 섹션에 location 속성을 지정합니다.


  



  
  
  
  
  
  
  
  
  
  




Go














  
  
    
  




  



  







  
    
  





  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Go 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Go API 참고 문서 [https://godoc.org/cloud.google.com/go/bigquery]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  






















  





  
    
  
  











  









  




  



  


  import (
	"context"
	"fmt"
	"io"

	"cloud.google.com/go/bigquery"
	"google.golang.org/api/iterator"
)

// queryWithDestination demonstrates saving the results of a query to a specific table by setting the destination
// via the API properties.
func queryWithDestination(w io.Writer, projectID, destDatasetID, destTableID string) error {
	// projectID := "my-project-id"
	// datasetID := "mydataset"
	// tableID := "mytable"
	ctx := context.Background()
	client, err := bigquery.NewClient(ctx, projectID)
	if err != nil {
		return fmt.Errorf("bigquery.NewClient: %v", err)
	}
	defer client.Close()

	q := client.Query("SELECT 17 as my_col")
	q.Location [https://cloud.google.com/go/docs/reference/cloud.google.com/go/bigquery/latest/index.html?hl=ko#cloud_google_com_go_bigquery_Job_Location] = "US" // Location must match the dataset(s) referenced in query.
	q.QueryConfig [https://cloud.google.com/go/docs/reference/cloud.google.com/go/bigquery/latest/index.html?hl=ko#cloud_google_com_go_bigquery_QueryConfig].Dst = client.Dataset(destDatasetID).Table(destTableID)
	// Run the query and print results when the query job is completed.
	job, err := q.Run(ctx)
	if err != nil {
		return err
	}
	status, err := job.Wait(ctx)
	if err != nil {
		return err
	}
	if err := status.Err [https://cloud.google.com/go/docs/reference/cloud.google.com/go/bigquery/latest/index.html?hl=ko#cloud_google_com_go_bigquery_JobStatus_Err](); err != nil {
		return err
	}
	it, err := job.Read(ctx)
	for {
		var row []bigquery.Value [https://cloud.google.com/go/docs/reference/cloud.google.com/go/bigquery/latest/index.html?hl=ko#cloud_google_com_go_bigquery_Value]
		err := it.Next(&row)
		if err == iterator.Done {
			break
		}
		if err != nil {
			return err
		}
		fmt.Fprintln(w, row)
	}
	return nil
}






























  



  
  
  
  
  
  
  
  
  
  




Java














  
  
  
    
  




  



  







  
    
  





  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Java 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Java API 참고 문서 [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/overview?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  

쿼리 결과를 영구 테이블에 저장하려면 QueryJobConfiguration [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.QueryJobConfiguration?hl=ko]에서 대상 테이블 [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.QueryJobConfiguration.Builder?hl=ko#com_google_cloud_bigquery_QueryJobConfiguration_Builder_setDestinationTable_com_google_cloud_bigquery_TableId_]을 원하는 TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId?hl=ko]로 설정합니다.






















  
  
  
  





  
    
  
  











  









  




  




  import com.google.cloud.bigquery.BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko];
import com.google.cloud.bigquery.BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko];
import com.google.cloud.bigquery.BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko];
import com.google.cloud.bigquery.QueryJobConfiguration [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.QueryJobConfiguration.html?hl=ko];
import com.google.cloud.bigquery.TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko];

public class SaveQueryToTable {

  public static void runSaveQueryToTable() {
    // TODO(developer): Replace these variables before running the sample.
    String query = "SELECT corpus FROM `bigquery-public-data.samples.shakespeare` GROUP BY corpus;";
    String destinationTable = "MY_TABLE";
    String destinationDataset = "MY_DATASET";

    saveQueryToTable(destinationDataset, destinationTable, query);
  }

  public static void saveQueryToTable(
      String destinationDataset, String destinationTableId, String query) {
    try {
      // Initialize client that will be used to send requests. This client only needs to be created
      // once, and can be reused for multiple requests.
      BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko] bigquery = BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko].getDefaultInstance().getService();

      // Identify the destination table
      TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko] destinationTable = TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko].of(destinationDataset, destinationTableId);

      // Build the query job
      QueryJobConfiguration [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.QueryJobConfiguration.html?hl=ko] queryConfig =
          QueryJobConfiguration [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.QueryJobConfiguration.html?hl=ko].newBuilder(query).setDestinationTable(destinationTable).build();

      // Execute the query.
      bigquery.query [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko#com_google_cloud_bigquery_BigQuery_query_com_google_cloud_bigquery_QueryJobConfiguration_com_google_cloud_bigquery_BigQuery_JobOption____](queryConfig);

      // The results are now saved in the destination table.

      System.out.println("Saved query ran successfully");
    } catch (BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko] | InterruptedException e) {
      System.out.println("Saved query did not run \n" + e.toString());
    }
  }
}





























  



  
  
  
  
  
  
  
  
  
  




 Node.js 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Node.js 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Node.js API 참고 문서 [https://googleapis.dev/nodejs/bigquery/latest/index.html]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  // Import the Google Cloud client library
const {BigQuery} = require('@google-cloud/bigquery [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/overview.html?hl=ko]');
const bigquery = new BigQuery [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/bigquery/bigquery.html?hl=ko]();

async function queryDestinationTable() {
  // Queries the U.S. given names dataset for the state of Texas
  // and saves results to permanent table.

  /**
   * TODO(developer): Uncomment the following lines before running the sample.
   */
  // const datasetId = 'my_dataset';
  // const tableId = 'my_table';

  // Create destination table reference
  const dataset = bigquery.dataset(datasetId);
  const destinationTable = dataset.table(tableId);

  const query = `SELECT name
    FROM \`bigquery-public-data.usa_names.usa_1910_2013\`
    WHERE state = 'TX'
    LIMIT 100`;

  // For all options, see https://cloud.google.com/bigquery/docs/reference/v2/tables#resource
  const options = {
    query: query,
    // Location must match that of the dataset(s) referenced in the query.
    location: 'US',
    destination: destinationTable,
  };

  // Run the query as a job
  const [job] = await bigquery.createQueryJob(options);

  console.log(`Job ${job [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/bigquery/bigquery.html?hl=ko].id} started.`);
  console.log(`Query results loaded to table ${destinationTable.id}`);
}




























  
  



  
  
  
  
  
  
  
  
  
  

Python










  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Python 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Python API 참고 문서 [https://cloud.google.com/python/docs/reference/bigquery/latest?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
    
쿼리 결과를 영구 테이블에 저장하려면 QueryJobConfig [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.job.QueryJob?hl=ko#google_cloud_bigquery_job_QueryJob]를 만들고 대상 [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.job.QueryJob?hl=ko#google_cloud_bigquery_job_QueryJob_destination]을 원하는 TableReference [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.table.TableReference?hl=ko]로 설정합니다.
작업 구성을 쿼리 메서드 [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client?hl=ko#google_cloud_bigquery_client_Client_query]에 전달합니다.

  
  
  




















  





  
    
  
  











  









  




  



  


  from google.cloud import bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko]

# Construct a BigQuery client object.
client = bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko].Client [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client.html?hl=ko]()

# TODO(developer): Set table_id to the ID of the destination table.
# table_id = "your-project.your_dataset.your_table_name"

job_config = bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko].QueryJobConfig [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.job.QueryJobConfig.html?hl=ko](destination=table_id)

sql = """
    SELECT corpus
    FROM `bigquery-public-data.samples.shakespeare`
    GROUP BY corpus;
"""

# Start the query, passing in the extra configuration.
query_job = client.query [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client.html?hl=ko](sql, job_config=job_config)  # Make an API request.
query_job [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.dbapi.Cursor.html?hl=ko#google_cloud_bigquery_dbapi_Cursor_query_job].result()  # Wait for the job to complete.

print("Query results loaded to the table {}".format(table_id))
외부 데이터 소스를 참조하는 테이블 만들기
외부 데이터 소스는 데이터가 BigQuery 스토리지에 저장되어 있지 않더라도 BigQuery에서 직접 쿼리할 수 있는 데이터 소스입니다. 예를 들어 다른 Google Cloud 데이터베이스, Cloud Storage의 파일 또는 다른 클라우드 제품에 BigQuery에서 분석하려는 데이터가 있는데 마이그레이션 준비가 되지 않았을 수 있습니다.
자세한 내용은 외부 데이터 소스 소개 [https://cloud.google.com/bigquery/external-data-sources?hl=ko]를 참조하세요.
데이터 로드 시 테이블 만들기
BigQuery로 데이터를 로드할 때 데이터를 새 테이블 또는 파티션으로 로드할 수도 있고, 데이터를 기존 테이블 또는 파티션에 추가할 수도 있으며, 테이블 또는 파티션을 덮어쓸 수도 있습니다. 데이터를 로드하기 전에 빈 테이블을 만들지 않아도 됩니다. 새 테이블을 만들면서 동시에 데이터를 로드할 수 있습니다.
데이터를 BigQuery로 로드하면 테이블 또는 파티션 스키마를 제공할 수 있으며, 지원되는 데이터 형식인 경우에는 스키마 자동 감지 [https://cloud.google.com/bigquery/docs/schema-detect?hl=ko]를 사용할 수 있습니다.
데이터 로드에 대한 자세한 내용은 BigQuery로 데이터 로드 소개 [https://cloud.google.com/bigquery/docs/loading-data?hl=ko]를 참조하세요.
테이블에 대한 액세스 제어
테이블 및 뷰에 대한 액세스를 구성하려면 허용되는 리소스 범위 순서(가장 큰 크기부터 가장 작은 크기 순서)대로 나열된 다음 수준의 항목에 IAM 역할을 부여하면 됩니다.
Google Cloud 리소스 계층 구조 [https://cloud.google.com/resource-manager/docs/cloud-platform-resource-hierarchy?hl=ko]의 상위 수준(예: 프로젝트, 폴더 또는 조직 수준)
데이터 세트 수준
테이블 또는 보기 수준
다음 방법을 사용해서 테이블 내에서 데이터 액세스를 제한할 수도 있습니다.
열 수준 보안 [https://cloud.google.com/bigquery/docs/column-level-security-intro?hl=ko]
열 데이터 마스킹 [https://cloud.google.com/bigquery/docs/column-data-masking-intro?hl=ko]
행 수준 보안 [https://cloud.google.com/bigquery/docs/row-level-security-intro?hl=ko]
IAM으로 보호되는 모든 리소스에 대한 액세스 권한은 적층식입니다. 예를 들어 항목이 프로젝트와 같은 높은 수준에서 액세스할 수 없는 경우 데이터 세트 수준에서 항목에 액세스 권한을 부여하면 해당 항목에서 데이터 세트의 테이블과 뷰에 액세스할 수 있습니다. 마찬가지로, 항목이 높은 수준 또는 데이터 세트 수준에서 액세스할 수 없는 경우 테이블 또는 뷰 수준에서 항목에 액세스 권한을 부여할 수 있습니다.
프로젝트, 폴더 또는 조직 수준과 같이 Google Cloud리소스 계층 구조 [https://cloud.google.com/resource-manager/docs/cloud-platform-resource-hierarchy?hl=ko]의 상위 수준에서 IAM 역할을 부여하면 포괄적인 리소스 집합에 대한 액세스 권한이 항목에 부여됩니다. 예를 들어 프로젝트 수준에서 항목에 역할을 부여하면 프로젝트의 모든 데이터 세트에 적용되는 권한이 항목에 부여됩니다.
데이터 세트 수준에서 역할을 부여하면 항목이 상위 수준에서 액세스할 수 없는 경우에도 특정 데이터 세트의 테이블과 뷰에서 항목이 수행할 수 있는 작업이 지정됩니다. 데이터 세트 수준의 액세스 권한 제어 구성에 대한 자세한 내용은 데이터 세트에 대한 액세스 제어 [https://cloud.google.com/bigquery/docs/dataset-access-controls?hl=ko]를 참조하세요.
테이블 또는 뷰 수준에서 역할을 부여하면 항목이 상위 수준에서 액세스할 수 없는 경우에도 테이블과 뷰에서 항목이 수행할 수 있는 작업이 지정됩니다. 테이블 수준의 액세스 권한 제어 구성에 대한 자세한 내용은 테이블 및 뷰에 대한 액세스 제어 [https://cloud.google.com/bigquery/docs/table-access-controls?hl=ko]를 참조하세요.
IAM 커스텀 역할 [https://cloud.google.com/iam/docs/creating-custom-roles?hl=ko]을 만들 수도 있습니다. 커스텀 역할을 만들 경우 항목이 수행하도록 하려는 특정 작업에 따라 권한을 부여합니다.
IAM으로 보호되는 리소스에는 '거부' 권한을 설정할 수 없습니다.
역할 및 권한에 대한 자세한 내용은 IAM 문서의 역할 이해 [https://cloud.google.com/iam/docs/understanding-roles?hl=ko] 및 BigQuery IAM 역할 및 권한 [https://cloud.google.com/bigquery/docs/access-control?hl=ko]을 참조하세요.
테이블에 대한 정보 가져오기
다음 방법으로 테이블에 대한 정보 또는 메타데이터를 가져올 수 있습니다.
Google Cloud 콘솔 사용
bq 명령줄 도구 bq show [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_show] 명령어 사용
tables.get [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/get?hl=ko] API 메서드 호출
클라이언트 라이브러리 사용
INFORMATION_SCHEMA.VIEWS [https://cloud.google.com/bigquery/docs/information-schema-views?hl=ko] 뷰 쿼리
필수 권한
테이블에 대한 정보를 가져오려면 최소한 bigquery.tables.get 권한이 부여되어 있어야 합니다. 다음과 같은 사전 정의된 IAM 역할에는 bigquery.tables.get 권한이 포함되어 있습니다.
bigquery.metadataViewer
bigquery.dataViewer
bigquery.dataOwner
bigquery.dataEditor
bigquery.admin
또한 bigquery.datasets.create 권한이 있는 사용자는 데이터 세트를 만들 때 해당 데이터 세트에 대한 bigquery.dataOwner 액세스 권한을 부여받습니다. bigquery.dataOwner 액세스 권한이 있으면 사용자가 테이블 메타데이터를 검색할 수 있습니다.
BigQuery의 IAM 역할과 권한에 대한 자세한 내용은 액세스 제어 [https://cloud.google.com/bigquery/access-control?hl=ko]를 참조하세요.
테이블 정보 가져오기
테이블에 대한 정보를 가져오려면 다음과 같이 하세요.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/tables?hl=ko#%EC%BD%98%EC%86%94] ---
탐색 패널의 리소스 섹션에서 프로젝트를 펼친 후 데이터 세트를 선택합니다.
데이터 세트 이름을 클릭하여 펼칩니다. 데이터 세트의 테이블과 뷰가 표시됩니다.
테이블 이름을 클릭합니다.
세부정보 패널에서 세부정보를 클릭하여 테이블 설명과 테이블 정보를 표시합니다.
선택적으로 스키마 탭으로 전환하여 테이블의 스키마 정의를 봅니다.

--- 탭: bq [https://cloud.google.com/bigquery/docs/tables?hl=ko#bq] ---
In the Google Cloud console, activate Cloud Shell.
    Activate Cloud Shell [https://console.cloud.google.com/?cloudshell=true&hl=ko]
    
      At the bottom of the Google Cloud console, a
      Cloud Shell [https://cloud.google.com/shell/docs/how-cloud-shell-works?hl=ko]
      session starts and displays a command-line prompt. Cloud Shell is a shell environment
      with the Google Cloud CLI
      already installed and with values already set for
      your current project. It can take a few seconds for the session to initialize.
    
    
  










bq show [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_show] 명령어를 실행하여 모든 테이블 정보를 표시합니다. 테이블 스키마 정보만 표시하려면 --schema 플래그를 사용합니다. --format 플래그를 사용하면 출력을 제어할 수 있습니다.

기본 프로젝트가 아닌 프로젝트의 테이블에 대한 정보를 가져오려면 프로젝트 ID를 project_id:dataset 형식으로 데이터 세트에 추가합니다.

bq show [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_show] \
--schema \
--format=prettyjson \
project_id:dataset.table

각 항목의 의미는 다음과 같습니다.


project_id는 프로젝트 ID입니다.
dataset는 데이터 세트 이름입니다.
table은 테이블의 이름입니다.


예를 들면 다음과 같습니다.

다음 명령어를 입력하여 mydataset의 mytable 관련 정보를 모두 표시합니다. mydataset는 기본 프로젝트에 있습니다.

bq show [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_show] --format=prettyjson mydataset.mytable

다음 명령어를 입력하여 mydataset의 mytable 관련 정보를 모두 표시합니다. mydataset는 기본 프로젝트가 아닌 myotherproject에 있습니다.

bq show [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_show] --format=prettyjson myotherproject:mydataset.mytable

mydataset의 mytable 관련 스키마 정보만 표시하려면 다음 명령어를 입력합니다. mydataset는 기본 프로젝트가 아닌 myotherproject에 있습니다.

bq show [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_show] --schema --format=prettyjson myotherproject:mydataset.mytable

 API tables.get [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/get?hl=ko] 메서드를 호출하고 관련 매개변수를 모두 제공합니다.
Go









  
  
  
  





  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Go 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Go API 참고 문서 [https://godoc.org/cloud.google.com/go/bigquery]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  import (
	"context"
	"fmt"
	"io"

	"cloud.google.com/go/bigquery"
)

// printTableInfo demonstrates fetching metadata from a table and printing some basic information
// to an io.Writer.
func printTableInfo(w io.Writer, projectID, datasetID, tableID string) error {
	// projectID := "my-project-id"
	// datasetID := "mydataset"
	// tableID := "mytable"
	ctx := context.Background()
	client, err := bigquery.NewClient(ctx, projectID)
	if err != nil {
		return fmt.Errorf("bigquery.NewClient: %v", err)
	}
	defer client.Close()

	meta, err := client.Dataset(datasetID).Table(tableID).Metadata(ctx)
	if err != nil {
		return err
	}
	// Print basic information about the table.
	fmt.Fprintf(w, "Schema has %d top-level fields\n", len(meta.Schema [https://cloud.google.com/go/docs/reference/cloud.google.com/go/bigquery/latest/index.html?hl=ko#cloud_google_com_go_bigquery_Schema]))
	fmt.Fprintf(w, "Description: %s\n", meta.Description)
	fmt.Fprintf(w, "Rows in managed storage: %d\n", meta.NumRows)
	return nil
}





























  
  



  
  
  
  
  
  
  
  
  
  

 Java 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Java 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Java API 참고 문서 [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/overview?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  import com.google.cloud.bigquery.BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko];
import com.google.cloud.bigquery.BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko];
import com.google.cloud.bigquery.BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko];
import com.google.cloud.bigquery.Table [https://cloud.google.com/java/docs/reference/google-cloud-biglake/latest/com.google.cloud.bigquery.biglake.v1.Table.html?hl=ko];
import com.google.cloud.bigquery.TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko];

public class GetTable {

  public static void runGetTable() {
    // TODO(developer): Replace these variables before running the sample.
    String projectId = "bigquery_public_data";
    String datasetName = "samples";
    String tableName = "shakespeare";
    getTable(projectId, datasetName, tableName);
  }

  public static void getTable(String projectId, String datasetName, String tableName) {
    try {
      // Initialize client that will be used to send requests. This client only needs to be created
      // once, and can be reused for multiple requests.
      BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko] bigquery = BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko].getDefaultInstance().getService();

      TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko] tableId = TableId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.TableId.html?hl=ko].of(projectId, datasetName, tableName);
      Table [https://cloud.google.com/java/docs/reference/google-cloud-biglake/latest/com.google.cloud.bigquery.biglake.v1.Table.html?hl=ko] table = bigquery.getTable [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko#com_google_cloud_bigquery_BigQuery_getTable_com_google_cloud_bigquery_TableId_com_google_cloud_bigquery_BigQuery_TableOption____](tableId);
      System.out.println("Table info: " + table.getDescription());
    } catch (BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko] e) {
      System.out.println("Table not retrieved. \n" + e.toString());
    }
  }
}




























  
  



  
  
  
  
  
  
  
  
  
  

 Node.js 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Node.js 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Node.js API 참고 문서 [https://googleapis.dev/nodejs/bigquery/latest/index.html]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  // Import the Google Cloud client library
const {BigQuery} = require('@google-cloud/bigquery [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/overview.html?hl=ko]');
const bigquery = new BigQuery [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/bigquery/bigquery.html?hl=ko]();

async function getTable() {
  // Retrieves table named "my_table" in "my_dataset".

  /**
   * TODO(developer): Uncomment the following lines before running the sample
   */
  // const datasetId = "my_dataset";
  // const tableId = "my_table";

  // Retrieve table reference
  const dataset = bigquery.dataset(datasetId);
  const [table] = await dataset.table(tableId).get();

  console.log('Table:');
  console.log(table.metadata.tableReference);
}
getTable();




























  
  



  
  
  
  
  
  
  
  
  
  

PHP









  
  
  
  





  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 PHP 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery PHP API 참고 문서 [https://cloud.google.com/php/docs/reference/cloud-bigquery/latest/BigQueryClient?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  use Google\Cloud\BigQuery\BigQueryClient;

/** Uncomment and populate these variables in your code */
//$projectId = 'The Google project ID';
//$datasetId = 'The BigQuery dataset ID';
//$tableId   = 'The BigQuery table ID';

$bigQuery = new BigQueryClient([
    'projectId' => $projectId,
]);
$dataset = $bigQuery->dataset($datasetId);
$table = $dataset->table($tableId);




























  
  



  
  
  
  
  
  
  
  
  
  

 Python 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Python 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Python API 참고 문서 [https://cloud.google.com/python/docs/reference/bigquery/latest?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  
from google.cloud import bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko]

# Construct a BigQuery client object.
client = bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko].Client [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client.html?hl=ko]()

# TODO(developer): Set table_id to the ID of the model to fetch.
# table_id = 'your-project.your_dataset.your_table'

table = client.get_table [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client.html?hl=ko#google_cloud_bigquery_client_Client_get_table](table_id)  # Make an API request.

# View table properties
print(
    "Got table '{}.{}.{}'.".format(table.project, table.dataset_id, table.table_id)
)
print("Table schema: {}".format(table.schema))
print("Table description: {}".format(table.description))
print("Table has {} rows".format(table.num_rows [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.table.Table.html?hl=ko#google_cloud_bigquery_table_Table_num_rows]))
INFORMATION_SCHEMA를 사용하여 테이블 정보 가져오기
INFORMATION_SCHEMA는 데이터 세트, 루틴, 테이블, 뷰, 작업, 예약, 데이터 스트리밍에 대한 메타데이터에 액세스할 수 있는 일련의 뷰입니다.
다음 뷰를 쿼리하여 테이블 정보를 가져올 수 있습니다.
INFORMATION_SCHEMA.TABLES 및 INFORMATION_SCHEMA.TABLE_OPTIONS 뷰를 사용하여 프로젝트의 테이블 및 뷰에 대한 메타데이터를 가져옵니다.
INFORMATION_SCHEMA.COLUMNS 및 INFORMATION_SCHEMA.COLUMN_FIELD_PATHS 뷰를 사용하여 테이블의 열(필드)에 대한 메타데이터를 검색합니다.
INFORMATION_SCHEMA.TABLE_STORAGE 뷰를 사용하여 테이블별로 현재 및 이전 스토리지 사용량에 대한 메타데이터를 검색합니다.
TABLES 및 TABLE_OPTIONS 뷰에는 뷰에 대한 대략적인 정보도 포함되어 있습니다. 자세한 정보를 보려면 INFORMATION_SCHEMA.VIEWS [https://cloud.google.com/bigquery/docs/information-schema-views?hl=ko] 뷰를 대신 쿼리하세요.
TABLES 뷰
INFORMATION_SCHEMA.TABLES 뷰를 쿼리하면 데이터 세트의 각 테이블 또는 뷰당 하나의 행이 쿼리 결과에 포함됩니다. 뷰에 대한 자세한 내용은 INFORMATION_SCHEMA.VIEWS 뷰 [https://cloud.google.com/bigquery/docs/information-schema-views?hl=ko]를 대신 쿼리하세요.
INFORMATION_SCHEMA.TABLES 뷰에는 다음과 같은 스키마가 있습니다.
열 이름 데이터 유형 값
table_catalog STRING 데이터 세트가 포함된 프로젝트의 프로젝트 ID
table_schema STRING 테이블이나 뷰가 포함된 데이터 세트 이름(datasetId라고도 함)
table_name STRING 테이블 또는 뷰의 이름(tableId라고도 함)
table_type STRING 테이블 유형. 다음 중 하나입니다.
BASE TABLE: 표준 테이블 [https://cloud.google.com/bigquery/docs/tables-intro?hl=ko]
CLONE: 테이블 클론 [https://cloud.google.com/bigquery/docs/table-clones-intro?hl=ko]
SNAPSHOT: 테이블 스냅샷 [https://cloud.google.com/bigquery/docs/table-snapshots-intro?hl=ko]
VIEW: 뷰 [https://cloud.google.com/bigquery/docs/views-intro?hl=ko]
MATERIALIZED VIEW: 구체화된 뷰 [https://cloud.google.com/bigquery/docs/materialized-views-intro?hl=ko] 또는 구체화된 뷰 복제본 [https://cloud.google.com/bigquery/docs/materialized-views-intro?hl=ko#materialized_view_replicas]
EXTERNAL: 외부 데이터 소스 [https://cloud.google.com/bigquery/external-data-sources?hl=ko]를 참조하는 테이블
is_insertable_into STRING 테이블의 DML INSERT [https://cloud.google.com/bigquery/docs/reference/standard-sql/dml-syntax?hl=ko#insert_statement] 문 지원 여부에 따라 YES 또는 NO
is_fine_grained_mutations_enabled STRING 테이블에서 세분화된 DML 변형 [https://cloud.google.com/bigquery/docs/data-manipulation-language?hl=ko#enable_fine-grained_dml]이 사용 설정되어 있는지 여부에 따라 YES 또는 NO
is_typed STRING 값이 항상 NO임
is_change_history_enabled STRING 변경 내역 [https://cloud.google.com/bigquery/docs/change-history?hl=ko] 사용 설정 여부에 따라 YES 또는 NO
creation_time TIMESTAMP 테이블 생성 시간
base_table_catalog STRING 테이블 클론 [https://cloud.google.com/bigquery/docs/table-clones-intro?hl=ko] 및 테이블 스냅샷 [https://cloud.google.com/bigquery/docs/table-snapshots-intro?hl=ko]의 경우 기본 테이블의 프로젝트입니다. table_type이 CLONE 또는 SNAPSHOT으로 설정된 테이블에만 적용됩니다.
base_table_schema STRING 테이블 클론 [https://cloud.google.com/bigquery/docs/table-clones-intro?hl=ko] 및 테이블 스냅샷 [https://cloud.google.com/bigquery/docs/table-snapshots-intro?hl=ko]의 경우 기본 테이블의 데이터 세트입니다. table_type이 CLONE 또는 SNAPSHOT으로 설정된 테이블에만 적용됩니다.
base_table_name STRING 테이블 클론 [https://cloud.google.com/bigquery/docs/table-clones-intro?hl=ko] 및 테이블 스냅샷 [https://cloud.google.com/bigquery/docs/table-snapshots-intro?hl=ko]의 경우 기본 테이블의 이름입니다. table_type이 CLONE 또는 SNAPSHOT으로 설정된 테이블에만 적용됩니다.
snapshot_time_ms TIMESTAMP 테이블 클론 [https://cloud.google.com/bigquery/docs/table-clones-intro?hl=ko] 및 테이블 스냅샷 [https://cloud.google.com/bigquery/docs/table-snapshots-intro?hl=ko]의 경우 이 테이블을 만들기 위해 기본 테이블에서 클론 [https://cloud.google.com/bigquery/docs/table-clones-create?hl=ko] 또는 스냅샷 [https://cloud.google.com/bigquery/docs/table-snapshots-create?hl=ko] 작업이 실행된 시간입니다. 시간 이동 [https://cloud.google.com/bigquery/docs/time-travel?hl=ko]이 사용된 경우 이 필드에 시간 이동 타임스탬프가 포함됩니다. 그렇지 않으면 snapshot_time_ms 필드가 creation_time 필드와 동일합니다. table_type이 CLONE 또는 SNAPSHOT으로 설정된 테이블에만 적용됩니다.
replica_source_catalog STRING 구체화된 뷰 복제본 [https://cloud.google.com/bigquery/docs/materialized-views-intro?hl=ko#materialized_view_replicas]의 경우 기본 구체화된 뷰의 프로젝트입니다.
replica_source_schema STRING 구체화된 뷰 복제본 [https://cloud.google.com/bigquery/docs/materialized-views-intro?hl=ko#materialized_view_replicas]의 경우 기본 구체화된 뷰의 데이터 세트입니다.
replica_source_name STRING 구체화된 뷰 복제본 [https://cloud.google.com/bigquery/docs/materialized-views-intro?hl=ko#materialized_view_replicas]의 경우 기본 구체화된 뷰의 이름입니다.
replication_status STRING 구체화된 뷰 복제본 [https://cloud.google.com/bigquery/docs/materialized-views-intro?hl=ko#materialized_view_replicas]의 경우 기본 구체화된 뷰에서 구체화된 뷰 복제본으로의 복제 상태로, 다음 중 하나입니다.
REPLICATION_STATUS_UNSPECIFIED
ACTIVE: 오류 없이 복제가 활성 상태
SOURCE_DELETED: 소스 구체화된 뷰가 삭제됨
PERMISSION_DENIED: 구체화 뷰를 생성한 쿼리에 사용된 소스 Amazon S3 BigLake 테이블이 포함된 데이터 세트에 대해 소스 구체화 뷰가 승인 [https://cloud.google.com/bigquery/docs/authorized-views?hl=ko]되지 않았습니다.
UNSUPPORTED_CONFIGURATION: 소스 구체화된 뷰 승인 이외의 복제본 기본 요건 [https://cloud.google.com/bigquery/docs/materialized-view-replicas-create?hl=ko#prepare]에 문제가 있습니다.
replication_error STRING replication_status가 구체화된 뷰 복제본 [https://cloud.google.com/bigquery/docs/materialized-views-intro?hl=ko#materialized_view_replicas]의 복제 문제를 나타내는 경우 replication_error에서 문제에 대한 추가 세부정보를 제공합니다.
ddl STRING CREATE TABLE [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#create_table_statement] 또는 CREATE VIEW [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#create_view_statement]와 같은 테이블을 다시 만드는 데 사용할 수 있는 DDL 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko]
default_collation_name STRING 기본 콜레이션 사양 [https://cloud.google.com/bigquery/docs/reference/standard-sql/collation-concepts?hl=ko] 이름(있는 경우)입니다. 그 외의 경우는 NULL입니다.
upsert_stream_apply_watermark TIMESTAMP 변경 데이터 캡처(CDC)를 사용하는 테이블의 경우 행 수정이 마지막으로 적용된 시간입니다. 자세한 내용은 테이블 upsert 작업 진행률 모니터링 [https://cloud.google.com/bigquery/docs/change-data-capture?hl=ko#monitor_table_upsert_operation_progress]을 참조하세요.
예시
예시 1:
다음 예시에서는 이름이 mydataset인 데이터 세트에 있는 모든 테이블의 테이블 메타데이터를 검색합니다. 반환되는 메타데이터는 기본 프로젝트에서 mydataset에 있는 모든 테이블 유형에 사용됩니다.
mydataset에는 다음 테이블이 포함되어 있습니다.
mytable1: 표준 BigQuery 테이블
myview1: BigQuery 뷰
기본 프로젝트가 아닌 프로젝트에 쿼리를 실행하려면 프로젝트 ID를 `project_id`.dataset.INFORMATION_SCHEMA.view 형식으로 데이터 세트에 추가합니다(예: `myproject`.mydataset.INFORMATION_SCHEMA.TABLES).
참고: INFORMATION_SCHEMA 뷰 이름은 대소문자를 구분합니다.
SELECT
  table_catalog, table_schema, table_name, table_type,
  is_insertable_into, creation_time, ddl
FROM
  mydataset.INFORMATION_SCHEMA.TABLES;
결과는 다음과 비슷합니다. 가독성을 위해 일부 열은 결과에서 제외됩니다.
+----------------+---------------+----------------+------------+--------------------+---------------------+---------------------------------------------+
| table_catalog  | table_schema  |   table_name   | table_type | is_insertable_into |    creation_time    |                     ddl                     |
+----------------+---------------+----------------+------------+--------------------+---------------------+---------------------------------------------+
| myproject      | mydataset     | mytable1       | BASE TABLE | YES                | 2018-10-29 20:34:44 | CREATE TABLE `myproject.mydataset.mytable1` |
|                |               |                |            |                    |                     | (                                           |
|                |               |                |            |                    |                     |   id INT64                                  |
|                |               |                |            |                    |                     | );                                          |
| myproject      | mydataset     | myview1        | VIEW       | NO                 | 2018-12-29 00:19:20 | CREATE VIEW `myproject.mydataset.myview1`   |
|                |               |                |            |                    |                     | AS SELECT 100 as id;                        |
+----------------+---------------+----------------+------------+--------------------+---------------------+---------------------------------------------+
예시 2:
다음 예시에서는 INFORMATION_SCHEMA.TABLES 뷰에서 CLONE 또는 SNAPSHOT 유형의 모든 테이블에 대해 테이블 메타데이터를 검색합니다. 반환되는 메타데이터는 기본 프로젝트의 mydataset에 있는 테이블의 메타데이터입니다.
기본 프로젝트가 아닌 프로젝트에 쿼리를 실행하려면 프로젝트 ID를 `project_id`.dataset.INFORMATION_SCHEMA.view 형식으로 데이터 세트에 추가합니다(예: `myproject`.mydataset.INFORMATION_SCHEMA.TABLES).
  SELECT
    table_name, table_type, base_table_catalog,
    base_table_schema, base_table_name, snapshot_time_ms
  FROM
    mydataset.INFORMATION_SCHEMA.TABLES
  WHERE
    table_type = 'CLONE'
  OR
    table_type = 'SNAPSHOT';
결과는 다음과 비슷합니다. 가독성을 위해 일부 열은 결과에서 제외됩니다.
  +--------------+------------+--------------------+-------------------+-----------------+---------------------+
  | table_name   | table_type | base_table_catalog | base_table_schema | base_table_name | snapshot_time_ms    |
  +--------------+------------+--------------------+-------------------+-----------------+---------------------+
  | items_clone  | CLONE      | myproject          | mydataset         | items           | 2018-10-31 22:40:05 |
  | orders_bk    | SNAPSHOT   | myproject          | mydataset         | orders          | 2018-11-01 08:22:39 |
  +--------------+------------+--------------------+-------------------+-----------------+---------------------+
예 3:
다음 예시는 census_bureau_usa [https://console.cloud.google.com/bigquery?p=bigquery-public-data&%3Bd=census_bureau_usa&%3Bpage=dataset&hl=ko] 데이터 세트에 있는 population_by_zip_2010 테이블의 INFORMATION_SCHEMA.TABLES 뷰에서 table_name 및 ddl 열을 검색합니다. 이 데이터 세트는 BigQuery 공개 데이터 세트 프로그램 [https://cloud.google.com/public-datasets?hl=ko]의 일부입니다.
쿼리하려는 테이블이 다른 프로젝트에 있으므로 프로젝트 ID를 다음 형식으로 데이터 세트에 추가합니다. `project_id`.dataset.INFORMATION_SCHEMA.view 이 예시에서 값은 `bigquery-public-data`.census_bureau_usa.INFORMATION_SCHEMA.TABLES입니다.
SELECT
  table_name, ddl
FROM
  `bigquery-public-data`.census_bureau_usa.INFORMATION_SCHEMA.TABLES
WHERE
  table_name = 'population_by_zip_2010';
결과는 다음과 비슷합니다.
+------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|       table_name       |                                                                                                            ddl                                                                                                             |
+------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| population_by_zip_2010 | CREATE TABLE `bigquery-public-data.census_bureau_usa.population_by_zip_2010`                                                                                                                                               |
|                        | (                                                                                                                                                                                                                          |
|                        |   geo_id STRING OPTIONS(description="Geo code"),                                                                                                                                                                           |
|                        |   zipcode STRING NOT NULL OPTIONS(description="Five digit ZIP Code Tabulation Area Census Code"),                                                                                                                          |
|                        |   population INT64 OPTIONS(description="The total count of the population for this segment."),                                                                                                                             |
|                        |   minimum_age INT64 OPTIONS(description="The minimum age in the age range. If null, this indicates the row as a total for male, female, or overall population."),                                                          |
|                        |   maximum_age INT64 OPTIONS(description="The maximum age in the age range. If null, this indicates the row as having no maximum (such as 85 and over) or the row is a total of the male, female, or overall population."), |
|                        |   gender STRING OPTIONS(description="male or female. If empty, the row is a total population summary.")                                                                                                                    |
|                        | )                                                                                                                                                                                                                          |
|                        | OPTIONS(                                                                                                                                                                                                                   |
|                        |   labels=[("freebqcovid", "")]                                                                                                                                                                                             |
|                        | );                                                                                                                                                                                                                         |
+------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
  
TABLE_OPTIONS 뷰
INFORMATION_SCHEMA.TABLE_OPTIONS 뷰를 쿼리하면 쿼리 결과에 데이터 세트의 각 테이블이나 뷰의 옵션마다 행 하나가 포함됩니다. 뷰에 대한 자세한 내용을 확인하려면 대신 INFORMATION_SCHEMA.VIEWS 뷰 [https://cloud.google.com/bigquery/docs/information-schema-views?hl=ko]를 쿼리하세요.
INFORMATION_SCHEMA.TABLE_OPTIONS 뷰에는 다음과 같은 스키마가 있습니다.
열 이름 데이터 유형 값
TABLE_CATALOG STRING 데이터 세트가 포함된 프로젝트의 프로젝트 ID
TABLE_SCHEMA STRING 테이블이나 뷰가 포함된 데이터 세트 이름(또는 datasetId라고 함)
TABLE_NAME STRING 테이블 또는 뷰의 이름(또는 tableId라고 함)
OPTION_NAME STRING 옵션 표 [https://cloud.google.com/bigquery/docs/tables?hl=ko#options_table]의 이름 값 중 하나
OPTION_TYPE STRING 옵션 표 [https://cloud.google.com/bigquery/docs/tables?hl=ko#options_table]의 데이터 유형 값 중 하나
OPTION_VALUE STRING 옵션 표 [https://cloud.google.com/bigquery/docs/tables?hl=ko#options_table]의 값 옵션 중 하나
옵션 표
OPTION_NAME
OPTION_TYPE
OPTION_VALUE
description
STRING
테이블 설명
enable_refresh
BOOL
구체화된 뷰에 자동 새로고침이 사용 설정되었는지 여부
expiration_timestamp
TIMESTAMP
이 테이블이 만료되는 시간
friendly_name
STRING
테이블을 설명하는 이름
kms_key_name
STRING
테이블을 암호화하는 데 사용된 Cloud KMS 키의 이름
labels
ARRAY<STRUCT<STRING, STRING>>
테이블의 라벨을 나타내는 STRUCT 배열
max_staleness
INTERVAL
구성된 테이블의 BigQuery 변경 데이터 캡처(CDC) 삽입/업데이트(upsert) [https://cloud.google.com/bigquery/docs/change-data-capture?hl=ko#manage_table_staleness]의 최대 지연 시간
partition_expiration_days
FLOAT64
파티션을 나눈 테이블의 모든 파티션 기본 수명(일)
refresh_interval_minutes
FLOAT64
구체화된 뷰가 새로고침되는 빈도
require_partition_filter
BOOL
테이블에 대한 쿼리에 파티션 필터가 필요한지 여부
tags
ARRAY<STRUCT<STRING, STRING>>
네임스페이스화된 <키, 값> 문법의 테이블에 연결된 태그. 자세한 내용은 태그 및 조건부 액세스 [https://cloud.google.com/iam/docs/tags-access-control?hl=ko]를 참조하세요.
외부 테이블에 다음 옵션을 사용할 수 있습니다.
옵션
allow_jagged_rows
BOOL
true이면 뒤에 오는 선택적인 열이 누락된 행을 허용합니다.
CSV 데이터에 적용됩니다.
allow_quoted_newlines
BOOL
true이면 파일에서 따옴표 안에 줄바꿈 문자가 포함된 데이터 섹션을 허용합니다.
CSV 데이터에 적용됩니다.
bigtable_options
STRING
Bigtable 외부 테이블을 만들 때만 필요합니다.
Bigtable 외부 테이블의 스키마를 JSON 형식으로 지정합니다.
Bigtable 테이블 정의 옵션의 목록은 REST API 참조에서 BigtableOptions [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables?hl=ko#bigtableoptions]를 참조하세요.
column_name_character_map
STRING
지원되는 열 이름 문자 범위 및 지원되지 않는 문자의 처리 동작을 정의합니다. 기본 설정은 STRICT입니다. 즉, 지원되지 않는 문자가 있으면 BigQuery에서 오류가 발생합니다. V1 및 V2는 지원되지 않는 문자를 밑줄로 대체합니다.
지원되는 값은 다음과 같습니다.
STRICT. 유연한 열 이름 [https://cloud.google.com/bigquery/docs/schemas?hl=ko#flexible-column-names]을 사용 설정합니다. 기본값입니다. 열 이름에 지원되지 않는 문자가 포함된 작업을 로드하면 오류 메시지와 함께 실패합니다. 로드 작업이 성공하도록 지원되지 않는 문자를 밑줄로 바꾸도록 구성하려면 default_column_name_character_map [https://cloud.google.com/bigquery/docs/default-configuration?hl=ko#configuration_settings] 구성 설정을 지정합니다.
V1. 열 이름에는 표준 열 이름 문자 [https://cloud.google.com/bigquery/docs/schemas?hl=ko#column_names]만 포함할 수 있습니다. 지원되지 않는 문자(Parquet 파일 열 이름의 마침표 [https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet?hl=ko#limitations_2] 제외)는 밑줄로 대체됩니다. 이는 column_name_character_map이 도입되기 전에 생성된 테이블의 기본 동작입니다.
V2. 표준 열 이름 문자 [https://cloud.google.com/bigquery/docs/schemas?hl=ko#column_names] 외에도 유연한 열 이름 [https://cloud.google.com/bigquery/docs/schemas?hl=ko#flexible-column-names]도 지원합니다. 지원되지 않는 문자(Parquet 파일 열 이름의 마침표 [https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet?hl=ko#limitations_2] 제외)는 밑줄로 대체됩니다.
CSV 및 Parquet 데이터에 적용됩니다.
compression
STRING
데이터 소스의 압축 유형입니다. 지원되는 값은 GZIP입니다. 지정하지 않으면 데이터 소스는 압축되지 않습니다.
CSV 및 JSON 데이터에 적용됩니다.
decimal_target_types
ARRAY<STRING>
Decimal 유형을 변환하는 방법을 결정합니다. ExternalDataConfiguration.decimal_target_types [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables?hl=ko#ExternalDataConfiguration.FIELDS.decimal_target_types]와 동일합니다.
예: ["NUMERIC", "BIGNUMERIC"]
description
STRING
이 테이블에 대한 설명입니다.
enable_list_inference
BOOL
true이면 특히 Parquet LIST 논리 유형에 대해 스키마 추론을 사용합니다.
Parquet 데이터에 적용됩니다.
enable_logical_types
BOOL
true이면 Avro 논리 유형을 해당 SQL 유형으로 변환합니다. 자세한 내용은 논리 유형 [https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro?hl=ko#logical_types]을 참조하세요.
Avro 데이터에 적용됩니다.
encoding
STRING
데이터의 문자 인코딩입니다. 지원되는 값은 UTF8(또는 UTF-8), ISO_8859_1(또는 ISO-8859-1), UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE입니다. 기본값은 UTF-8입니다.
CSV 데이터에 적용됩니다.
enum_as_string
BOOL
true이면 기본적으로 BYTES 대신 Parquet ENUM 논리 유형을 STRING으로 추론합니다.
Parquet 데이터에 적용됩니다.
expiration_timestamp
TIMESTAMP
이 테이블이 만료되는 시간입니다. 지정하지 않으면 테이블이 만료되지 않습니다.
예: "2025-01-01 00:00:00 UTC"
field_delimiter
STRING
CSV 파일의 필드 구분 기호입니다.
CSV 데이터에 적용됩니다.
format
STRING
외부 데이터의 형식입니다. CREATE EXTERNAL TABLE [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#create_external_table_statement]의 지원 값으로는 AVRO, CLOUD_BIGTABLE, CSV, DATASTORE_BACKUP, DELTA_LAKE(미리보기 [https://cloud.google.com/products?hl=ko#product-launch-stages]), GOOGLE_SHEETS, NEWLINE_DELIMITED_JSON(또는 JSON), ORC, PARQUET 등이 있습니다.
LOAD DATA [https://cloud.google.com/bigquery/docs/reference/standard-sql/load-statements?hl=ko]의 지원 값으로는 AVRO, CSV, DELTA_LAKE(미리보기 [https://cloud.google.com/products?hl=ko#product-launch-stages]), NEWLINE_DELIMITED_JSON(또는 JSON), ORC, PARQUET 등이 있습니다.
값 JSON은 NEWLINE_DELIMITED_JSON과 동일합니다.
hive_partition_uri_prefix
STRING
파티션 키 인코딩이 시작되기 전에 모든 소스 URI의 공통 프리픽스입니다. 파티션을 나눈 하이브 외부 테이블에만 적용됩니다.
Avro, CSV, JSON, Parquet, ORC 데이터에 적용됩니다.
예: "gs://bucket/path"
file_set_spec_type
STRING
로드 작업 및 외부 테이블의 소스 URI를 해석하는 방법을 지정합니다.
지원되는 값은 다음과 같습니다.
FILE_SYSTEM_MATCH. 객체 스토어의 파일을 나열하여 소스 URI를 확장합니다. FileSetSpecType이 설정되지 않은 경우의 기본 동작입니다.
NEW_LINE_DELIMITED_MANIFEST. 제공된 URI가 줄바꿈으로 구분된 매니페스트 파일이며 한 줄에 URI가 하나씩 있음을 나타냅니다. 매니페스트 파일에서 와일드 카드 URI가 지원되지 않으며 모든 참조된 데이터 파일은 매니페스트 파일과 동일한 버킷에 있어야 합니다.
예를 들어 소스 URI가 "gs://bucket/path/file"이고 file_set_spec_type이 FILE_SYSTEM_MATCH인 경우 파일은 데이터 파일로 직접 사용됩니다. file_set_spec_type이 NEW_LINE_DELIMITED_MANIFEST면 파일의 각 줄이 데이터 파일을 가리키는 URI로 해석됩니다.
ignore_unknown_values
BOOL
true인 경우 오류를 반환하지 않고 테이블 스키마에 표시되지 않는 추가 값을 무시합니다.
CSV 및 JSON 데이터에 적용됩니다.
json_extension
STRING
JSON 데이터의 경우 특정 JSON 교환 형식을 나타냅니다. 지정되지 않은 경우 BigQuery는 데이터를 일반 JSON 레코드로 읽습니다.
지원되는 값은 다음과 같습니다.
GEOJSON. 줄바꿈으로 구분된 GeoJSON 데이터 자세한 내용은 줄바꿈으로 구분된 GeoJSON 파일에서 외부 테이블 만들기 [https://cloud.google.com/bigquery/docs/geospatial-data?hl=ko#external-geojson]를 참조하세요.
max_bad_records
INT64
데이터를 읽을 때 무시할 불량 레코드의 최대 개수입니다.
CSV, JSON, Google Sheets 데이터에 적용됩니다.
max_staleness
INTERVAL
BigLake 테이블 [https://cloud.google.com/bigquery/docs/biglake-intro?hl=ko#metadata_caching_for_performance] 및 객체 테이블 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko#metadata_caching_for_performance]에 적용할 수 있습니다.
테이블에 대한 작업에서 캐시된 메타데이터를 사용할지 여부와 작업이 사용하기 위해 캐시된 메타데이터가 얼마나 최신이어야 하는지를 지정합니다.
메타데이터 캐싱을 사용 중지하려면 0을 지정합니다. 이 값이 기본값입니다.
메타데이터 캐싱을 사용 설정하려면 30분에서 7일 사이의 간격 리터럴 [https://cloud.google.com/bigquery/docs/reference/standard-sql/lexical?hl=ko#interval_literals] 값을 지정합니다. 예를 들어 4시간 비활성 간격에는 INTERVAL 4 HOUR를 지정합니다. 이 값을 사용하면 지난 4시간 이내에 새로고침된 경우 테이블에 대한 작업이 캐시된 메타데이터를 사용합니다. 캐시된 메타데이터가 이보다 오래된 경우 작업이 Cloud Storage에서 메타데이터를 대신 검색하도록 되돌아갑니다.
null_marker
STRING
CSV 파일의 NULL 값을 나타내는 문자열입니다.
CSV 데이터에 적용됩니다.
null_markers
ARRAY<STRING>
(프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages])
CSV 파일의 NULL 값을 나타내는 문자열 목록입니다.
이 옵션은 null_marker 옵션과 함께 사용할 수 없습니다.
CSV 데이터에 적용됩니다.
object_metadata
STRING
객체 테이블 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko]을 만들 때만 필요합니다.
객체 테이블을 만들 때 이 옵션의 값을 SIMPLE로 설정합니다.
preserve_ascii_control_characters
BOOL
true이면 '\x00'부터 '\x1F'까지 ASCII 테이블의 처음 32자에 해당하는 삽입된 ASCII 제어 문자가 유지됩니다.
CSV 데이터에 적용됩니다.
projection_fields
STRING
로드할 항목 속성의 목록입니다.
Datastore 데이터에 적용됩니다.
quote
STRING
CSV 파일에서 데이터 섹션을 인용하는 데 사용되는 문자열입니다. 데이터에 따옴표 붙은 줄바꿈 문자가 있다면 allow_quoted_newlines 속성을 true로 설정합니다.
CSV 데이터에 적용됩니다.
reference_file_schema_uri
STRING
사용자가 테이블 스키마와 함께 참조 파일을 제공합니다.
Parquet/ORC/AVRO 데이터에 적용됩니다.
예: "gs://bucket/path/reference_schema_file.parquet"
require_hive_partition_filter
BOOL
true인 경우 이 테이블에 대한 모든 쿼리에는 데이터를 읽을 때 파티션을 제거하는 데 사용할 수 있는 파티션 필터가 필요합니다. 파티션을 나눈 하이브 외부 테이블에만 적용됩니다.
Avro, CSV, JSON, Parquet, ORC 데이터에 적용됩니다.
sheet_range
STRING
쿼리할 Google Sheets 스프레드시트의 범위입니다.
Google Sheets 데이터에 적용됩니다.
예시: "sheet1!A1:B20"
skip_leading_rows
INT64
데이터를 읽을 때 건너뛸 파일 상단의 행 수입니다.
CSV 및 Google Sheets 데이터에 적용됩니다.
source_column_match
STRING
(프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages])
이는 로드된 열을 스키마에 일치시키는 데 사용되는 전략을 제어합니다.
이 값이 지정되지 않으면 스키마가 제공되는 방식에 따라 기본값이 결정됩니다. 자동 감지가 사용 설정된 경우 기본 동작은 이름으로 열을 일치시키는 것입니다. 그렇지 않으면 기본적으로 위치별로 열이 일치합니다. 이는 동작의 하위 호환성을 유지하기 위해 수행됩니다.
지원되는 값은 다음과 같습니다.
POSITION: 위치별로 일치합니다. 이 옵션은 열이 스키마와 동일한 방식으로 정렬되어 있다고 가정합니다.
NAME: 이름으로 일치합니다. 이 옵션은 헤더 행을 열 이름으로 읽고 스키마의 필드 이름과 일치하도록 열을 재정렬합니다. 열 이름은 skip_leading_rows 속성을 기반으로 건너뛴 마지막 행에서 읽어옵니다.
tags <ARRAY<STRUCT<STRING, STRING>>>
테이블의 IAM 태그 배열이며 키-값 쌍으로 표현됩니다. 키는 네임스페이스화된 키 이름 [https://cloud.google.com/iam/docs/tags-access-control?hl=ko#definitions]이어야 하고 값은 닉네임 [https://cloud.google.com/iam/docs/tags-access-control?hl=ko#definitions]이어야 합니다.
time_zone
STRING
(프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages])
특정 시간대가 없는 타임스탬프 값을 파싱할 때 적용되는 기본 시간대입니다.
유효한 시간대 이름 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko#time_zone_name]을 확인하세요.
이 값이 없으면 특정 시간대가 없는 타임스탬프 값을 파싱할 때 기본 시간대 UTC를 사용합니다.
CSV 및 JSON 데이터에 적용됩니다.
date_format
STRING
(프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages])
입력 파일에서 DATE 값의 형식이 지정되는 방식을 정의하는 형식 요소 [https://cloud.google.com/bigquery/docs/reference/standard-sql/format-elements?hl=ko#format_string_as_datetime]입니다(예: MM/DD/YYYY).
이 값이 있으면 이 형식만 호환되는 DATE 형식입니다. 스키마 자동 감지 [https://cloud.google.com/bigquery/docs/schema-detect?hl=ko#date_and_time_values]도 기존 형식 대신 이 형식을 기반으로 DATE 열 유형을 결정합니다.
이 값이 없으면 DATE 필드가 기본 형식 [https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv?hl=ko#data_types]으로 파싱됩니다.
CSV 및 JSON 데이터에 적용됩니다.
datetime_format
STRING
(프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages])
입력 파일에서 DATETIME 값의 형식이 지정되는 방식을 정의하는 형식 요소 [https://cloud.google.com/bigquery/docs/reference/standard-sql/format-elements?hl=ko#format_string_as_datetime](예: MM/DD/YYYY HH24:MI:SS.FF3)입니다.
이 값이 있으면 이 형식만 호환되는 DATETIME 형식입니다. 스키마 자동 감지 [https://cloud.google.com/bigquery/docs/schema-detect?hl=ko#date_and_time_values]도 기존 형식 대신 이 형식을 기반으로 DATETIME 열 유형을 결정합니다.
이 값이 없으면 DATETIME 필드가 기본 형식 [https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv?hl=ko#data_types]으로 파싱됩니다.
CSV 및 JSON 데이터에 적용됩니다.
time_format
STRING
(프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages])
입력 파일에서 TIME 값의 형식이 지정되는 방식을 정의하는 형식 요소 [https://cloud.google.com/bigquery/docs/reference/standard-sql/format-elements?hl=ko#format_string_as_datetime]입니다(예: HH24:MI:SS.FF3).
이 값이 있으면 이 형식이 호환되는 유일한 TIME 형식입니다. 스키마 자동 감지 [https://cloud.google.com/bigquery/docs/schema-detect?hl=ko#date_and_time_values]도 기존 형식 대신 이 형식을 기반으로 TIME 열 유형을 결정합니다.
이 값이 없으면 TIME 필드가 기본 형식 [https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv?hl=ko#data_types]으로 파싱됩니다.
CSV 및 JSON 데이터에 적용됩니다.
timestamp_format
STRING
(프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages])
입력 파일에서 TIMESTAMP 값의 형식이 지정되는 방식을 정의하는 형식 요소 [https://cloud.google.com/bigquery/docs/reference/standard-sql/format-elements?hl=ko#format_string_as_datetime]입니다(예: MM/DD/YYYY HH24:MI:SS.FF3).
이 값이 있으면 이 형식만 호환되는 TIMESTAMP 형식입니다. 스키마 자동 감지 [https://cloud.google.com/bigquery/docs/schema-detect?hl=ko#date_and_time_values]도 기존 형식 대신 이 형식을 기반으로 TIMESTAMP 열 유형을 결정합니다.
이 값이 없으면 TIMESTAMP 필드가 기본 형식 [https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv?hl=ko#data_types]으로 파싱됩니다.
CSV 및 JSON 데이터에 적용됩니다.
uris
Bigtable 테이블이 아닌 객체 테이블을 포함한 외부 테이블의 경우:
ARRAY<STRING>
외부 데이터 위치의 정규화된 URI 배열입니다. 각 URI에는 버킷 이름 뒤에 와야 하는 별표(*) 와일드 카드 문자 [https://cloud.google.com/bigquery/docs/loading-data-cloud-storage?hl=ko#load-wildcards]가 하나 포함될 수 있습니다. 여러 파일을 대상으로 하는 uris 값을 지정하는 경우 해당하는 모든 파일은 호환되는 스키마를 공유해야 합니다.
다음 예시에서는 유효한 uris 값을 보여줍니다.
['gs://bucket/path1/myfile.csv']
['gs://bucket/path1/*.csv']
['gs://bucket/path1/*', 'gs://bucket/path2/file00*']

Bigtable 테이블의 경우:
STRING
데이터 소스로 사용할 Bigtable 테이블을 식별하는 URI입니다. Bigtable URI는 하나만 지정할 수 있습니다.
예를 들면 https://googleapis.com/bigtable/projects/project_id/instances/instance_id[/appProfiles/app_profile]/tables/table_name입니다.
Bigtable URI를 생성하는 방법에 대한 자세한 내용은 Bigtable URI 검색 [https://cloud.google.com/bigquery/docs/create-bigtable-external-table?hl=ko#bigtable-uri]을 참조하세요.
예시
예시 1:
다음 예시에서는 INFORMATION_SCHEMA.TABLE_OPTIONS 뷰를 쿼리하여 기본 프로젝트(myproject)의 mydataset에 있는 모든 테이블의 기본 테이블 만료 시간을 검색합니다.
기본 프로젝트가 아닌 프로젝트에 쿼리를 실행하려면 프로젝트 ID를 `project_id`.dataset.INFORMATION_SCHEMA.view 형식으로 데이터 세트에 추가합니다(예: `myproject`.mydataset.INFORMATION_SCHEMA.TABLE_OPTIONS).
참고: INFORMATION_SCHEMA 뷰 이름은 대소문자를 구분합니다.
  SELECT
    *
  FROM
    mydataset.INFORMATION_SCHEMA.TABLE_OPTIONS
  WHERE
    option_name = 'expiration_timestamp';
결과는 다음과 비슷합니다.
  +----------------+---------------+------------+----------------------+-------------+--------------------------------------+
  | table_catalog  | table_schema  | table_name |     option_name      | option_type |             option_value             |
  +----------------+---------------+------------+----------------------+-------------+--------------------------------------+
  | myproject      | mydataset     | mytable1   | expiration_timestamp | TIMESTAMP   | TIMESTAMP "2020-01-16T21:12:28.000Z" |
  | myproject      | mydataset     | mytable2   | expiration_timestamp | TIMESTAMP   | TIMESTAMP "2021-01-01T21:12:28.000Z" |
  +----------------+---------------+------------+----------------------+-------------+--------------------------------------+
  
참고: 만료 시간이 지정되지 않은 테이블은 쿼리 결과에서 제외됩니다.
예시 2:
다음 예시는 테스트 데이터가 포함된 mydataset의 모든 테이블에 대한 메타데이터를 검색합니다. 이 쿼리는 description 옵션의 값을 사용하여 설명의 아무 곳에서나 'test'가 포함된 테이블을 찾습니다. mydataset는 기본 프로젝트 myproject에 있습니다.
기본 프로젝트가 아닌 프로젝트에 쿼리를 실행하려면 프로젝트 ID를 `project_id`.dataset.INFORMATION_SCHEMA.view 형식으로 데이터 세트에 추가합니다(예: `myproject`.mydataset.INFORMATION_SCHEMA.TABLE_OPTIONS).
  SELECT
    *
  FROM
    mydataset.INFORMATION_SCHEMA.TABLE_OPTIONS
  WHERE
    option_name = 'description'
    AND option_value LIKE '%test%';
결과는 다음과 비슷합니다.
  +----------------+---------------+------------+-------------+-------------+--------------+
  | table_catalog  | table_schema  | table_name | option_name | option_type | option_value |
  +----------------+---------------+------------+-------------+-------------+--------------+
  | myproject      | mydataset     | mytable1   | description | STRING      | "test data"  |
  | myproject      | mydataset     | mytable2   | description | STRING      | "test data"  |
  +----------------+---------------+------------+-------------+-------------+--------------+
  
COLUMNS 뷰
INFORMATION_SCHEMA.COLUMNS 뷰를 쿼리하면 테이블의 각 열(필드)당 하나의 행이 쿼리 결과에 포함됩니다.
INFORMATION_SCHEMA.COLUMNS 뷰에는 다음과 같은 스키마가 있습니다.
열 이름 데이터 유형 값
TABLE_CATALOG STRING 데이터 세트가 포함된 프로젝트의 프로젝트 ID
TABLE_SCHEMA STRING 테이블이 포함된 데이터 세트 이름(또는 datasetId라고 함)
TABLE_NAME STRING 테이블 또는 뷰의 이름(또는 tableId라고 함)
COLUMN_NAME STRING 열 이름
ORDINAL_POSITION INT64 테이블에 있는 열의 1부터 시작하는 오프셋. _PARTITIONTIME 또는 _PARTITIONDATE와 같은 의사 열이면 값은 NULL입니다.
IS_NULLABLE STRING 열의 모드가 NULL 값을 허용하는지 여부에 따라 YES 또는 NO
DATA_TYPE STRING 열의 GoogleSQL 데이터 유형 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko]
IS_GENERATED STRING 값이 항상 NEVER임
GENERATION_EXPRESSION STRING 값이 항상 NULL임
IS_STORED STRING 값이 항상 NULL임
IS_HIDDEN STRING 열이 _PARTITIONTIME 또는 _PARTITIONDATE와 같은 의사 열인지 여부에 따라 YES 또는 NO
IS_UPDATABLE STRING 값이 항상 NULL임
IS_SYSTEM_DEFINED STRING 열이 _PARTITIONTIME 또는 _PARTITIONDATE와 같은 의사 열인지 여부에 따라 YES 또는 NO
IS_PARTITIONING_COLUMN STRING 열이 파티션 나누기 열 [https://cloud.google.com/bigquery/docs/partitioned-tables?hl=ko]인지 여부에 따라 YES 또는 NO
CLUSTERING_ORDINAL_POSITION INT64 테이블 클러스터링 열에 있는 해당 열의 1부터 시작하는 오프셋. 테이블이 클러스터링된 테이블이 아니면 값은 NULL입니다.
COLLATION_NAME STRING 콜레이션 사양 [https://cloud.google.com/bigquery/docs/reference/standard-sql/collation-concepts?hl=ko] 이름(있는 경우)입니다. 그 외의 경우는 NULL입니다.

STRING 또는 ARRAY<STRING>이 전달된 경우 콜레이션 사양(있는 경우)이 반환됩니다. 그 외의 경우는 NULL이 반환됩니다.
COLUMN_DEFAULT STRING 존재하는 경우 열의 기본값 [https://cloud.google.com/bigquery/docs/default-values?hl=ko]이고 그렇지 않은 경우 값은 NULL입니다.
ROUNDING_MODE STRING 유형이 매개변수화된 NUMERIC 또는 BIGNUMERIC인 경우 필드에 기록되는 값에 사용되는 반올림 모드입니다. 그렇지 않으면 값은 NULL입니다.
POLICY_TAGS ARRAY<STRING> 열에 연결된 정책 태그 목록
예시
다음 예시는 census_bureau_usa [https://console.cloud.google.com/bigquery?p=bigquery-public-data&%3Bd=census_bureau_usa&%3Bpage=dataset&hl=ko] 데이터 세트에 있는 population_by_zip_2010 테이블의 INFORMATION_SCHEMA.COLUMNS 뷰에서 메타데이터를 검색합니다. 이 데이터 세트는 BigQuery 공개 데이터 세트 프로그램 [https://cloud.google.com/public-datasets/?hl=ko]의 일부입니다.
쿼리하려는 테이블이 bigquery-public-data 프로젝트라는 다른 프로젝트에 있으므로 프로젝트 ID를 `project_id`.dataset.INFORMATION_SCHEMA.view 형식으로 데이터 세트에 추가합니다(예: `bigquery-public-data`.census_bureau_usa.INFORMATION_SCHEMA.TABLES).
다음 열은 현재 나중에 사용하도록 예약되어 있으므로 쿼리 결과에서 제외됩니다.
IS_GENERATED
GENERATION_EXPRESSION
IS_STORED
IS_UPDATABLE
참고: INFORMATION_SCHEMA 뷰 이름은 대소문자를 구분합니다.
  SELECT
    * EXCEPT(is_generated, generation_expression, is_stored, is_updatable)
  FROM
    `bigquery-public-data`.census_bureau_usa.INFORMATION_SCHEMA.COLUMNS
  WHERE
    table_name = 'population_by_zip_2010';
결과는 다음과 비슷합니다. 가독성을 위해 일부 열은 결과에서 제외됩니다.
+------------------------+-------------+------------------+-------------+-----------+-----------+-------------------+------------------------+-----------------------------+-------------+
|       table_name       | column_name | ordinal_position | is_nullable | data_type | is_hidden | is_system_defined | is_partitioning_column | clustering_ordinal_position | policy_tags |
+------------------------+-------------+------------------+-------------+-----------+-----------+-------------------+------------------------+-----------------------------+-------------+
| population_by_zip_2010 | zipcode     |                1 | NO          | STRING    | NO        | NO                | NO                     |                        NULL | 0 rows      |
| population_by_zip_2010 | geo_id      |                2 | YES         | STRING    | NO        | NO                | NO                     |                        NULL | 0 rows      |
| population_by_zip_2010 | minimum_age |                3 | YES         | INT64     | NO        | NO                | NO                     |                        NULL | 0 rows      |
| population_by_zip_2010 | maximum_age |                4 | YES         | INT64     | NO        | NO                | NO                     |                        NULL | 0 rows      |
| population_by_zip_2010 | gender      |                5 | YES         | STRING    | NO        | NO                | NO                     |                        NULL | 0 rows      |
| population_by_zip_2010 | population  |                6 | YES         | INT64     | NO        | NO                | NO                     |                        NULL | 0 rows      |
+------------------------+-------------+------------------+-------------+-----------+-----------+-------------------+------------------------+-----------------------------+-------------+
  
COLUMN_FIELD_PATHS 뷰
INFORMATION_SCHEMA.COLUMN_FIELD_PATHS 뷰를 쿼리하면 RECORD(또는 STRUCT) 열 내에 중첩된 [https://cloud.google.com/bigquery/docs/nested-repeated?hl=ko] 각 열당 하나의 행이 쿼리 결과에 포함됩니다.
INFORMATION_SCHEMA.COLUMN_FIELD_PATHS 뷰에는 다음과 같은 스키마가 있습니다.
열 이름 데이터 유형 값
TABLE_CATALOG STRING 데이터 세트가 포함된 프로젝트의 프로젝트 ID
TABLE_SCHEMA STRING 테이블이 포함된 데이터 세트 이름(또는 datasetId라고 함)
TABLE_NAME STRING 테이블 또는 뷰의 이름(또는 tableId라고 함)
COLUMN_NAME STRING 열 이름
FIELD_PATH STRING `RECORD` 또는 `STRUCT` 열에 있는 중첩된 [https://cloud.google.com/bigquery/docs/nested-repeated?hl=ko] 열의 경로
DATA_TYPE STRING 열의 GoogleSQL 데이터 유형 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko]
DESCRIPTION STRING 열 설명
COLLATION_NAME STRING 콜레이션 사양 [https://cloud.google.com/bigquery/docs/reference/standard-sql/collation-concepts?hl=ko] 이름(있는 경우)입니다. 그 외의 경우는 NULL입니다.

STRING, ARRAY<STRING> 또는 STRUCT의 STRING 필드가 전달된 경우 콜레이션 사양(있는 경우)이 반환됩니다. 그 외의 경우는 NULL이 반환됩니다.
ROUNDING_MODE STRING 매개변수화된 NUMERIC 또는 BIGNUMERIC 값에 정밀도 및 확장을 적용할 때 사용되는 반올림 모드입니다. 그렇지 않으면 값은 NULL입니다.
POLICY_TAGS ARRAY<STRING> 열에 연결된 정책 태그 목록
예시
다음 예시는 github_repos 데이터 세트 [https://console.cloud.google.com/bigquery?p=bigquery-public-data&%3Bd=github_repos&%3Bpage=dataset&hl=ko]에 있는 commits 테이블의 INFORMATION_SCHEMA.COLUMN_FIELD_PATHS 뷰에서 메타데이터를 검색합니다. 이 데이터 세트는 BigQuery 공개 데이터 세트 프로그램 [https://cloud.google.com/public-datasets/?hl=ko]의 일부입니다.
쿼리하려는 테이블이 bigquery-public-data 프로젝트라는 다른 프로젝트에 있으므로 프로젝트 ID를 `project_id`.dataset.INFORMATION_SCHEMA.view 형식으로 데이터 세트에 추가합니다(예: `bigquery-public-data`.github_repos.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS).
commits 테이블에는 다음과 같은 중첩 열과 중첩 및 반복 열이 포함됩니다.
author: 중첩 RECORD 열
committer: 중첩 RECORD 열
trailer: 중첩 및 반복 RECORD 열
difference: 중첩 및 반복 RECORD 열
author 및 difference 열의 메타데이터를 보려면 다음 쿼리를 실행합니다.
참고: INFORMATION_SCHEMA 뷰 이름은 대소문자를 구분합니다.
SELECT
  *
FROM
  `bigquery-public-data`.github_repos.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS
WHERE
  table_name = 'commits'
  AND (column_name = 'author' OR column_name = 'difference');
결과는 다음과 비슷합니다. 가독성을 위해 일부 열은 결과에서 제외됩니다.
  +------------+-------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-------------+-------------+
  | table_name | column_name |     field_path      |                                                                      data_type                                                                      | description | policy_tags |
  +------------+-------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-------------+-------------+
  | commits    | author      | author              | STRUCT<name STRING, email STRING, time_sec INT64, tz_offset INT64, date TIMESTAMP>                                                                  | NULL        | 0 rows      |
  | commits    | author      | author.name         | STRING                                                                                                                                              | NULL        | 0 rows      |
  | commits    | author      | author.email        | STRING                                                                                                                                              | NULL        | 0 rows      |
  | commits    | author      | author.time_sec     | INT64                                                                                                                                               | NULL        | 0 rows      |
  | commits    | author      | author.tz_offset    | INT64                                                                                                                                               | NULL        | 0 rows      |
  | commits    | author      | author.date         | TIMESTAMP                                                                                                                                           | NULL        | 0 rows      |
  | commits    | difference  | difference          | ARRAY<STRUCT<old_mode INT64, new_mode INT64, old_path STRING, new_path STRING, old_sha1 STRING, new_sha1 STRING, old_repo STRING, new_repo STRING>> | NULL        | 0 rows      |
  | commits    | difference  | difference.old_mode | INT64                                                                                                                                               | NULL        | 0 rows      |
  | commits    | difference  | difference.new_mode | INT64                                                                                                                                               | NULL        | 0 rows      |
  | commits    | difference  | difference.old_path | STRING                                                                                                                                              | NULL        | 0 rows      |
  | commits    | difference  | difference.new_path | STRING                                                                                                                                              | NULL        | 0 rows      |
  | commits    | difference  | difference.old_sha1 | STRING                                                                                                                                              | NULL        | 0 rows      |
  | commits    | difference  | difference.new_sha1 | STRING                                                                                                                                              | NULL        | 0 rows      |
  | commits    | difference  | difference.old_repo | STRING                                                                                                                                              | NULL        | 0 rows      |
  | commits    | difference  | difference.new_repo | STRING                                                                                                                                              | NULL        | 0 rows      |
  +------------+-------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-------------+-------------+
  
TABLE_STORAGE 뷰
TABLE_STORAGE 및 TABLE_STORAGE_BY_ORGANIZATION 뷰에는 다음과 같은 스키마가 있습니다.
열 이름 데이터 유형 값
PROJECT_ID STRING 데이터 세트가 포함된 프로젝트의 프로젝트 ID
PROJECT_NUMBER INT64 데이터 세트가 포함된 프로젝트의 프로젝트 번호
TABLE_CATALOG STRING 데이터 세트가 포함된 프로젝트의 프로젝트 ID
TABLE_SCHEMA STRING 테이블이나 구체화된 뷰가 포함된 데이터 세트 이름(또는 datasetId라고 함)
TABLE_NAME STRING 테이블 또는 구체화된 뷰의 이름(또는 tableId라고 함)
CREATION_TIME TIMESTAMP 테이블 생성 시간
TOTAL_ROWS INT64 테이블 또는 구체화된 뷰의 총 행 수
TOTAL_PARTITIONS INT64 테이블 또는 구체화된 뷰에 있는 파티션 수. 파티션을 나누지 않은 테이블은 0을 반환합니다.
TOTAL_LOGICAL_BYTES INT64 테이블 또는 구체화된 뷰에 있는 논리적(비압축) 총 바이트 수
ACTIVE_LOGICAL_BYTES INT64 90일을 경과하지 않은 논리적(비압축) 바이트 수
LONG_TERM_LOGICAL_BYTES INT64 90일을 경과한 논리적(비압축) 바이트 수
CURRENT_PHYSICAL_BYTES INT64 모든 파티션에서 현재 테이블 스토리지의 총 물리적 바이트 수
TOTAL_PHYSICAL_BYTES INT64 활성, 장기, 시간 이동(데이터 삭제 또는 변경) 바이트를 포함하여 스토리지에 사용된 총 물리적(압축) 바이트 수 장애 안전(시간 이동 기간 후 보관된 데이터 삭제 또는 변경) 바이트는 포함되지 않습니다.
ACTIVE_PHYSICAL_BYTES INT64 시간 이동(데이터 삭제 또는 변경) 바이트를 포함하여 90일을 경과하지 않은 물리적(압축) 바이트 수
LONG_TERM_PHYSICAL_BYTES INT64 90일을 경과한 물리적(압축) 바이트 수
TIME_TRAVEL_PHYSICAL_BYTES INT64 시간 이동 스토리지(데이터 삭제 또는 변경)에 사용된 물리적(압축) 바이트 수
STORAGE_LAST_MODIFIED_TIME TIMESTAMP 데이터가 테이블에 작성된 가장 최근 시간입니다.
DELETED BOOLEAN 테이블 삭제 여부
TABLE_TYPE STRING 테이블 유형입니다. 예를 들면 BASE TABLE입니다.
FAIL_SAFE_PHYSICAL_BYTES INT64 장애 안전 스토리지(데이터 삭제 또는 변경)에 사용된 물리적(압축) 바이트 수
LAST_METADATA_INDEX_REFRESH_TIME TIMESTAMP 테이블의 마지막 메타데이터 색인 새로고침 시간입니다.
TABLE_DELETION_REASON STRING DELETED 필드가 true인 경우 테이블 삭제 이유입니다. 가능한 값은 다음과 같습니다.
TABLE_EXPIRATION: 설정된 만료 시간 후 테이블 삭제됨
DATASET_DELETION: 사용자가 데이터 세트를 삭제함
USER_DELETED: 사용자가 테이블을 삭제함
TABLE_DELETION_TIME TIMESTAMP 테이블의 삭제 시간입니다.
예시
예시 1:
다음 예시에서는 현재 프로젝트에 대해 청구되는 총 논리 바이트를 보여줍니다.
SELECT
  SUM(total_logical_bytes) AS total_logical_bytes
FROM
  `region-
REGION`.INFORMATION_SCHEMA.TABLE_STORAGE;
결과는 다음과 비슷합니다.
+---------------------+
| total_logical_bytes |
+---------------------+
| 971329178274633     |
+---------------------+
예시 2:
다음 예시에서는 현재 프로젝트의 데이터 세트 수준에서 다양한 스토리지 바이트(GiB 단위)를 보여줍니다.
SELECT
  table_schema AS dataset_name,
  -- Logical
  SUM(total_logical_bytes) / power(1024, 3) AS total_logical_gib,  
  SUM(active_logical_bytes) / power(1024, 3) AS active_logical_gib, 
  SUM(long_term_logical_bytes) / power(1024, 3) AS long_term_logical_gib, 
  -- Physical
  SUM(total_physical_bytes) / power(1024, 3) AS total_physical_gib,
  SUM(active_physical_bytes) / power(1024, 3) AS active_physical_gib,
  SUM(active_physical_bytes - time_travel_physical_bytes) / power(1024, 3) AS active_no_tt_physical_gib,
  SUM(long_term_physical_bytes) / power(1024, 3) AS long_term_physical_gib,
  SUM(time_travel_physical_bytes) / power(1024, 3) AS time_travel_physical_gib,
  SUM(fail_safe_physical_bytes) / power(1024, 3) AS fail_safe_physical_gib 
FROM
  `region-
REGION`.INFORMATION_SCHEMA.TABLE_STORAGE 
WHERE 
  table_type ='BASE TABLE'
GROUP BY 
  table_schema  
ORDER BY 
  dataset_name 
예 3:
다음 예시는 향후 30일 동안 논리적 및 물리적 청구 모델 간의 데이터 세트당 가격 차이를 예측하는 방법을 보여줍니다. 이 예시에서는 이후의 스토리지 사용량이 쿼리 실행 시점부터 30일동안 일정하다고 가정합니다. 이 예측은 기본 테이블로 제한되며 데이터 세트 안의 다른 모든 테이블 유형을 제외합니다.
이 쿼리의 가격 책정 변수에 사용된 가격은 us-central1 리전의 가격입니다. 다른 지역에서 이 쿼리를 실행하려면 가격 변수를 적절하게 업데이트하세요. 가격 책정 정보는 스토리지 가격 책정 [https://cloud.google.com/bigquery/pricing?hl=ko#storage]을 참조하세요.
Google Cloud 콘솔에서 BigQuery 페이지를 엽니다.
BigQuery 페이지로 이동 [https://console.cloud.google.com/bigquery?hl=ko]
쿼리 편집기 상자에 다음과 같은 GoogleSQL 쿼리를 입력합니다. INFORMATION_SCHEMA에는 GoogleSQL 문법이 필요합니다. GoogleSQL은 Google Cloud 콘솔의 기본 문법입니다.
DECLARE active_logical_gib_price FLOAT64 DEFAULT 0.02;
DECLARE long_term_logical_gib_price FLOAT64 DEFAULT 0.01;
DECLARE active_physical_gib_price FLOAT64 DEFAULT 0.04;
DECLARE long_term_physical_gib_price FLOAT64 DEFAULT 0.02;

WITH
 storage_sizes AS (
   SELECT
     table_schema AS dataset_name,
     -- Logical
     SUM(IF(deleted=false, active_logical_bytes, 0)) / power(1024, 3) AS active_logical_gib,
     SUM(IF(deleted=false, long_term_logical_bytes, 0)) / power(1024, 3) AS long_term_logical_gib,
     -- Physical
     SUM(active_physical_bytes) / power(1024, 3) AS active_physical_gib,
     SUM(active_physical_bytes - time_travel_physical_bytes) / power(1024, 3) AS active_no_tt_physical_gib,
     SUM(long_term_physical_bytes) / power(1024, 3) AS long_term_physical_gib,
     -- Restorable previously deleted physical
     SUM(time_travel_physical_bytes) / power(1024, 3) AS time_travel_physical_gib,
     SUM(fail_safe_physical_bytes) / power(1024, 3) AS fail_safe_physical_gib,
   FROM
     `region-
REGION`.INFORMATION_SCHEMA.TABLE_STORAGE_BY_PROJECT
   WHERE total_physical_bytes + fail_safe_physical_bytes > 0
     -- Base the forecast on base tables only for highest precision results
     AND table_type  = 'BASE TABLE'
     GROUP BY 1
 )
SELECT
  dataset_name,
  -- Logical
  ROUND(active_logical_gib, 2) AS active_logical_gib,
  ROUND(long_term_logical_gib, 2) AS long_term_logical_gib,
  -- Physical
  ROUND(active_physical_gib, 2) AS active_physical_gib,
  ROUND(long_term_physical_gib, 2) AS long_term_physical_gib,
  ROUND(time_travel_physical_gib, 2) AS time_travel_physical_gib,
  ROUND(fail_safe_physical_gib, 2) AS fail_safe_physical_gib,
  -- Compression ratio
  ROUND(SAFE_DIVIDE(active_logical_gib, active_no_tt_physical_gib), 2) AS active_compression_ratio,
  ROUND(SAFE_DIVIDE(long_term_logical_gib, long_term_physical_gib), 2) AS long_term_compression_ratio,
  -- Forecast costs logical
  ROUND(active_logical_gib * active_logical_gib_price, 2) AS forecast_active_logical_cost,
  ROUND(long_term_logical_gib * long_term_logical_gib_price, 2) AS forecast_long_term_logical_cost,
  -- Forecast costs physical
  ROUND((active_no_tt_physical_gib + time_travel_physical_gib + fail_safe_physical_gib) * active_physical_gib_price, 2) AS forecast_active_physical_cost,
  ROUND(long_term_physical_gib * long_term_physical_gib_price, 2) AS forecast_long_term_physical_cost,
  -- Forecast costs total
  ROUND(((active_logical_gib * active_logical_gib_price) + (long_term_logical_gib * long_term_logical_gib_price)) -
     (((active_no_tt_physical_gib + time_travel_physical_gib + fail_safe_physical_gib) * active_physical_gib_price) + (long_term_physical_gib * long_term_physical_gib_price)), 2) AS forecast_total_cost_difference
FROM
  storage_sizes
ORDER BY
  (forecast_active_logical_cost + forecast_active_physical_cost) DESC;
참고: INFORMATION_SCHEMA 뷰 이름은 대소문자를 구분합니다.
실행을 클릭합니다.
결과는 다음과 비슷합니다.
+--------------+--------------------+-----------------------+---------------------+------------------------+--------------------------+-----------------------------+------------------------------+----------------------------------+-------------------------------+----------------------------------+--------------------------------+
| dataset_name | active_logical_gib | long_term_logical_gib | active_physical_gib | long_term_physical_gib | active_compression_ratio | long_term_compression_ratio | forecast_active_logical_cost | forecaset_long_term_logical_cost | forecast_active_physical_cost | forecast_long_term_physical_cost | forecast_total_cost_difference |
+--------------+--------------------+-----------------------+---------------------+------------------------+--------------------------+-----------------------------+------------------------------+----------------------------------+-------------------------------+----------------------------------+--------------------------------+
| dataset1     |               10.0 |                  10.0 |                 1.0 |                    1.0 |                     10.0 |                        10.0 |                          0.2 |                              0.1 |                          0.04 |                             0.02 |                           0.24 |
데이터 세트의 테이블 나열
다음 방법으로 데이터 세트의 테이블을 나열할 수 있습니다.
Google Cloud 콘솔 사용
bq 명령줄 도구 bq ls [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_ls] 명령어 사용
tables.list [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/list?hl=ko] API 메서드 호출
클라이언트 라이브러리 사용
필수 권한
데이터 세트의 테이블을 나열하려면 최소한 bigquery.tables.list 권한이 부여되어 있어야 합니다. 다음과 같은 사전 정의된 IAM 역할에는 bigquery.tables.list 권한이 포함되어 있습니다.
bigquery.user
bigquery.metadataViewer
bigquery.dataViewer
bigquery.dataEditor
bigquery.dataOwner
bigquery.admin
BigQuery의 IAM 역할과 권한에 대한 자세한 내용은 액세스 제어 [https://cloud.google.com/bigquery/access-control?hl=ko]를 참조하세요.
표 나열
데이터 세트의 테이블을 나열하려면 다음과 같이 하세요.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/tables?hl=ko#%EC%BD%98%EC%86%94] ---
Google Cloud 콘솔의 탐색창에서 데이터세트를 클릭하여 펼칩니다. 그러면 데이터세트에 있는 테이블과 뷰가 표시됩니다.
목록을 스크롤하여 데이터 세트의 테이블을 확인합니다. 테이블과 뷰는 각기 다른 아이콘으로 구분할 수 있습니다.

--- 탭: bq [https://cloud.google.com/bigquery/docs/tables?hl=ko#bq] ---
In the Google Cloud console, activate Cloud Shell.
    Activate Cloud Shell [https://console.cloud.google.com/?cloudshell=true&hl=ko]
    
      At the bottom of the Google Cloud console, a
      Cloud Shell [https://cloud.google.com/shell/docs/how-cloud-shell-works?hl=ko]
      session starts and displays a command-line prompt. Cloud Shell is a shell environment
      with the Google Cloud CLI
      already installed and with values already set for
      your current project. It can take a few seconds for the session to initialize.
    
    
  










bq ls [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_ls] 명령어를 실행합니다. --format 플래그를 사용하면 출력을 제어할 수 있습니다. 기본 프로젝트가 아닌 다른 프로젝트의 테이블을 나열하는 경우 프로젝트 ID를 project_id:dataset 형식으로 데이터 세트에 추가합니다.

추가 플래그에는 다음이 포함됩니다.


--max_results 또는 -n: 결과의 최대 수를 나타내는 정수입니다. 기본값은 50입니다.


bq ls [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_ls] \
--format=pretty \
--max_results integer \
project_id:dataset

각 항목의 의미는 다음과 같습니다.


integer는 나열할 테이블 수를 나타내는 정수입니다.
project_id는 프로젝트 ID입니다.
dataset는 데이터 세트 이름입니다.


명령어를 실행하면 Type 필드에 TABLE 또는 VIEW가 표시됩니다. 예를 들면 다음과 같습니다.

+-------------------------+-------+----------------------+-------------------+
|         tableId         | Type  |        Labels        | Time Partitioning |
+-------------------------+-------+----------------------+-------------------+
| mytable                 | TABLE | department:shipping  |                   |
| myview                  | VIEW  |                      |                   |
+-------------------------+-------+----------------------+-------------------+


예를 들면 다음과 같습니다.

다음 명령어를 입력하면 기본 프로젝트의 데이터 세트 mydataset에 있는 테이블이 나열됩니다.
   bq ls [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_ls] --format=pretty mydataset

다음 명령어를 입력하여 mydataset에서 50개의 기본 테이블 출력을 반환합니다. 여기서 mydataset는 기본 프로젝트에 있습니다.
   bq ls [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_ls] --format=pretty --max_results 60 mydataset

myotherproject의 데이터 세트 mydataset에 있는 테이블을 나열하려면 다음 명령어를 입력합니다.
   bq ls [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_ls] --format=pretty myotherproject:mydataset

 API API를 사용하여 테이블을 나열하려면 tables.list [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/list?hl=ko] 메서드를 호출합니다.
 C# 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 C# 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery C# API 참고 문서 [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  
using Google.Cloud.BigQuery.V2 [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.html?hl=ko];
using System;
using System.Collections.Generic;
using System.Linq;

public class BigQueryListTables
{
    public void ListTables(
        string projectId = "your-project-id",
        string datasetId = "your_dataset_id"
    )
    {
        BigQueryClient [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko] client = BigQueryClient [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko].Create [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko#Google_Cloud_BigQuery_V2_BigQueryClient_Create_System_String_Google_Apis_Auth_OAuth2_GoogleCredential_](projectId);
        // Retrieve list of tables in the dataset
        List<BigQueryTable> tables = client.ListTables [https://cloud.google.com/dotnet/docs/reference/Google.Cloud.BigQuery.V2/latest/Google.Cloud.BigQuery.V2.BigQueryClient.html?hl=ko#Google_Cloud_BigQuery_V2_BigQueryClient_ListTables_Google_Apis_Bigquery_v2_Data_DatasetReference_Google_Cloud_BigQuery_V2_ListTablesOptions_](datasetId).ToList();
        // Display the results
        if (tables.Count > 0)
        {
            Console.WriteLine($"Tables in dataset {datasetId}:");
            foreach (var table in tables)
            {
                Console.WriteLine($"\t{table.Reference.TableId}");
            }
        }
        else
        {
            Console.WriteLine($"{datasetId} does not contain any tables.");
        }
    }
}




























  
  



  
  
  
  
  
  
  
  
  
  

Go









  
  
  
  





  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Go 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Go API 참고 문서 [https://godoc.org/cloud.google.com/go/bigquery]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  import (
	"context"
	"fmt"
	"io"

	"cloud.google.com/go/bigquery"
	"google.golang.org/api/iterator"
)

// listTables demonstrates iterating through the collection of tables in a given dataset.
func listTables(w io.Writer, projectID, datasetID string) error {
	// projectID := "my-project-id"
	// datasetID := "mydataset"
	ctx := context.Background()
	client, err := bigquery.NewClient(ctx, projectID)
	if err != nil {
		return fmt.Errorf("bigquery.NewClient: %v", err)
	}
	defer client.Close()

	ts := client.Dataset(datasetID).Tables [https://cloud.google.com/go/docs/reference/cloud.google.com/go/bigquery/latest/index.html?hl=ko#cloud_google_com_go_bigquery_Dataset_Tables](ctx)
	for {
		t, err := ts.Next()
		if err == iterator.Done {
			break
		}
		if err != nil {
			return err
		}
		fmt.Fprintf(w, "Table: %q\n", t.TableID)
	}
	return nil
}





























  
  



  
  
  
  
  
  
  
  
  
  

 Java 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Java 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Java API 참고 문서 [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/overview?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  import com.google.api.gax.paging.Page [https://cloud.google.com/java/docs/reference/gax/latest/com.google.api.gax.paging.Page.html?hl=ko];
import com.google.cloud.bigquery.BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko];
import com.google.cloud.bigquery.BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko].TableListOption [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.TableListOption.html?hl=ko];
import com.google.cloud.bigquery.BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko];
import com.google.cloud.bigquery.BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko];
import com.google.cloud.bigquery.DatasetId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.DatasetId.html?hl=ko];
import com.google.cloud.bigquery.Table [https://cloud.google.com/java/docs/reference/google-cloud-biglake/latest/com.google.cloud.bigquery.biglake.v1.Table.html?hl=ko];

public class ListTables {

  public static void runListTables() {
    // TODO(developer): Replace these variables before running the sample.
    String projectId = "bigquery-public-data";
    String datasetName = "samples";
    listTables(projectId, datasetName);
  }

  public static void listTables(String projectId, String datasetName) {
    try {
      // Initialize client that will be used to send requests. This client only needs to be created
      // once, and can be reused for multiple requests.
      BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko] bigquery = BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko].getDefaultInstance().getService();

      DatasetId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.DatasetId.html?hl=ko] datasetId = DatasetId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.DatasetId.html?hl=ko].of(projectId, datasetName);
      Page<Table> tables = bigquery.listTables [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko#com_google_cloud_bigquery_BigQuery_listTables_com_google_cloud_bigquery_DatasetId_com_google_cloud_bigquery_BigQuery_TableListOption____](datasetId, TableListOption.pageSize(100));
      tables.iterateAll().forEach(table -> System.out.print(table.getTableId().getTable() + "\n"));

      System.out.println("Tables listed successfully.");
    } catch (BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko] e) {
      System.out.println("Tables were not listed. Error occurred: " + e.toString());
    }
  }
}




























  
  



  
  
  
  
  
  
  
  
  
  

 Node.js 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Node.js 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Node.js API 참고 문서 [https://googleapis.dev/nodejs/bigquery/latest/index.html]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  // Import the Google Cloud client library
const {BigQuery} = require('@google-cloud/bigquery [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/overview.html?hl=ko]');
const bigquery = new BigQuery [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/bigquery/bigquery.html?hl=ko]();

async function listTables() {
  // Lists tables in 'my_dataset'.

  /**
   * TODO(developer): Uncomment the following lines before running the sample.
   */
  // const datasetId = 'my_dataset';

  // List all tables in the dataset
  const [tables] = await bigquery.dataset(datasetId).getTables [https://cloud.google.com/nodejs/docs/reference/bigquery/latest/bigquery/dataset.html?hl=ko]();

  console.log('Tables:');
  tables.forEach(table => console.log(table.id));
}




























  
  



  
  
  
  
  
  
  
  
  
  

PHP









  
  
  
  





  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 PHP 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery PHP API 참고 문서 [https://cloud.google.com/php/docs/reference/cloud-bigquery/latest/BigQueryClient?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  use Google\Cloud\BigQuery\BigQueryClient;

/** Uncomment and populate these variables in your code */
// $projectId  = 'The Google project ID';
// $datasetId  = 'The BigQuery dataset ID';

$bigQuery = new BigQueryClient([
    'projectId' => $projectId,
]);
$dataset = $bigQuery->dataset($datasetId);
$tables = $dataset->tables();
foreach ($tables as $table) {
    print($table->id() . PHP_EOL);
}




























  
  



  
  
  
  
  
  
  
  
  
  

 Python 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Python 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Python API 참고 문서 [https://cloud.google.com/python/docs/reference/bigquery/latest?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  
from google.cloud import bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko]

# Construct a BigQuery client object.
client = bigquery [https://cloud.google.com/python/docs/reference/bigquery/latest/?hl=ko].Client [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client.html?hl=ko]()

# TODO(developer): Set dataset_id to the ID of the dataset that contains
#                  the tables you are listing.
# dataset_id = 'your-project.your_dataset'

tables = client.list_tables [https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client.html?hl=ko#google_cloud_bigquery_client_Client_list_tables](dataset_id)  # Make an API request.

print("Tables contained in '{}':".format(dataset_id))
for table in tables:
    print("{}.{}.{}".format(table.project, table.dataset_id, table.table_id))




























  
  



  
  
  
  
  
  
  
  
  
  

 Ruby 









  
  
  
  





  
  
  
    
  




  



  







  
    
  



  



  
  
    
    
      
        
          이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Ruby 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Ruby API 참고 문서 [https://googleapis.dev/ruby/google-cloud-bigquery/latest/Google/Cloud/Bigquery.html]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  require "google/cloud/bigquery"

def list_tables dataset_id = "your_dataset_id"
  bigquery = Google::Cloud::Bigquery [https://cloud.google.com/ruby/docs/reference/google-cloud-bigquery-analytics_hub/latest/Google-Cloud-Bigquery.html?hl=ko].new [https://cloud.google.com/ruby/docs/reference/google-cloud-bigquery/latest/Google-Cloud-Bigquery.html?hl=ko]
  dataset  = bigquery.dataset dataset_id

  puts "Tables in dataset #{dataset_id}:"
  dataset.tables.each do |table|
    puts "\t#{table.table_id}"
  end
end
테이블 보안
BigQuery에서 테이블에 대한 액세스를 제어하려면 IAM으로 리소스에 대한 액세스 제어 [https://cloud.google.com/bigquery/docs/control-access-to-resources-iam?hl=ko]를 참고하세요.
다음 단계
데이터 세트에 대한 자세한 내용은 데이터 세트 소개 [https://cloud.google.com/bigquery/docs/datasets-intro?hl=ko]를 참조하세요.
테이블 데이터 처리에 대한 자세한 내용은 테이블 데이터 관리 [https://cloud.google.com/bigquery/docs/managing-table-data?hl=ko]를 참조하세요.
테이블 스키마 지정에 대한 자세한 내용은 스키마 지정 [https://cloud.google.com/bigquery/docs/schemas?hl=ko]을 참조하세요.
테이블 스키마 수정에 대한 자세한 내용은 테이블 스키마 수정 [https://cloud.google.com/bigquery/docs/managing-table-schemas?hl=ko]을 참조하세요.
테이블 관리에 대한 자세한 내용은 테이블 관리 [https://cloud.google.com/bigquery/docs/managing-tables?hl=ko]를 참조하세요.
BigQuery INFORMATION_SCHEMA 소개 [https://cloud.google.com/bigquery/docs/information-schema-intro?hl=ko]에서 INFORMATION_SCHEMA의 개요 참조
직접 사용해 보기
Google Cloud를 처음 사용하는 경우 계정을 만들어 실제 시나리오에서 BigQuery의 성능을 평가할 수 있습니다. 신규 고객에게는 워크로드를 실행, 테스트, 배포하는 데 사용할 수 있는 $300의 무료 크레딧이 제공됩니다.
BigQuery 무료로 사용해 보기 [https://console.cloud.google.com/freetrial?hl=ko]
도움이 되었나요?
의견 보내기