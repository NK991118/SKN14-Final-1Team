Source URL: https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs

BigQuery [https://cloud.google.com/bigquery?hl=ko]
Documentation [https://cloud.google.com/bigquery/docs?hl=ko]
가이드 [https://cloud.google.com/bigquery/docs/introduction?hl=ko]
도움이 되었나요?
의견 보내기
이 페이지의 내용
하이브 파티션을 나눈 데이터 로드 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#load_hive_partitioned_data]
증분 로드 수행 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#performing_incremental_loads]
파티션 스키마 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#partition_schema]
지원되는 데이터 레이아웃 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#supported_data_layouts]
지원되지 않는 데이터 레이아웃 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#unsupported_data_layouts]
감지 모드 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#detection_modes]
제한사항 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#limitations]
다음 단계 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#whats_next]
외부에서 파티션을 나눈 데이터 로드
bookmark_border
BigQuery는 하이브 파티션 나누기 레이아웃을 사용하여 Cloud Storage에 저장된 데이터를 로드할 수 있습니다. 하이브 파티션 나누기는 파일을 여러 파티션으로 분리하는 이름 지정 규칙을 사용하여 외부 데이터가 여러 파일로 구성됨을 의미합니다. 자세한 내용은 지원되는 데이터 레이아웃 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#supported_data_layouts]을 참조하세요.
기본적으로 파티션을 나눈 테이블 [https://cloud.google.com/bigquery/docs/partitioned-tables?hl=ko]을 명시적으로 만들지 않으면 데이터를 로드한 후 BigQuery에서 데이터의 파티션이 나뉘지 않습니다.
하이브 파티션을 나눈 데이터 로드
하이브 파티션을 나눈 데이터를 로드하려면 다음 옵션 중 하나를 선택합니다.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#%EC%BD%98%EC%86%94] ---
Google Cloud 콘솔에서 BigQuery로 이동합니다.
    BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko]

탐색기 창에서 프로젝트를 확장하고 데이터 세트를 선택합니다.
more_vert 작업 보기를 클릭한 후 테이블 만들기를 클릭합니다. 그러면 테이블 만들기 창이 열립니다.

소스 섹션에서 다음 세부정보를 지정합니다.
  
    다음 항목으로 테이블 만들기에서 Google Cloud Storage를 선택합니다.
    Cloud Storage 버킷에서 파일 선택에 와일드 카드 [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#load-wildcards]를 사용하여 Cloud Storage 폴더 경로를 입력합니다.
      예를 들면 my_bucket/my_files*입니다. Cloud Storage 버킷은 생성, 추가 또는 덮어쓰려는 테이블이 포함된 데이터 세트와 동일한 위치에 있어야 합니다.
    
    파일 형식 목록에서 파일 유형을 선택합니다.
    소스 데이터 파티션 나누기 체크박스를 선택한 후 소스 URI 프리픽스 선택에 대해 Cloud Storage URI 프리픽스를 입력합니다. 예를 들면 gs://my_bucket/my_files입니다.
    파티션 추론 모드 섹션에서 다음 옵션 중 하나를 선택합니다.
유형을 자동으로 추론: 파티션 스키마 감지 모드를 AUTO로 설정합니다.
        모든 열은 문자열: 파티션 스키마 감지 모드를 STRINGS로 설정합니다.
        직접 제공하여 파티션 스키마 감지 모드를 CUSTOM으로 설정하고 파티션 키의 스키마 정보를 직접 입력합니다. 자세한 내용은 커스텀 파티션 키 스키마 제공 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#custom_partition_key_schema]을 참조하세요.
      
    선택사항: 이 테이블의 모든 쿼리에 파티션 필터가 필요하면 파티션 필터 필요 체크박스를 선택합니다. 파티션 필터를 필수항목으로 설정하면 비용을 줄이고 성능을 높일 수 있습니다. 자세한 내용은 쿼리에서 파티션 키에 조건자 필터 필요 [https://cloud.google.com/bigquery/docs/hive-partitioned-queries-gcs?hl=ko#requiring_predicate_filters_on_partition_keys_in_queries]를 참조하세요.

    대상 섹션에서 다음 세부정보를 지정합니다.
      
        프로젝트에서 테이블을 만들 프로젝트를 선택합니다.
        데이터 세트에서 테이블을 만들 데이터 세트를 선택합니다.
        테이블에 만들 테이블의 이름을 입력합니다.
        테이블 유형에서 기본 테이블을 선택합니다 .
      
    

    스키마 섹션에 스키마 [https://cloud.google.com/bigquery/docs/schemas?hl=ko] 정의를 입력합니다. 
  스키마의 자동 감지 [https://cloud.google.com/bigquery/docs/schema-detect?hl=ko]를 사용 설정하려면 자동 감지를 선택합니다.
  스키마와 일치하지 않는 추가 열 값이 있는 행을 무시하려면 고급 옵션 섹션을 펼치고 알 수 없는 값을 선택합니다.
      테이블 만들기를 클릭합니다.

--- 탭: SQL [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#sql] ---
외부에서 파티션을 나눈 테이블을 만들려면 LOAD DATA 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/other-statements?hl=ko#load_data_statement]의 WITH PARTITION COLUMNS 절을 사용하여 파티션 스키마 세부정보를 지정합니다.

예시는 외부에서 파티션을 나눈 파일 로드 [https://cloud.google.com/bigquery/docs/reference/standard-sql/other-statements?hl=ko#load_a_file_that_is_externally_partitioned]를 참조하세요.

--- 탭: bq [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#bq] ---
자동 파티션 키 유형 감지를 사용하여 하이브로 파티션을 나눈 데이터를 로드합니다.

bq load --source_format=ORC --hive_partitioning_mode=AUTO \
--hive_partitioning_source_uri_prefix=gcs_uri_shared_prefix \
dataset.table gcs_uris

문자열 유형 파티션 키 감지를 사용하여 하이브로 파티션을 나눈 데이터를 로드합니다.

bq load --source_format=CSV --autodetect \
--hive_partitioning_mode=STRINGS \
--hive_partitioning_source_uri_prefix=gcs_uri_shared_prefix \
dataset.table gcs_uris

source\_uri\_prefix 필드를 사용하여 인코딩된 커스텀 파티션 키 스키마를 사용하여 하이브로 파티션을 나눈 데이터를 로드합니다.

bq load --source_format=JSON --hive_partitioning_mode=CUSTOM \
--hive_partitioning_source_uri_prefix=gcs_uri_shared_prefix/partition_key_schema \
dataset.table gcs_uris file_schema

파티션 키 스키마는 소스 URI 프리픽스 바로 뒤에 인코딩됩니다. --hive_partitioning_source_uri_prefix를 지정하려면 다음 형식을 사용하세요.

--hive_partitioning_source_uri_prefix=gcs_uri_shared_prefix/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}

--- 탭: API [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#api] ---
하이브 파티션 나누기에 대한 지원은 JobConfigurationLoad [https://cloud.google.com/bigquery/docs/reference/rest/v2/Job?hl=ko#jobconfigurationload]에서 HivePartitioningOptions [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables?hl=ko#hivepartitioningoptions]를 설정하여 존재합니다.
참고: hivePartitioningOptions.mode가 CUSTOM으로 설정된 경우, 다음과 같이 hivePartitioningOptions.sourceUriPrefix 필드에 파티션 키 스키마를 인코딩해야 합니다.
gs://BUCKET/PATH_TO_TABLE/{KEY1:TYPE1}/{KEY2:TYPE2}/...
증분 로드 수행
다음과 같은 데이터 레이아웃을 가정해 보겠습니다.
gs://my_bucket/my_table/dt=2019-10-31/val=1/file1
gs://my_bucket/my_table/dt=2018-10-31/val=2/file2
gs://my_bucket/my_table/dt=2017-10-31/val=3/file3
gs://my_bucket/my_table/dt=2016-10-31/val=4/file4
2019-10-31의 데이터만 로드하려면 다음 안내를 따르세요.
하이브 파티션 나누기 모드 [https://cloud.google.com/bigquery/docs/hive-partitioned-queries-gcs?hl=ko#partition_schema_detection_modes]를 AUTO, STRINGS, 또는 CUSTOM으로 설정합니다.
AUTO 또는 STRINGS 하이브 파티션 나누기 모드의 소스 URI 프리픽스를 gs://my_bucket/my_table/로 설정합니다. CUSTOM의 경우 gs://my_bucket/my_table/{dt:DATE}/{val:INTEGER}를 제공합니다.
URI gs://my_bucket/my_table/dt=2019-10-31/*을 사용합니다.
dt 및 val 열이 포함된 데이터가 로드되고, 두 열의 값은 각각 2019-10-31과 1입니다.
특정 파일의 데이터만 로드하려면 다음 안내를 따르세요.
하이브 파티션 나누기 모드 [https://cloud.google.com/bigquery/docs/hive-partitioned-queries-gcs?hl=ko#partition_schema_detection_modes]를 AUTO, STRINGS, 또는 CUSTOM으로 설정합니다.
AUTO 또는 STRINGS 하이브 파티션 나누기 모드의 소스 URI 프리픽스를 gs://my_bucket/my_table/로 설정합니다. CUSTOM에는 gs://my_bucket/my_table/{dt:DATE}/{val:INTEGER}를 입력합니다.
URI gs://my_bucket/my_table/dt=2017-10-31/val=3/file3,gs://my_bucket/my_table/dt=2016-10-31/val=4/file4를 사용합니다.
dt 및 val 열이 채워진 두 파일에서 데이터가 로드됩니다.
파티션 스키마
다음 섹션에서는 기본 하이브 파티션 나누기 레이아웃 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#supported_data_layouts] 및 BigQuery가 지원하는 스키마 감지 모드 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#detection_modes]를 설명합니다.
지원되는 데이터 레이아웃
하이브 파티션 키는 Cloud Storage에서 데이터를 쿼리할 때 일반 열로 표시됩니다. 데이터는 기본 Hive 파티션 나누기 레이아웃을 따라야 합니다. 예를 들어 다음 파일의 키-값 쌍은 기본 레이아웃을 따라 등호 부호(=)를 구분자로 사용하는 디렉터리로 구성되어 있으며, 파티션 키의 순서는 항상 동일합니다.
gs://my_bucket/my_table/dt=2019-10-31/lang=en/my_filename
gs://my_bucket/my_table/dt=2018-10-31/lang=fr/my_filename
이 예시에서 공통 소스 URI 프리픽스는 gs://my_bucket/my_table입니다.
지원되지 않는 데이터 레이아웃
파티션 키 이름이 디렉터리 경로에 인코딩되어 있지 않으면 파티션 스키마 감지가 실패합니다. 예를 들어 다음과 같이 파티션 키 이름이 인코딩되지 않은 경로를 가정해 보겠습니다.
gs://my_bucket/my_table/2019-10-31/en/my_filename
파일의 스키마 순서가 일관되지 않으면 감지가 실패합니다. 예를 들어 다음의 두 파일은 파티션 키 인코딩이 반전된 경우입니다.
gs://my_bucket/my_table/dt=2019-10-31/lang=en/my_filename
gs://my_bucket/my_table/lang=fr/dt=2018-10-31/my_filename
감지 모드
BigQuery는 다음 세 가지 모드의 Hive 파티션 스키마 감지를 지원합니다.
AUTO: 키 이름과 유형이 자동 감지됩니다. 다음 유형을 감지할 수 있습니다.
STRING [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko#string_type]
INTEGER [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko#integer_types]
DATE [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko#date_type]
예를 들면 /date=2018-10-18/입니다.
TIMESTAMP [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko#timestamp_type]
예를 들면 /time=2018-10-18 16:00:00+00/입니다.
STRINGS: 키 이름이 STRING 유형으로 자동 변환됩니다.
CUSTOM: 파티션 키 스키마는 소스 URI 프리픽스에 지정된 대로 인코딩됩니다.
커스텀 파티션 키 스키마
CUSTOM 스키마를 사용하려면 소스 URI 프리픽스 필드에 스키마를 지정해야 합니다. CUSTOM 스키마를 사용하면 각 파티션 키의 유형을 지정할 수 있습니다. 값은 지정된 유형에 유효하도록 파싱해야 하며, 그렇지 않으면 쿼리가 실패합니다.
예를 들어 source_uri_prefix 플래그를 gs://my_bucket/my_table/{dt:DATE}/{val:STRING}로 설정하면 BigQuery가 val을 STRING으로, dt를 DATE로 처리하고, gs://my_bucket/my_table을 일치하는 파일의 소스 URI 프리픽스로 사용합니다.
제한사항
하이브 파티션 나누기 지원은 모든 URI에 대해 파티션 인코딩 바로 앞에서 끝나는 공통의 소스 URI 프리픽스를 가정하여 구축됩니다(예: gs://BUCKET/PATH_TO_TABLE/).
파티션을 나눈 Hive 테이블의 디렉터리 구조는 동일한 파티션 나누기 키가 동일한 순서로 표시된다고 가정하며, 이때 파티션 키는 테이블당 최대 10개입니다.
데이터는 기본 Hive 파티션 나누기 레이아웃 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#supported_data_layouts]을 따라야 합니다.
기본 파일에 있는 Hive 파티션 나누기 키와 열은 겹치지 않아야 합니다.
GoogleSQL [https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax?hl=ko]에서만 지원됩니다.
Cloud Storage에서 로드 관련 모든 제한사항 [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#limitations]이 적용됩니다.
다음 단계
파티션을 나눈 테이블 [https://cloud.google.com/bigquery/docs/partitioned-tables?hl=ko] 알아보기
BigQuery에서 SQL을 사용하는 [https://cloud.google.com/bigquery/docs/introduction-sql?hl=ko] 방법 알아보기
도움이 되었나요?
의견 보내기