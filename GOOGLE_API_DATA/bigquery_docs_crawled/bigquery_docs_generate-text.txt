Source URL: https://cloud.google.com/bigquery/docs/generate-text

BigQuery [https://cloud.google.com/bigquery?hl=ko]
Documentation [https://cloud.google.com/bigquery/docs?hl=ko]
가이드 [https://cloud.google.com/bigquery/docs/introduction?hl=ko]
도움이 되었나요?
의견 보내기
이 페이지의 내용
필수 권한 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#required_permissions]
시작하기 전에 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#before_you_begin]
연결 만들기 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#create_a_connection]
서비스 계정에 액세스 권한 부여 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#give_the_service_accounts_access]
원격 모델 연결의 서비스 계정에 역할 부여 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#grant_a_role_to_the_remote_model_connections_service_account]
ML.GENERATE_TEXT 함수를 사용하여 텍스트 생성
bookmark_border
이 문서에서는 Vertex AI 모델을 나타내는 BigQuery ML 원격 모델 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model?hl=ko]을 만든 후 이 원격 모델을 ML.GENERATE_TEXT 함수 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text?hl=ko]와 함께 사용하여 텍스트를 생성하는 방법을 설명합니다.
지원되는 원격 모델 유형은 다음과 같습니다.
사전 학습된 Vertex AI 모델 [https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models?hl=ko]을 통한 원격 모델 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model?hl=ko]
Anthropic Claude 모델 [https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/use-claude?hl=ko](프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages])을 통한 원격 모델 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model?hl=ko]
지원되는 개방형 모델 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model-open?hl=ko#supported_open_models]을 통한 원격 모델 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model-open?hl=ko]
선택한 Vertex AI 모델에 따라 객체 테이블 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko]의 비정형 데이터 입력 또는 표준 테이블 [https://cloud.google.com/bigquery/docs/tables-intro?hl=ko#standard_tables]의 텍스트 입력을 기반으로 텍스트를 생성할 수 있습니다.
필수 권한
연결을 만들려면 다음 Identity and Access Management(IAM) 역할에 멤버십이 필요합니다.
roles/bigquery.connectionAdmin
연결의 서비스 계정에 권한을 부여하려면 다음 권한이 필요합니다.
resourcemanager.projects.setIamPolicy
BigQuery ML을 사용하여 모델을 만들려면 다음 IAM 권한이 필요합니다.
bigquery.jobs.create
bigquery.models.create
bigquery.models.getData
bigquery.models.updateData
bigquery.models.updateMetadata
추론을 실행하려면 다음 권한이 필요합니다.
테이블에 대한 bigquery.tables.getData
모델에 대한 bigquery.models.getData
bigquery.jobs.create
시작하기 전에
In the Google Cloud console, on the project selector page, select or create a Google Cloud project.
Note: If you don't plan to keep the resources that you create in this procedure, create a project instead of selecting an existing project. After you finish these steps, you can delete the project, removing all resources associated with the project.
Go to project selector [https://console.cloud.google.com/projectselector2/home/dashboard?hl=ko]
Verify that billing is enabled for your Google Cloud project [https://cloud.google.com/billing/docs/how-to/verify-billing-enabled?hl=ko#confirm_billing_is_enabled_on_a_project].
Enable the BigQuery, BigQuery Connection, and Vertex AI APIs.
Enable the APIs [https://console.cloud.google.com/flows/enableapi?apiid=bigquery.googleapis.com%2Cbigqueryconnection.googleapis.com%2Caiplatform.googleapis.com&hl=ko]
연결 만들기
원격 모델이 사용할 클라우드 리소스 연결 [https://cloud.google.com/bigquery/docs/create-cloud-resource-connection?hl=ko]을 만들고 연결의 서비스 계정을 가져옵니다.
다음 옵션 중 하나를 선택합니다.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#%EC%BD%98%EC%86%94] ---
BigQuery 페이지로 이동합니다.

BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko] 
연결을 만들려면 add 추가를 클릭한 다음 외부 데이터 소스에 연결을 클릭합니다.
연결 유형 목록에서 Vertex AI 원격 모델, 원격 함수, BigLake(Cloud 리소스)를 선택합니다.
연결 ID 필드에 연결 이름을 입력합니다.
연결 만들기를 클릭합니다.
연결로 이동을 클릭합니다.
연결 정보 창에서 나중의 단계에 사용할 서비스 계정 ID를 복사합니다.

--- 탭: bq [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#bq] ---
명령줄 환경에서 연결을 만듭니다.

bq mk --connection --location=REGION --project_id=PROJECT_ID \
    --connection_type=CLOUD_RESOURCE CONNECTION_ID

--project_id 매개변수는 기본 프로젝트를 재정의합니다.

다음을 바꿉니다.


REGION: 연결 리전 [https://cloud.google.com/bigquery/docs/locations?hl=ko#supported_locations]
PROJECT_ID: Google Cloud 프로젝트 ID
CONNECTION_ID: 연결의 ID


연결 리소스를 만들면 BigQuery가 고유한 시스템 서비스 계정을 만들고 이를 연결에 연계합니다.

문제 해결: 다음 연결 오류가 발생하면 Google Cloud SDK를 업데이트 [https://cloud.google.com/sdk/docs/quickstart?hl=ko]하세요.

Flags parsing error: flag --connection_type=CLOUD_RESOURCE: value should be one of...

이후 단계에서 사용할 수 있도록 서비스 계정 ID를 가져와 복사합니다.

bq show --connection PROJECT_ID.REGION.CONNECTION_ID

출력은 다음과 비슷합니다.

name                          properties
1234.REGION.CONNECTION_ID     {"serviceAccountId": "connection-1234-9u56h9@gcp-sa-bigquery-condel.iam.gserviceaccount.com"}

--- 탭: Terraform [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#terraform] ---
google_bigquery_connection [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_connection] 리소스를 사용합니다.
참고: Terraform을 사용해서 BigQuery 객체를 만들려면 Cloud Resource Manager API [https://cloud.google.com/resource-manager/reference/rest?hl=ko]를 사용 설정해야 합니다.
BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다. 자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.

다음 예시에서는 US 리전에 my_cloud_resource_connection이라는 Cloud 리소스 연결을 만듭니다.























  
  
  
  
  





  
    
  
  

















  



  


  
# This queries the provider for project information.
data "google_project" "default" {}

# This creates a cloud resource connection in the US region named my_cloud_resource_connection.
# Note: The cloud resource nested object has only one output field - serviceAccountId.
resource "google_bigquery_connection" "default" {
  connection_id = "my_cloud_resource_connection"
  project       = data.google_project.default.project_id
  location      = "US"
  cloud_resource {}
}





























Google Cloud 프로젝트에 Terraform 구성을 적용하려면 다음 섹션의 단계를 완료하세요.
Cloud Shell 준비

  Cloud Shell [https://shell.cloud.google.com/?hl=ko]을 실행합니다.
  
    Terraform 구성을 적용할 기본 Google Cloud 프로젝트를 설정합니다.
    
    이 명령어는 프로젝트당 한 번만 실행하면 되며 어떤 디렉터리에서도 실행할 수 있습니다.
    export GOOGLE_CLOUD_PROJECT=PROJECT_ID
    Terraform 구성 파일에서 명시적 값을 설정하면 환경 변수가 재정의됩니다.
  

디렉터리 준비
각 Terraform 구성 파일에는 자체 디렉터리(루트 모듈이라고도 함)가 있어야 합니다.

  
    Cloud Shell [https://shell.cloud.google.com/?hl=ko]에서 디렉터리를 만들고 해당 디렉터리 내에 새 파일을 만드세요. 파일 이름에는 .tf 확장자가 있어야 합니다(예: main.tf). 이 튜토리얼에서는 파일을 main.tf라고 합니다.
    mkdir DIRECTORY && cd DIRECTORY && touch main.tf
  
  
    튜토리얼을 따라 하는 경우 각 섹션이나 단계에서 샘플 코드를 복사할 수 있습니다.
    샘플 코드를 새로 만든 main.tf에 복사합니다.
    필요한 경우 GitHub에서 코드를 복사합니다. 이는 Terraform 스니펫이 엔드 투 엔드 솔루션의 일부인 경우에 권장됩니다.
    
  
  환경에 적용할 샘플 매개변수를 검토하고 수정합니다.
  변경사항을 저장합니다.
  
    Terraform을 초기화합니다. 이 작업은 디렉터리당 한 번만 수행하면 됩니다.
    terraform init
    원하는 경우 최신 Google 공급업체 버전을 사용하려면 -upgrade 옵션을 포함합니다.
    
    terraform init -upgrade
  

변경사항 적용

  
    구성을 검토하고 Terraform에서 만들거나 업데이트할 리소스가 예상과 일치하는지 확인합니다.
    terraform plan
    필요에 따라 구성을 수정합니다.
  
  
    다음 명령어를 실행하고 프롬프트에 yes를 입력하여 Terraform 구성을 적용합니다.
    terraform apply
    Terraform에 '적용 완료' 메시지가 표시될 때까지 기다립니다.
  
  결과를 보려면 Google Cloud 프로젝트를 엽니다 [https://console.cloud.google.com/?hl=ko]. Google Cloud 콘솔에서 UI의 리소스로 이동하여 Terraform이 리소스를 만들었거나 업데이트했는지 확인합니다.
  

참고: Terraform 샘플은 일반적으로 필요한 API가 Google Cloud 프로젝트에서 사용 설정되었다고 가정합니다.
서비스 계정에 액세스 권한 부여
원격 모델이 사용하는 연결의 서비스 계정에 Vertex AI 사용자 역할을 부여해야 합니다. 원격 모델을 사용하여 객체 테이블 데이터에서 텍스트를 생성 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#generate_text_from_object_table_data]하는 경우 객체 테이블에서 사용하는 연결의 서비스 계정에 Vertex AI 사용자 역할도 부여해야 합니다.
원격 모델 연결의 서비스 계정에 역할 부여
원격 모델 연결의 서비스 계정에 Vertex AI 사용자 역할을 부여합니다.
원격 모델을 만들 때 엔드포인트를 URL(예: endpoint = 'https://us-central1-aiplatform.googleapis.com/v1/projects/myproject/locations/us-central1/publishers/google/models/text-embedding-004')로 지정할 계획이라면 URL에 지정한 동일한 프로젝트에서 이 역할을 부여합니다.
원격 모델을 만들 때 모델 이름을 사용(예: endpoint = 'text-embedding-004')하여 엔드포인트를 지정할 계획이라면 원격 모델을 만들려는 동일한 프로젝트에서 이 역할을 부여합니다.
다른 프로젝트에서 역할을 부여하면 bqcx-1234567890-xxxx@gcp-sa-bigquery-condel.iam.gserviceaccount.com does not have the permission to access resource 오류가 발생합니다.
역할을 부여하려면 다음 단계를 따르세요.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#%EC%BD%98%EC%86%94] ---
IAM 및 관리자 페이지로 이동합니다.

IAM 및 관리자로 이동 [https://console.cloud.google.com/project/_/iam-admin?hl=ko] 
person_add 추가를 클릭합니다.

주 구성원 추가 대화상자가 열립니다.
새 주 구성원 필드에 앞에서 복사한 서비스 계정 ID를 입력합니다.
역할 선택 필드에서 Vertex AI를 선택한 후 Vertex AI 사용자를 선택합니다.
저장을 클릭합니다.

--- 탭: gcloud [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gcloud] ---
gcloud projects add-iam-policy-binding 명령어 [https://cloud.google.com/sdk/gcloud/reference/projects/add-iam-policy-binding?hl=ko]를 사용합니다.

gcloud projects add-iam-policy-binding 'PROJECT_NUMBER' --member='serviceAccount:MEMBER' --role='roles/aiplatform.user' --condition=None


다음을 바꿉니다.

  PROJECT_NUMBER: 프로젝트 번호
  MEMBER: 이전에 복사한 서비스 계정 ID
객체 테이블 연결의 서비스 계정에 역할 부여
원격 모델을 사용하여 객체 테이블 데이터에서 텍스트를 생성하는 경우 객체 테이블 연결의 서비스 계정에 Vertex AI 사용자 역할을 부여합니다.
객체 테이블 연결의 서비스 계정을 찾으려면 다음 단계를 따르세요.
BigQuery 페이지로 이동합니다.
BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko]
탐색기 창에서 객체 테이블이 포함된 데이터 세트를 펼칩니다.
객체 테이블을 선택합니다.
편집기 창에서 세부정보 탭을 클릭합니다.
연결 ID 필드의 연결 이름을 기록합니다.
탐색기 창에서 외부 연결 폴더를 펼칩니다.
객체 테이블의 연결 ID 필드와 일치하는 연결을 선택합니다.
서비스 계정 ID 필드의 값을 복사합니다.
역할을 부여하려면 다음 단계를 따르세요.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#%EC%BD%98%EC%86%94] ---
IAM 및 관리자 페이지로 이동합니다.

IAM 및 관리자로 이동 [https://console.cloud.google.com/project/_/iam-admin?hl=ko] 
person_add 추가를 클릭합니다.

주 구성원 추가 대화상자가 열립니다.
새 주 구성원 필드에 앞에서 복사한 서비스 계정 ID를 입력합니다.
역할 선택 필드에서 Vertex AI를 선택한 후 Vertex AI 사용자를 선택합니다.
저장을 클릭합니다.

--- 탭: gcloud [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gcloud] ---
gcloud projects add-iam-policy-binding 명령어 [https://cloud.google.com/sdk/gcloud/reference/projects/add-iam-policy-binding?hl=ko]를 사용합니다.

gcloud projects add-iam-policy-binding 'PROJECT_NUMBER' --member='serviceAccount:MEMBER' --role='roles/aiplatform.user' --condition=None


다음을 바꿉니다.

  PROJECT_NUMBER: 프로젝트 번호
  MEMBER: 이전에 복사한 서비스 계정 ID
Anthropic Claude 모델 사용 설정
이 단계는 Claude 모델을 사용하려는 경우에만 필요합니다.
Google Cloud 콘솔에서 Vertex AI Model Garden 페이지로 이동합니다.
Model Garden으로 이동 [https://console.cloud.google.com/vertex-ai/model-garden?hl=ko]
사용할 Claude 모델을 검색하거나 탐색합니다.
모델 카드를 클릭합니다.
모델 페이지에서 사용 설정을 클릭합니다.
요청된 사용 설정 정보를 입력한 후 다음을 클릭합니다.
이용약관 섹션에서 체크박스를 선택합니다.
동의를 클릭하여 이용약관에 동의하고 모델을 사용 설정합니다.
개방형 모델 배포
지원되는 개방형 모델 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model-open?hl=ko#supported_open_models]을 사용하려면 먼저 해당 모델을 Vertex AI에 배포해야 합니다. 자세한 방법은 개방형 모델 배포 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model-open?hl=ko#deploy_open_models]를 참고하세요.
BigQuery ML 원격 모델 만들기
원격 모델을 만듭니다.
--- 탭: 모델 열기 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#%EB%AA%A8%EB%8D%B8-%EC%97%B4%EA%B8%B0] ---
Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.

BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko] 


SQL 편집기를 사용하여 원격 모델 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model-open?hl=ko]을 만듭니다.

CREATE OR REPLACE MODEL
`PROJECT_ID.DATASET_ID.MODEL_NAME`
REMOTE WITH CONNECTION `PROJECT_ID.REGION.CONNECTION_ID`
OPTIONS (ENDPOINT = 'https://ENDPOINT_REGION-aiplatform.googleapis.com/v1/projects/ENDPOINT_PROJECT_ID/locations/ENDPOINT_REGION/endpoints/ENDPOINT_ID');



다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델을 포함할 데이터 세트의 ID. 이 데이터 세트는 사용 중인 연결과 동일한 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]에 있어야 합니다.
  MODEL_NAME: 모델의 이름
  REGION: 연결에 사용되는 리전
  CONNECTION_ID: BigQuery 연결의 ID.
  Google Cloud 콘솔에서 연결 세부정보를 확인 [https://cloud.google.com/bigquery/docs/working-with-connections?hl=ko#view-connections]하고 연결 ID에 표시되는 정규화된 연결 ID의 마지막 섹션에 있는 값을 복사하여 이 값을 확인할 수 있습니다. 예를 들면 다음과 같습니다. projects/myproject/locations/connection_location/connections/myconnection
  

  ENDPOINT_REGION: 개방형 모델이 배포되는 리전입니다.
  ENDPOINT_PROJECT_ID: 개방형 모델이 배포된 프로젝트입니다.
  ENDPOINT_ID: 개방형 모델에서 사용하는 HTTPS 엔드포인트의 ID입니다. 온라인 예측 [https://console.cloud.google.com/vertex-ai/online-prediction/endpoints?hl=ko] 페이지에서 개방형 모델을 찾아 ID 필드의 값을 복사하여 엔드포인트 ID를 가져올 수 있습니다.

--- 탭: 다른 모든 모델 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#%EB%8B%A4%EB%A5%B8-%EB%AA%A8%EB%93%A0-%EB%AA%A8%EB%8D%B8] ---
Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.

BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko] 


SQL 편집기를 사용하여 원격 모델 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model?hl=ko]을 만듭니다.

CREATE OR REPLACE MODEL
`PROJECT_ID.DATASET_ID.MODEL_NAME`
REMOTE WITH CONNECTION `PROJECT_ID.REGION.CONNECTION_ID`
OPTIONS (ENDPOINT = 'ENDPOINT');



다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델을 포함할 데이터 세트의 ID. 이 데이터 세트는 사용 중인 연결과 동일한 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]에 있어야 합니다.
  MODEL_NAME: 모델의 이름
  REGION: 연결에 사용되는 리전
  CONNECTION_ID: BigQuery 연결의 ID.
  Google Cloud 콘솔에서 연결 세부정보를 확인 [https://cloud.google.com/bigquery/docs/working-with-connections?hl=ko#view-connections]하고 연결 ID에 표시되는 정규화된 연결 ID의 마지막 섹션에 있는 값을 복사하여 이 값을 확인할 수 있습니다. 예를 들면 다음과 같습니다. projects/myproject/locations/connection_location/connections/myconnection
  

  ENDPOINT: 사용할 Vertex AI 모델의 이름입니다.
  선행 학습된 Vertex AI 모델 및 Claude 모델의 경우 모델 이름을 지정합니다. 이러한 모델 중 일부의 경우 이름의 일부로 모델의 특정 버전 [https://cloud.google.com/vertex-ai/docs/generative-ai/learn/model-versioning?hl=ko]을 지정할 수 있습니다. 지원되는 모델 이름 및 버전에 관한 자세한 내용은 ENDPOINT [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model?hl=ko#endpoint]를 참고하세요.
중요: text-bison 및 text-unicorn 모델은 2025년 4월에 지원 중단됩니다. 이러한 모델 중 하나를 사용하는 원격 모델이 있는 경우 최대한 빨리 Gemini 1.5 모델 [https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models?hl=ko#gemini-models]로 마이그레이션하세요.
참고: gemini-1.0-pro-vision 모델을 사용하는 원격 모델이 있는 경우 성능을 개선하기 위해 Gemini 1.5 모델 [https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models?hl=ko#gemini-models]로 마이그레이션하는 것이 좋습니다.
테이블에서 프롬프트를 사용하여 텍스트 데이터에서 텍스트 생성
원격 모델에서 ML.GENERATE_TEXT 함수 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text?hl=ko]를 사용하고 테이블 열의 프롬프트 데이터를 사용하여 텍스트를 생성합니다.
--- 탭: gemini-2.0-flash [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-2.0-flash] ---
Preview
      
        
    
    

    
      
      
        This product or feature is subject to the "Pre-GA Offerings Terms" in the General Service Terms section
        of the Service Specific Terms [https://cloud.google.com/terms/service-terms?hl=ko#1].
        
        Pre-GA products and features are available "as is" and might have limited support.
      
      For more information, see the
      launch stage descriptions [https://cloud.google.com/products?hl=ko#product-launch-stages].
  
  
  





SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  GROUND_WITH_GOOGLE_SEARCH AS ground_with_google_search,
  SAFETY_SETTINGS AS safety_settings)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 프롬프트가 포함된 테이블의 이름. 이 테이블에는 이름이 prompt인 열이 있어야 합니다. 또는 별칭을 사용하여 다른 이름의 열을 사용할 수 있습니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE:
  
  토큰 선택에서 무작위성 수준을 제어하는 FLOAT64 값입니다. temperature 값은 0.0보다 크고 1.0보다 작거나 같아야 합니다.
  temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다.
   
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  GROUND_WITH_GOOGLE_SEARCH: 응답을 생성할 때 Vertex AI 모델이 Google 검색으로 그라운딩 [https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview?hl=ko#ground-public]을 사용할지 여부를 결정하는 BOOL 값입니다. 그라운딩을 통해 모델은 응답을 생성할 때 인터넷에서 추가 정보를 사용하여 보다 구체적이고 사실에 기반하는 모델 응답을 만들 수 있습니다. flatten_json_output 및 이 필드가 모두 True로 설정되면 결과에 추가 ml_generate_text_grounding_result 열이 포함되어 모델이 추가 정보를 수집하는 데 사용한 소스를 제공합니다. 기본값은 FALSE입니다.
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  


예시


다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


프롬프트에 prompts 테이블의 prompt 열을 사용합니다.
더 긴 응답을 반환합니다.
JSON 응답을 별도의 열로 평면화합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.flash_2_model`,
    TABLE mydataset.prompts,
    STRUCT(
      0.4 AS temperature, 8192 AS max_output_tokens,
      TRUE AS flatten_json_output));

--- 탭: gemini-1.5-flash [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-1.5-flash] ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  GROUND_WITH_GOOGLE_SEARCH AS ground_with_google_search,
  SAFETY_SETTINGS AS safety_settings)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 프롬프트가 포함된 테이블의 이름. 이 테이블에는 이름이 prompt인 열이 있어야 합니다. 또는 별칭을 사용하여 다른 이름의 열을 사용할 수 있습니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 1.0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  GROUND_WITH_GOOGLE_SEARCH: 응답을 생성할 때 Vertex AI 모델이 Google 검색으로 그라운딩 [https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview?hl=ko#ground-public]을 사용할지 여부를 결정하는 BOOL 값입니다. 그라운딩을 통해 모델은 응답을 생성할 때 인터넷에서 추가 정보를 사용하여 보다 구체적이고 사실에 기반하는 모델 응답을 만들 수 있습니다. flatten_json_output 및 이 필드가 모두 True로 설정되면 결과에 추가 ml_generate_text_grounding_result 열이 포함되어 모델이 추가 정보를 수집하는 데 사용한 소스를 제공합니다. 기본값은 FALSE입니다.
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  


예시


다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


프롬프트에 prompts 테이블의 prompt 열을 사용합니다.
짧은 응답을 반환합니다.
JSON 응답을 별도의 열로 평면화합니다.
대답 그라운딩을 위해 공개 웹 데이터를 검색하여 반환합니다.
두 가지 안전 설정을 사용하여 안전하지 않은 응답을 필터링합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    TABLE mydataset.prompts,
    STRUCT(
      100 AS max_output_tokens, 0.5 AS top_p,
      TRUE AS flatten_json_output,
      TRUE AS ground_with_google_search,
      [STRUCT('HARM_CATEGORY_HATE_SPEECH' AS category,
        'BLOCK_LOW_AND_ABOVE' AS threshold),
      STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category,
        'BLOCK_MEDIUM_AND_ABOVE' AS threshold)] AS safety_settings));

--- 탭: gemini-1.5-pro [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-1.5-pro] ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  GROUND_WITH_GOOGLE_SEARCH AS ground_with_google_search,
  SAFETY_SETTINGS AS safety_settings)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 프롬프트가 포함된 테이블의 이름. 이 테이블에는 이름이 prompt인 열이 있어야 합니다. 또는 별칭을 사용하여 다른 이름의 열을 사용할 수 있습니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 1.0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  GROUND_WITH_GOOGLE_SEARCH: 응답을 생성할 때 Vertex AI 모델이 Google 검색으로 그라운딩 [https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview?hl=ko#ground-public]을 사용할지 여부를 결정하는 BOOL 값입니다. 그라운딩을 통해 모델은 응답을 생성할 때 인터넷에서 추가 정보를 사용하여 보다 구체적이고 사실에 기반하는 모델 응답을 만들 수 있습니다. flatten_json_output 및 이 필드가 모두 True로 설정되면 결과에 추가 ml_generate_text_grounding_result 열이 포함되어 모델이 추가 정보를 수집하는 데 사용한 소스를 제공합니다. 기본값은 FALSE입니다.
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  


예시


다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


프롬프트에 prompts 테이블의 prompt 열을 사용합니다.
짧은 응답을 반환합니다.
JSON 응답을 별도의 열로 평면화합니다.
대답 그라운딩을 위해 공개 웹 데이터를 검색하여 반환합니다.
두 가지 안전 설정을 사용하여 안전하지 않은 응답을 필터링합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    TABLE mydataset.prompts,
    STRUCT(
      100 AS max_output_tokens, 0.5 AS top_p,
      TRUE AS flatten_json_output,
      TRUE AS ground_with_google_search,
      [STRUCT('HARM_CATEGORY_HATE_SPEECH' AS category,
        'BLOCK_LOW_AND_ABOVE' AS threshold),
      STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category,
        'BLOCK_MEDIUM_AND_ABOVE' AS threshold)] AS safety_settings));

--- 탭: gemini-pro [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-pro] ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_K AS top_k, TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  GROUND_WITH_GOOGLE_SEARCH AS ground_with_google_search,
  SAFETY_SETTINGS AS safety_settings)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 프롬프트가 포함된 테이블의 이름. 이 테이블에는 이름이 prompt인 열이 있어야 합니다. 또는 별칭을 사용하여 다른 이름의 열을 사용할 수 있습니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 40입니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  GROUND_WITH_GOOGLE_SEARCH: 응답을 생성할 때 Vertex AI 모델이 Google 검색으로 그라운딩 [https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview?hl=ko#ground-public]을 사용할지 여부를 결정하는 BOOL 값입니다. 그라운딩을 통해 모델은 응답을 생성할 때 인터넷에서 추가 정보를 사용하여 보다 구체적이고 사실에 기반하는 모델 응답을 만들 수 있습니다. flatten_json_output 및 이 필드가 모두 True로 설정되면 결과에 추가 ml_generate_text_grounding_result 열이 포함되어 모델이 추가 정보를 수집하는 데 사용한 소스를 제공합니다. 기본값은 FALSE입니다.
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  


예시


다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


프롬프트에 prompts 테이블의 prompt 열을 사용합니다.
다소 가능성이 있는 짧은 응답을 반환합니다.
JSON 응답을 별도의 열로 평면화합니다.
대답 그라운딩을 위해 공개 웹 데이터를 검색하여 반환합니다.
두 가지 안전 설정을 사용하여 안전하지 않은 응답을 필터링합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    TABLE mydataset.prompts,
    STRUCT(
      0.4 AS temperature, 100 AS max_output_tokens, 0.5 AS top_p,
      40 AS top_k, TRUE AS flatten_json_output,
      TRUE AS ground_with_google_search,
      [STRUCT('HARM_CATEGORY_HATE_SPEECH' AS category,
        'BLOCK_LOW_AND_ABOVE' AS threshold),
      STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category,
        'BLOCK_MEDIUM_AND_ABOVE' AS threshold)] AS safety_settings));

--- 탭: tabpanel-claude ---
Preview
      
        
    
    

    
      
      
        This product or feature is subject to the "Pre-GA Offerings Terms" in the General Service Terms section
        of the Service Specific Terms [https://cloud.google.com/terms/service-terms?hl=ko#1].
        
        Pre-GA products and features are available "as is" and might have limited support.
      
      For more information, see the
      launch stage descriptions [https://cloud.google.com/products?hl=ko#product-launch-stages].
  
  
  





SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(TOKENS AS max_output_tokens, TOP_K AS top_k,
  TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 프롬프트가 포함된 테이블의 이름. 이 테이블에는 이름이 prompt인 열이 있어야 합니다. 또는 별칭을 사용하여 다른 이름의 열을 사용할 수 있습니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  
  
  이 값은 [1,4096] 범위 내에 있어야 합니다.
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  
  


예시


다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


프롬프트에 prompts 테이블의 prompt 열을 사용합니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    TABLE mydataset.prompts,
    STRUCT(TRUE AS flatten_json_output));

--- 탭: tabpanel-모델-열기 ---
참고: 개방형 모델을 사용하려면 먼저 Vertex AI에 배포해야 합니다. 자세한 내용은 개방형 모델 배포 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#deploy_an_open_model]를 참고하세요.


SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(TOKENS AS max_output_tokens,
   TEMPERATURE AS temperature, TOP_K AS top_k,
  TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 프롬프트가 포함된 테이블의 이름. 이 테이블에는 이름이 prompt인 열이 있어야 합니다. 또는 별칭을 사용하여 다른 이름의 열을 사용할 수 있습니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  
  
  이 값은 [1,4096] 범위 내에 있어야 합니다.
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.


  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  
  


예시


다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


프롬프트에 prompts 테이블의 prompt 열을 사용합니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    TABLE mydataset.prompts,
    STRUCT(TRUE AS flatten_json_output));

--- 탭: tabpanel-text-bison ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_K AS top_k, TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 프롬프트가 포함된 테이블의 이름. 이 테이블에는 이름이 prompt인 열이 있어야 합니다. 또는 별칭을 사용하여 다른 이름의 열을 사용할 수 있습니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  이 값은 [1,1024] 범위 내에 있어야 합니다.
  
  
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 40입니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  


예시


다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


프롬프트에 prompts 테이블의 prompt 열을 사용합니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    TABLE mydataset.prompts,
    STRUCT(TRUE AS flatten_json_output));

--- 탭: tabpanel-text-bison32 ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_K AS top_k, TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 프롬프트가 포함된 테이블의 이름. 이 테이블에는 이름이 prompt인 열이 있어야 합니다. 또는 별칭을 사용하여 다른 이름의 열을 사용할 수 있습니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 40입니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  


예시


다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


프롬프트에 prompts 테이블의 prompt 열을 사용합니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    TABLE mydataset.prompts,
    STRUCT(TRUE AS flatten_json_output));

--- 탭: tabpanel-text-unicorn ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_K AS top_k, TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 프롬프트가 포함된 테이블의 이름. 이 테이블에는 이름이 prompt인 열이 있어야 합니다. 또는 별칭을 사용하여 다른 이름의 열을 사용할 수 있습니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  이 값은 [1,1024] 범위 내에 있어야 합니다.
  
  
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 40입니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  


예시


다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


프롬프트에 prompts 테이블의 prompt 열을 사용합니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    TABLE mydataset.prompts,
    STRUCT(TRUE AS flatten_json_output));
쿼리의 프롬프트를 사용하여 텍스트 데이터에서 텍스트 생성
원격 모델로 ML.GENERATE_TEXT 함수 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text?hl=ko]를 사용하고 프롬프트 데이터를 제공하는 쿼리를 사용하여 텍스트를 생성합니다.
--- 탭: gemini-2.0-flash [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-2.0-flash] ---
Preview
      
        
    
    

    
      
      
        This product or feature is subject to the "Pre-GA Offerings Terms" in the General Service Terms section
        of the Service Specific Terms [https://cloud.google.com/terms/service-terms?hl=ko#1].
        
        Pre-GA products and features are available "as is" and might have limited support.
      
      For more information, see the
      launch stage descriptions [https://cloud.google.com/products?hl=ko#product-launch-stages].
  
  
  





SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  (PROMPT_QUERY),
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  GROUND_WITH_GOOGLE_SEARCH AS ground_with_google_search,
  SAFETY_SETTINGS AS safety_settings)
);

다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID입니다.
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  PROMPT_QUERY: 프롬프트 데이터를 제공하는 쿼리
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE:
  
  토큰 선택에서 무작위성 수준을 제어하는 FLOAT64 값입니다. temperature 값은 0.0보다 크고 1.0보다 작거나 같아야 합니다.
  temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다.
   
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  GROUND_WITH_GOOGLE_SEARCH: 응답을 생성할 때 Vertex AI 모델이 Google 검색으로 그라운딩 [https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview?hl=ko#ground-public]을 사용할지 여부를 결정하는 BOOL 값입니다. 그라운딩을 통해 모델은 응답을 생성할 때 인터넷에서 추가 정보를 사용하여 보다 구체적이고 사실에 기반하는 모델 응답을 만들 수 있습니다. flatten_json_output 및 이 필드가 모두 True로 설정되면 결과에 추가 ml_generate_text_grounding_result 열이 포함되어 모델이 추가 정보를 수집하는 데 사용한 소스를 제공합니다. 기본값은 FALSE입니다.
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  



예시 1

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .05 AS TEMPERATURE,
      TRUE AS flatten_json_output));

예시 2

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


쿼리를 사용하여 테이블 열에 프롬프트 프리픽스 [https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-prompts?hl=ko#prompt_structure]를 제공하는 문자열을 연결하여 프롬프트 데이터를 만듭니다.
짧은 응답을 반환합니다.
모델의 JSON 응답을 별도의 열로 파싱하지 않습니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT(question, 'Text:', description, 'Category') AS prompt
      FROM mydataset.input_table
    ),
    STRUCT(
      100 AS max_output_tokens,
      .1 AS TEMPERATURE,
      FALSE AS flatten_json_output));



예시 3

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
JSON 응답을 별도의 열로 평면화합니다.
대답 그라운딩을 위해 공개 웹 데이터를 검색하여 반환합니다.
두 가지 안전 설정을 사용하여 안전하지 않은 응답을 필터링합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .1 AS TEMPERATURE,
      TRUE AS flatten_json_output, TRUE AS ground_with_google_search,
      [STRUCT('HARM_CATEGORY_HATE_SPEECH' AS category,
        'BLOCK_LOW_AND_ABOVE' AS threshold),
      STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category,
        'BLOCK_MEDIUM_AND_ABOVE' AS threshold)] AS safety_settings));

--- 탭: gemini-1.5-flash [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-1.5-flash] ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  (PROMPT_QUERY),
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  GROUND_WITH_GOOGLE_SEARCH AS ground_with_google_search,
  SAFETY_SETTINGS AS safety_settings)
);

다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID입니다.
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  PROMPT_QUERY: 프롬프트 데이터를 제공하는 쿼리
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 1.0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  GROUND_WITH_GOOGLE_SEARCH: 응답을 생성할 때 Vertex AI 모델이 Google 검색으로 그라운딩 [https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview?hl=ko#ground-public]을 사용할지 여부를 결정하는 BOOL 값입니다. 그라운딩을 통해 모델은 응답을 생성할 때 인터넷에서 추가 정보를 사용하여 보다 구체적이고 사실에 기반하는 모델 응답을 만들 수 있습니다. flatten_json_output 및 이 필드가 모두 True로 설정되면 결과에 추가 ml_generate_text_grounding_result 열이 포함되어 모델이 추가 정보를 수집하는 데 사용한 소스를 제공합니다. 기본값은 FALSE입니다.
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  



예시 1

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .05 AS TEMPERATURE,
      TRUE AS flatten_json_output));

예시 2

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


쿼리를 사용하여 테이블 열에 프롬프트 프리픽스 [https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-prompts?hl=ko#prompt_structure]를 제공하는 문자열을 연결하여 프롬프트 데이터를 만듭니다.
짧은 응답을 반환합니다.
모델의 JSON 응답을 별도의 열로 파싱하지 않습니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT(question, 'Text:', description, 'Category') AS prompt
      FROM mydataset.input_table
    ),
    STRUCT(
      100 AS max_output_tokens,
      .1 AS TEMPERATURE,
      FALSE AS flatten_json_output));



예시 3

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
JSON 응답을 별도의 열로 평면화합니다.
대답 그라운딩을 위해 공개 웹 데이터를 검색하여 반환합니다.
두 가지 안전 설정을 사용하여 안전하지 않은 응답을 필터링합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .1 AS TEMPERATURE,
      TRUE AS flatten_json_output, TRUE AS ground_with_google_search,
      [STRUCT('HARM_CATEGORY_HATE_SPEECH' AS category,
        'BLOCK_LOW_AND_ABOVE' AS threshold),
      STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category,
        'BLOCK_MEDIUM_AND_ABOVE' AS threshold)] AS safety_settings));

--- 탭: gemini-1.5-pro [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-1.5-pro] ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  (PROMPT_QUERY),
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  GROUND_WITH_GOOGLE_SEARCH AS ground_with_google_search,
  SAFETY_SETTINGS AS safety_settings)
);

다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID입니다.
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  PROMPT_QUERY: 프롬프트 데이터를 제공하는 쿼리
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 1.0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  GROUND_WITH_GOOGLE_SEARCH: 응답을 생성할 때 Vertex AI 모델이 Google 검색으로 그라운딩 [https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview?hl=ko#ground-public]을 사용할지 여부를 결정하는 BOOL 값입니다. 그라운딩을 통해 모델은 응답을 생성할 때 인터넷에서 추가 정보를 사용하여 보다 구체적이고 사실에 기반하는 모델 응답을 만들 수 있습니다. flatten_json_output 및 이 필드가 모두 True로 설정되면 결과에 추가 ml_generate_text_grounding_result 열이 포함되어 모델이 추가 정보를 수집하는 데 사용한 소스를 제공합니다. 기본값은 FALSE입니다.
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  



예시 1

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .05 AS TEMPERATURE,
      TRUE AS flatten_json_output));

예시 2

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


쿼리를 사용하여 테이블 열에 프롬프트 프리픽스 [https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-prompts?hl=ko#prompt_structure]를 제공하는 문자열을 연결하여 프롬프트 데이터를 만듭니다.
짧은 응답을 반환합니다.
모델의 JSON 응답을 별도의 열로 파싱하지 않습니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT(question, 'Text:', description, 'Category') AS prompt
      FROM mydataset.input_table
    ),
    STRUCT(
      100 AS max_output_tokens,
      .1 AS TEMPERATURE,
      FALSE AS flatten_json_output));



예시 3

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
JSON 응답을 별도의 열로 평면화합니다.
대답 그라운딩을 위해 공개 웹 데이터를 검색하여 반환합니다.
두 가지 안전 설정을 사용하여 안전하지 않은 응답을 필터링합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .1 AS TEMPERATURE,
      TRUE AS flatten_json_output, TRUE AS ground_with_google_search,
      [STRUCT('HARM_CATEGORY_HATE_SPEECH' AS category,
        'BLOCK_LOW_AND_ABOVE' AS threshold),
      STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category,
        'BLOCK_MEDIUM_AND_ABOVE' AS threshold)] AS safety_settings));

--- 탭: gemini-pro [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-pro] ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  (PROMPT_QUERY),
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_K AS top_k, TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  GROUND_WITH_GOOGLE_SEARCH AS ground_with_google_search,
  SAFETY_SETTINGS AS safety_settings)
);

다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID입니다.
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  PROMPT_QUERY: 프롬프트 데이터를 제공하는 쿼리
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 40입니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  GROUND_WITH_GOOGLE_SEARCH: 응답을 생성할 때 Vertex AI 모델이 Google 검색으로 그라운딩 [https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview?hl=ko#ground-public]을 사용할지 여부를 결정하는 BOOL 값입니다. 그라운딩을 통해 모델은 응답을 생성할 때 인터넷에서 추가 정보를 사용하여 보다 구체적이고 사실에 기반하는 모델 응답을 만들 수 있습니다. flatten_json_output 및 이 필드가 모두 True로 설정되면 결과에 추가 ml_generate_text_grounding_result 열이 포함되어 모델이 추가 정보를 수집하는 데 사용한 소스를 제공합니다. 기본값은 FALSE입니다.
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  



예시 1

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .05 AS TEMPERATURE,
      TRUE AS flatten_json_output));

예시 2

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


쿼리를 사용하여 테이블 열에 프롬프트 프리픽스 [https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-prompts?hl=ko#prompt_structure]를 제공하는 문자열을 연결하여 프롬프트 데이터를 만듭니다.
짧은 응답을 반환합니다.
모델의 JSON 응답을 별도의 열로 파싱하지 않습니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT(question, 'Text:', description, 'Category') AS prompt
      FROM mydataset.input_table
    ),
    STRUCT(
      100 AS max_output_tokens,
      .1 AS TEMPERATURE,
      FALSE AS flatten_json_output));



예시 3

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
JSON 응답을 별도의 열로 평면화합니다.
대답 그라운딩을 위해 공개 웹 데이터를 검색하여 반환합니다.
두 가지 안전 설정을 사용하여 안전하지 않은 응답을 필터링합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .1 AS TEMPERATURE,
      TRUE AS flatten_json_output, TRUE AS ground_with_google_search,
      [STRUCT('HARM_CATEGORY_HATE_SPEECH' AS category,
        'BLOCK_LOW_AND_ABOVE' AS threshold),
      STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category,
        'BLOCK_MEDIUM_AND_ABOVE' AS threshold)] AS safety_settings));

--- 탭: tabpanel-claude ---
Preview
      
        
    
    

    
      
      
        This product or feature is subject to the "Pre-GA Offerings Terms" in the General Service Terms section
        of the Service Specific Terms [https://cloud.google.com/terms/service-terms?hl=ko#1].
        
        Pre-GA products and features are available "as is" and might have limited support.
      
      For more information, see the
      launch stage descriptions [https://cloud.google.com/products?hl=ko#product-launch-stages].
  
  
  





SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  (PROMPT_QUERY),
  STRUCT(TOKENS AS max_output_tokens, TOP_K AS top_k,
  TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output)
);

다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID입니다.
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  PROMPT_QUERY: 프롬프트 데이터를 제공하는 쿼리
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  
  
  이 값은 [1,4096] 범위 내에 있어야 합니다.
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  
  



예시 1

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(TRUE AS flatten_json_output));

예시 2

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


쿼리를 사용하여 테이블 열에 프롬프트 프리픽스 [https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-prompts?hl=ko#prompt_structure]를 제공하는 문자열을 연결하여 프롬프트 데이터를 만듭니다.
짧은 응답을 반환합니다.
모델의 JSON 응답을 별도의 열로 파싱하지 않습니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT(question, 'Text:', description, 'Category') AS prompt
      FROM mydataset.input_table
    ),
    STRUCT(
      100 AS max_output_tokens,
      FALSE AS flatten_json_output));

--- 탭: tabpanel-모델-열기 ---
참고: 개방형 모델을 사용하려면 먼저 Vertex AI에 배포해야 합니다. 자세한 내용은 개방형 모델 배포 [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#deploy_an_open_model]를 참고하세요.


SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  (PROMPT_QUERY),
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_K AS top_k, TOP_P AS top_p,
  FLATTEN_JSON AS flatten_json_output)
);

다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID입니다.
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  PROMPT_QUERY: 프롬프트 데이터를 제공하는 쿼리
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  
  
  이 값은 [1,4096] 범위 내에 있어야 합니다.
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.


  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  값을 지정하지 않으면 모델에서 적절한 값을 결정합니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  
  



예시 1

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .05 AS TEMPERATURE,
      TRUE AS flatten_json_output));

예시 2

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


쿼리를 사용하여 테이블 열에 프롬프트 프리픽스 [https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-prompts?hl=ko#prompt_structure]를 제공하는 문자열을 연결하여 프롬프트 데이터를 만듭니다.
짧은 응답을 반환합니다.
모델의 JSON 응답을 별도의 열로 파싱하지 않습니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT(question, 'Text:', description, 'Category') AS prompt
      FROM mydataset.input_table
    ),
    STRUCT(
      100 AS max_output_tokens,
      .1 AS TEMPERATURE,
      FALSE AS flatten_json_output));

--- 탭: tabpanel-text-bison ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  (PROMPT_QUERY),
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_K AS top_k, TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences)
);

다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID입니다.
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  PROMPT_QUERY: 프롬프트 데이터를 제공하는 쿼리
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  이 값은 [1,1024] 범위 내에 있어야 합니다.
  
  
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 40입니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  



예시 1

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .05 AS TEMPERATURE,
      TRUE AS flatten_json_output));

예시 2

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


쿼리를 사용하여 테이블 열에 프롬프트 프리픽스 [https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-prompts?hl=ko#prompt_structure]를 제공하는 문자열을 연결하여 프롬프트 데이터를 만듭니다.
짧은 응답을 반환합니다.
모델의 JSON 응답을 별도의 열로 파싱하지 않습니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT(question, 'Text:', description, 'Category') AS prompt
      FROM mydataset.input_table
    ),
    STRUCT(
      100 AS max_output_tokens,
      .1 AS TEMPERATURE,
      FALSE AS flatten_json_output));

--- 탭: tabpanel-text-bison32 ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  (PROMPT_QUERY),
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_K AS top_k, TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences)
);

다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID입니다.
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  PROMPT_QUERY: 프롬프트 데이터를 제공하는 쿼리
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 40입니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  



예시 1

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .05 AS TEMPERATURE,
      TRUE AS flatten_json_output));

예시 2

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


쿼리를 사용하여 테이블 열에 프롬프트 프리픽스 [https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-prompts?hl=ko#prompt_structure]를 제공하는 문자열을 연결하여 프롬프트 데이터를 만듭니다.
짧은 응답을 반환합니다.
모델의 JSON 응답을 별도의 열로 파싱하지 않습니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT(question, 'Text:', description, 'Category') AS prompt
      FROM mydataset.input_table
    ),
    STRUCT(
      100 AS max_output_tokens,
      .1 AS TEMPERATURE,
      FALSE AS flatten_json_output));

--- 탭: tabpanel-text-unicorn ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  (PROMPT_QUERY),
  STRUCT(TOKENS AS max_output_tokens, TEMPERATURE AS temperature,
  TOP_K AS top_k, TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences)
);

다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID입니다.
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  PROMPT_QUERY: 프롬프트 데이터를 제공하는 쿼리
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  이 값은 [1,1024] 범위 내에 있어야 합니다.
  
  
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 40입니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  



예시 1

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


articles 테이블의 body 열에 있는 텍스트 요약을 요청하는 프롬프트입니다.
모델의 JSON 응답을 별도의 열로 파싱합니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT('Summarize this text', body) AS prompt
      FROM mydataset.articles
    ),
    STRUCT(
      .05 AS TEMPERATURE,
      TRUE AS flatten_json_output));

예시 2

다음 예시는 이러한 특성이 포함된 요청을 보여줍니다.


쿼리를 사용하여 테이블 열에 프롬프트 프리픽스 [https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-prompts?hl=ko#prompt_structure]를 제공하는 문자열을 연결하여 프롬프트 데이터를 만듭니다.
짧은 응답을 반환합니다.
모델의 JSON 응답을 별도의 열로 파싱하지 않습니다.


SELECT *
FROM
  ML.GENERATE_TEXT(
    MODEL `mydataset.text_model`,
    (
      SELECT CONCAT(question, 'Text:', description, 'Category') AS prompt
      FROM mydataset.input_table
    ),
    STRUCT(
      100 AS max_output_tokens,
      .1 AS TEMPERATURE,
      FALSE AS flatten_json_output));
객체 테이블 데이터에서 텍스트 생성
원격 모델로 ML.GENERATE_TEXT 함수 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text?hl=ko]를 사용하고, 객체 테이블을 사용하여 분석할 콘텐츠를 제공하고, prompt 매개변수에 프롬프트 데이터를 제공하여 텍스트를 생성합니다.
--- 탭: gemini-2.0-flash [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-2.0-flash] ---
Preview
      
        
    
    

    
      
      
        This product or feature is subject to the "Pre-GA Offerings Terms" in the General Service Terms section
        of the Service Specific Terms [https://cloud.google.com/terms/service-terms?hl=ko#1].
        
        Pre-GA products and features are available "as is" and might have limited support.
      
      For more information, see the
      launch stage descriptions [https://cloud.google.com/products?hl=ko#product-launch-stages].
  
  
  





SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(PROMPT AS prompt, TOKENS AS max_output_tokens,
  TEMPERATURE AS temperature, TOP_P AS top_p,
  FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  SAFETY_SETTINGS AS safety_settings)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 분석할 콘텐츠를 포함하는 객체 테이블 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko]의 이름입니다. 분석할 수 있는 콘텐츠 유형에 대한 자세한 내용은 입력 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text?hl=ko#input]을 참조하세요.
  객체 테이블에 사용되는 Cloud Storage 버킷은 모델을 만들고 ML.GENERATE_TEXT 함수를 호출하는 동일한 프로젝트에 있어야 합니다. 객체 테이블에서 사용하는 Cloud Storage 버킷이 포함된 프로젝트가 아닌 다른 프로젝트에서 ML.GENERATE_TEXT 함수를 호출하려면 service-A@gcp-sa-aiplatform.iam.gserviceaccount.com 서비스 계정에 버킷 수준에서 스토리지 관리자 역할을 부여 [https://cloud.google.com/storage/docs/access-control/using-iam-permissions?hl=ko#bucket-add]해야 합니다.
  
  PROMPT: 콘텐츠를 분석하는 데 사용할 프롬프트입니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE:
  
  토큰 선택에서 무작위성 수준을 제어하는 FLOAT64 값입니다. temperature 값은 0.0보다 크고 1.0보다 작거나 같아야 합니다.
  temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다.
   
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  


예시






이 예시에서는 feedback이라는 객체 테이블에서 오디오 콘텐츠를 번역하고 텍스트 변환합니다.

SELECT * FROM
  ML.GENERATE_TEXT(
    MODEL
      `mydataset.audio_model`,
        TABLE `mydataset.feedback`,
          STRUCT('What is the content of this audio clip, translated into Spanish?' AS PROMPT,
          .01 AS TEMPERATURE,
          TRUE AS FLATTEN_JSON_OUTPUT));

이 예시에서는 invoices라는 객체 테이블에서 PDF 콘텐츠를 분류합니다.

SELECT * FROM
  ML.GENERATE_TEXT(
    MODEL
      `mydataset.classify_model`,
        TABLE `mydataset.invoices`,
          STRUCT('Classify this document based on the invoice total, using the following categories: 0 to 100, 101 to 200, greater than 200' AS PROMPT,
          .5 AS TEMPERATURE,
          TRUE AS FLATTEN_JSON_OUTPUT));

--- 탭: gemini-1.5-flash [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-1.5-flash] ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(PROMPT AS prompt, TOKENS AS max_output_tokens,
  TEMPERATURE AS temperature, TOP_P AS top_p,
  FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  SAFETY_SETTINGS AS safety_settings)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 분석할 콘텐츠를 포함하는 객체 테이블 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko]의 이름입니다. 분석할 수 있는 콘텐츠 유형에 대한 자세한 내용은 입력 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text?hl=ko#input]을 참조하세요.
  객체 테이블에 사용되는 Cloud Storage 버킷은 모델을 만들고 ML.GENERATE_TEXT 함수를 호출하는 동일한 프로젝트에 있어야 합니다. 객체 테이블에서 사용하는 Cloud Storage 버킷이 포함된 프로젝트가 아닌 다른 프로젝트에서 ML.GENERATE_TEXT 함수를 호출하려면 service-A@gcp-sa-aiplatform.iam.gserviceaccount.com 서비스 계정에 버킷 수준에서 스토리지 관리자 역할을 부여 [https://cloud.google.com/storage/docs/access-control/using-iam-permissions?hl=ko#bucket-add]해야 합니다.
  
  PROMPT: 콘텐츠를 분석하는 데 사용할 프롬프트입니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 1.0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  


예시




이 예시에서는 feedback이라는 객체 테이블에서 오디오 콘텐츠를 번역하고 텍스트 변환합니다.

SELECT * FROM
  ML.GENERATE_TEXT(
    MODEL
      `mydataset.audio_model`,
        TABLE `mydataset.feedback`,
          STRUCT('What is the content of this audio clip, translated into Spanish?' AS PROMPT,
          TRUE AS FLATTEN_JSON_OUTPUT));

이 예시에서는 invoices라는 객체 테이블에서 PDF 콘텐츠를 분류합니다.

SELECT * FROM
  ML.GENERATE_TEXT(
    MODEL
      `mydataset.classify_model`,
        TABLE `mydataset.invoices`,
          STRUCT('Classify this document based on the invoice total, using the following categories: 0 to 100, 101 to 200, greater than 200' AS PROMPT,
          TRUE AS FLATTEN_JSON_OUTPUT));

--- 탭: gemini-1.5-pro [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-1.5-pro] ---
SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(PROMPT AS prompt, TOKENS AS max_output_tokens,
  TEMPERATURE AS temperature, TOP_P AS top_p,
  FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  SAFETY_SETTINGS AS safety_settings)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 분석할 콘텐츠를 포함하는 객체 테이블 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko]의 이름입니다. 분석할 수 있는 콘텐츠 유형에 대한 자세한 내용은 입력 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text?hl=ko#input]을 참조하세요.
  객체 테이블에 사용되는 Cloud Storage 버킷은 모델을 만들고 ML.GENERATE_TEXT 함수를 호출하는 동일한 프로젝트에 있어야 합니다. 객체 테이블에서 사용하는 Cloud Storage 버킷이 포함된 프로젝트가 아닌 다른 프로젝트에서 ML.GENERATE_TEXT 함수를 호출하려면 service-A@gcp-sa-aiplatform.iam.gserviceaccount.com 서비스 계정에 버킷 수준에서 스토리지 관리자 역할을 부여 [https://cloud.google.com/storage/docs/access-control/using-iam-permissions?hl=ko#bucket-add]해야 합니다.
  
  PROMPT: 콘텐츠를 분석하는 데 사용할 프롬프트입니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  이 값은 [1,8192] 범위 내에 있어야 합니다.
  
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 128입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 1.0입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  


예시




이 예시에서는 feedback이라는 객체 테이블에서 오디오 콘텐츠를 번역하고 텍스트 변환합니다.

SELECT * FROM
  ML.GENERATE_TEXT(
    MODEL
      `mydataset.audio_model`,
        TABLE `mydataset.feedback`,
          STRUCT('What is the content of this audio clip, translated into Spanish?' AS PROMPT,
          TRUE AS FLATTEN_JSON_OUTPUT));

이 예시에서는 invoices라는 객체 테이블에서 PDF 콘텐츠를 분류합니다.

SELECT * FROM
  ML.GENERATE_TEXT(
    MODEL
      `mydataset.classify_model`,
        TABLE `mydataset.invoices`,
          STRUCT('Classify this document based on the invoice total, using the following categories: 0 to 100, 101 to 200, greater than 200' AS PROMPT,
          TRUE AS FLATTEN_JSON_OUTPUT));

--- 탭: gemini-pro-vision [https://cloud.google.com/bigquery/docs/generate-text?hl=ko#gemini-pro-vision] ---
Preview
      
        
    
    

    
      
      
        This product or feature is subject to the "Pre-GA Offerings Terms" in the General Service Terms section
        of the Service Specific Terms [https://cloud.google.com/terms/service-terms?hl=ko#1].
        
        Pre-GA products and features are available "as is" and might have limited support.
      
      For more information, see the
      launch stage descriptions [https://cloud.google.com/products?hl=ko#product-launch-stages].
  
  
  





SELECT *
FROM ML.GENERATE_TEXT(
  MODEL `PROJECT_ID.DATASET_ID.MODEL_NAME`,
  TABLE PROJECT_ID.DATASET_ID.TABLE_NAME,
  STRUCT(PROMPT AS prompt, TOKENS AS max_output_tokens,
  TEMPERATURE AS temperature, TOP_K AS top_k,
  TOP_P AS top_p, FLATTEN_JSON AS flatten_json_output,
  STOP_SEQUENCES AS stop_sequences,
  SAFETY_SETTINGS AS safety_settings)
);


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID
  DATASET_ID: 모델이 포함된 데이터 세트의 ID
  MODEL_NAME: 모델의 이름
  TABLE_NAME: 분석할 콘텐츠를 포함하는 객체 테이블 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko]의 이름입니다. 분석할 수 있는 콘텐츠 유형에 대한 자세한 내용은 입력 [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text?hl=ko#input]을 참조하세요.
  객체 테이블에 사용되는 Cloud Storage 버킷은 모델을 만들고 ML.GENERATE_TEXT 함수를 호출하는 동일한 프로젝트에 있어야 합니다. 객체 테이블에서 사용하는 Cloud Storage 버킷이 포함된 프로젝트가 아닌 다른 프로젝트에서 ML.GENERATE_TEXT 함수를 호출하려면 service-A@gcp-sa-aiplatform.iam.gserviceaccount.com 서비스 계정에 버킷 수준에서 스토리지 관리자 역할을 부여 [https://cloud.google.com/storage/docs/access-control/using-iam-permissions?hl=ko#bucket-add]해야 합니다.
  
  PROMPT: 콘텐츠를 분석하는 데 사용할 프롬프트입니다.
  TOKENS: 대답에서 생성될 수 있는 토큰의 최대 개수를 설정하는 INT64 값입니다.
  
  
  
  이 값은 [1,2048] 범위 내에 있어야 합니다.
  
  짧은 응답이 필요하면 낮은 값을 지정하고 긴 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 2048입니다.
  
  
  
  
  TEMPERATURE: 토큰 선택에서 무작위성 수준을 제어하는 [0.0,1.0] 범위의 FLOAT64 값입니다.

기본값은 0.4입니다.temperature 값이 낮을수록 자유롭거나 창의적인 답변과 거리가 먼 확정적인 응답이 필요한 프롬프트에 적합하고, temperature 값이 높을수록 보다 다양하거나 창의적인 결과로 이어질 수 있습니다. temperature 값이 0이면 확정적입니다. 즉, 확률이 가장 높은 응답이 항상 선택됩니다.
  
  
  
  TOP_K: 모델이 선택에 고려해야 하는 토큰의 초기 풀을 결정하는 [1,40] 범위의 INT64 값. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 32입니다.
  
  
  
  TOP_P: [0.0,1.0] 범위의 FLOAT64 값은 토큰이 선택될 확률을 결정하는 데 도움이 됩니다. 임의성이 낮은 응답을 위해서는 낮은 값을 지정하고 임의성이 높은 응답을 위해서는 높은 값을 지정합니다.
  
  기본값은 0.95입니다.
  
  
  FLATTEN_JSON: 생성된 텍스트 및 보안 특성을 개별 열로 반환할지 여부를 결정하는 BOOL 값. 기본값은 FALSE입니다.
  
  STOP_SEQUENCES: 지정한 문자열이 모델의 응답에 포함된 경우 이 문자열을 제거하는 ARRAY<STRING> 값. 문자열은 대문자 사용을 비롯해 정확히 일치합니다. 기본값은 빈 배열입니다.
  
  
  
  SAFETY_SETTINGS: 응답을 필터링하도록 콘텐츠 안전 기준을 구성하는 ARRAY<STRUCT<STRING AS category, STRING AS threshold>> 값입니다. 구조체의 첫 번째 요소는 피해 카테고리를 지정하고 구조체의 두 번째 요소는 해당하는 차단 기준을 지정합니다. 모델은 이러한 설정을 위반하는 콘텐츠를 필터링합니다. 각 카테고리는 한 번만 지정할 수 있습니다. 예를 들어 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_MEDIUM_AND_ABOVE' AS threshold) 및 STRUCT('HARM_CATEGORY_DANGEROUS_CONTENT' AS category, 'BLOCK_ONLY_HIGH' AS threshold)를 모두 지정할 수 없습니다. 지정된 카테고리에 안전 설정이 없는 경우 BLOCK_MEDIUM_AND_ABOVE 안전 설정이 사용됩니다.

지원되는 카테고리는 다음과 같습니다.


  HARM_CATEGORY_HATE_SPEECH
  HARM_CATEGORY_DANGEROUS_CONTENT
  HARM_CATEGORY_HARASSMENT
  HARM_CATEGORY_SEXUALLY_EXPLICIT
  

지원되는 기준은 다음과 같습니다.


  BLOCK_NONE(제한됨 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#how_to_remove_automated_response_blocking_for_select_safety_attributes])
  BLOCK_LOW_AND_ABOVE
  BLOCK_MEDIUM_AND_ABOVE(기본값)
  BLOCK_ONLY_HIGH
  HARM_BLOCK_THRESHOLD_UNSPECIFIED
  

자세한 내용은 안전 카테고리 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety_attribute_scoring] 및 차단 기준 [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes?hl=ko#safety-settings]의 정의를 참고하세요.
  
  


예시


이 예시는 이름이 videos인 객체 테이블에서 동영상 콘텐츠를 분석하고 각 동영상의 콘텐츠를 설명합니다.

SELECT * FROM
  ML.GENERATE_TEXT(
    MODEL
      `mydataset.video_model`,
        TABLE `mydataset.videos`,
          STRUCT('What is happening in this video?' AS PROMPT,
          TRUE AS FLATTEN_JSON_OUTPUT));
도움이 되었나요?
의견 보내기