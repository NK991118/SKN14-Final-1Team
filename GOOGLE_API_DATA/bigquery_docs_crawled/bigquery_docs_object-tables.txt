Source URL: https://cloud.google.com/bigquery/docs/object-tables

BigQuery [https://cloud.google.com/bigquery?hl=ko]
Documentation [https://cloud.google.com/bigquery/docs?hl=ko]
가이드 [https://cloud.google.com/bigquery/docs/introduction?hl=ko]
도움이 되었나요?
의견 보내기
이 페이지의 내용
시작하기 전에 [https://cloud.google.com/bigquery/docs/object-tables?hl=ko#before_you_begin]
필요한 역할 [https://cloud.google.com/bigquery/docs/object-tables?hl=ko#required_roles]
객체 테이블 만들기 [https://cloud.google.com/bigquery/docs/object-tables?hl=ko#create-object-table]
객체 테이블 쿼리 [https://cloud.google.com/bigquery/docs/object-tables?hl=ko#query-object-tables]
다음 단계 [https://cloud.google.com/bigquery/docs/object-tables?hl=ko#whats_next]
객체 테이블 만들기
bookmark_border
이 문서에서는 객체 테이블 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko]을 만들어 BigQuery에서 구조화되지 않은 데이터에 액세스하는 방법을 설명합니다.
객체 테이블을 만들려면 다음 태스크를 완료해야 합니다.
Cloud Storage에서 객체 정보를 읽도록 연결 [https://cloud.google.com/bigquery/docs/connections-api-intro?hl=ko]을 만듭니다.
연결과 연결된 서비스 계정에 스토리지 객체 뷰어(roles/storage.objectViewer) 역할을 부여합니다.
CREATE EXTERNAL TABLE 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#create_external_table_statement]을 사용하여 객체 테이블을 만들고 연결과 연결합니다.
시작하기 전에
Sign in to your Google Cloud account. If you're new to Google Cloud, create an account [https://console.cloud.google.com/freetrial?hl=ko] to evaluate how our products perform in real-world scenarios. New customers also get $300 in free credits to run, test, and deploy workloads.
In the Google Cloud console, on the project selector page, select or create a Google Cloud project.
Note: If you don't plan to keep the resources that you create in this procedure, create a project instead of selecting an existing project. After you finish these steps, you can delete the project, removing all resources associated with the project.
Go to project selector [https://console.cloud.google.com/projectselector2/home/dashboard?hl=ko]
Verify that billing is enabled for your Google Cloud project [https://cloud.google.com/billing/docs/how-to/verify-billing-enabled?hl=ko#confirm_billing_is_enabled_on_a_project].
Enable the BigQuery and BigQuery Connection API APIs.
Enable the APIs [https://console.cloud.google.com/flows/enableapi?apiid=bigquery.googleapis.com%2Cbigqueryconnection.googleapis.com&hl=ko]
BigQuery 관리자가 연결을 만들고 [https://cloud.google.com/bigquery/docs/create-cloud-resource-connection?hl=ko#create-cloud-resource-connection] Cloud Storage에 대한 액세스를 설정 [https://cloud.google.com/bigquery/docs/create-cloud-resource-connection?hl=ko#access-storage]했는지 확인합니다.
필요한 역할
객체 테이블 작업을 수행하려면 조직 내 역할에 따라 사용자에게 다음 IAM 권한이 필요합니다. 사용자 역할에 대한 자세한 내용은 보안 모델 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko#security_model]을 참조하세요. 권한 부여에 대한 자세한 내용은 리소스에 대해 부여할 수 있는 역할 보기 [https://cloud.google.com/iam/docs/viewing-grantable-roles?hl=ko]를 참조하세요.
데이터 레이크 관리자
Cloud Storage에 연결 [https://cloud.google.com/bigquery/docs/create-cloud-resource-connection?hl=ko]하는 데 필요한 권한을 얻으려면 관리자에게 프로젝트에 대한 BigQuery 연결 관리자(roles/bigquery.connectionAdmin) 역할을 부여해 달라고 요청하세요.
Cloud Storage 버킷을 생성하고 관리 [https://cloud.google.com/storage/docs/creating-buckets?hl=ko]하는 데 필요한 권한을 얻으려면 관리자에게 스토리지 관리자에게 프로젝트에 대한 스토리지 관리자(roles/storage.admin) 역할을 부여해 달라고 요청하세요.
이 사전 정의된 역할에는 Cloud Storage에 연결하고 Cloud Storage 버킷을 만들고 관리하는 데 필요한 권한이 포함되어 있습니다. 필요한 정확한 권한을 보려면 필수 권한 섹션을 확장하세요.
필수 권한
데이터 웨어하우스 관리자
객체 테이블을 생성 [https://cloud.google.com/bigquery/docs/object-tables?hl=ko#create-object-table]하는 데 필요한 권한을 얻으려면 관리자에게 프로젝트에 대한 다음 역할을 부여해 달라고 요청하세요.
BigQuery 데이터 편집자(roles/bigquery.dataEditor) 역할
BigQuery 연결 관리자(roles/bigquery.connectionAdmin) 역할
이 사전 정의된 역할에는 객체 테이블을 만드는 데 필요한 권한이 포함됩니다. 필요한 정확한 권한을 보려면 필수 권한 섹션을 확장하세요.
필수 권한
데이터 분석가
객체 테이블을 쿼리 [https://cloud.google.com/bigquery/docs/object-tables?hl=ko#query-object-tables]하는 데 필요한 권한을 얻으려면 관리자에게 프로젝트에 대한 다음 역할을 부여해 달라고 요청하세요.
BigQuery 데이터 뷰어(roles/bigquery.dataViewer) 역할
BigQuery 연결 사용자(roles/bigquery.connectionUser) 역할
이 사전 정의된 역할에는 객체 테이블을 쿼리하는 데 필요한 권한이 포함되어 있습니다. 필요한 정확한 권한을 보려면 필수 권한 섹션을 확장하세요.
필수 권한
커스텀 역할 [https://cloud.google.com/iam/docs/creating-custom-roles?hl=ko]이나 다른 사전 정의된 역할 [https://cloud.google.com/iam/docs/understanding-roles?hl=ko]을 사용하여 이 권한을 부여받을 수도 있습니다.
주의: 데이터 분석가에게 다음 권한이 부여되면 안 됩니다.
Cloud Storage에서 직접 객체를 읽을 수 있는 권한(스토리지 객체 뷰어 IAM 역할 [https://cloud.google.com/storage/docs/access-control/iam-roles?hl=ko] 참조): 데이터 웨어하우스 관리자가 설정한 액세스 제어를 데이터 분석가가 우회할 수 있습니다.
(BigQuery 연결 관리자처럼) 테이블을 연결에 결합할 수 있는 권한
그렇지 않으면 데이터 분석가가 액세스 제어가 없는 새로운 객체 테이블을 만들어 데이터 웨어하우스 관리자가 설정한 제어를 우회할 수 있습니다.
객체 테이블 만들기
객체 테이블을 만들려면 먼저 이를 포함할 기존 데이터 세트가 있어야 합니다. 자세한 내용은 데이터 세트 만들기 [https://cloud.google.com/bigquery/docs/datasets?hl=ko]를 참조하세요.
객체 테이블을 만들려면 다음 안내를 따르세요.
--- 탭: SQL [https://cloud.google.com/bigquery/docs/object-tables?hl=ko#sql] ---
CREATE EXTERNAL TABLE 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#create_external_table_statement]을 사용합니다.






 Google Cloud 콘솔에서 BigQuery 페이지로 이동합니다.

BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko] 
쿼리 편집기에서 다음 문을 입력합니다.

CREATE EXTERNAL TABLE `PROJECT_ID.DATASET_ID.TABLE_NAME`
WITH CONNECTION {`PROJECT_ID.REGION.CONNECTION_ID`| DEFAULT}
OPTIONS(
  object_metadata = 'SIMPLE',
  uris = ['BUCKET_PATH'[,...]],
  max_staleness = STALENESS_INTERVAL,
  metadata_cache_mode = 'CACHE_MODE');


다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID입니다.
  DATASET_ID: 객체 테이블을 포함할 데이터 세트의 ID입니다.
  TABLE_NAME: 객체 테이블의 이름입니다.
  REGION: 연결이 포함된 리전 또는 멀티 리전 [https://cloud.google.com/bigquery/docs/locations?hl=ko#supported_locations]입니다.
  CONNECTION_ID: 이 객체 테이블에 사용할 클라우드 리소스 연결 [https://cloud.google.com/bigquery/docs/connections-api-intro?hl=ko]의 ID입니다. 연결은 Cloud Storage에서 데이터를 읽는 데 사용되는 서비스 계정을 결정합니다.
   Google Cloud 콘솔에서 연결 세부정보를 볼 때 [https://cloud.google.com/bigquery/docs/working-with-connections?hl=ko#view-connections] 연결 ID는 연결 ID에 표시되는 정규화된 연결 ID의 마지막 섹션에 있는 값입니다(예: projects/myproject/locations/connection_location/connections/myconnection).
  기본 연결 [https://cloud.google.com/bigquery/docs/default-connections?hl=ko]을 사용하려면 PROJECT_ID.REGION.CONNECTION_ID가 포함된 연결 문자열 대신 DEFAULT를 지정합니다.
 
  BUCKET_PATH: ['gs://bucket_name/[folder_name/]*'] 형식으로 객체 테이블에서 참조되는 객체가 포함된 Cloud Storage 버킷의 경로입니다.
  각 경로에 하나의 별표(*) 와일드 카드 문자를 사용하여 객체 테이블에 포함된 객체를 제한할 수 있습니다.
  예를 들어 버킷에 여러 유형의 구조화되지 않은 데이터가 있는 경우 ['gs://bucket_name/*.pdf']를 지정하여 PDF 객체에 대해서만 객체 테이블을 만들 수 있습니다. 자세한 내용은 Cloud Storage URI의 와일드 카드 지원 [https://cloud.google.com/bigquery/docs/external-data-cloud-storage?hl=ko#wildcard-support]을 참조하세요.
  ['gs://mybucket1/*', 'gs://mybucket2/folder5/*']와 같이 여러 경로를 제공하여 uris 옵션에 대해 여러 버킷을 지정할 수 있습니다.
  BigQuery에서 Cloud Storage URI를 사용하는 방법에 대한 자세한 내용은 Cloud Storage 리소스 경로 [https://cloud.google.com/bigquery/docs/external-data-cloud-storage?hl=ko#google-cloud-storage-uri]를 참조하세요.
  STALENESS_INTERVAL: 캐시된 메타데이터가 객체 테이블에 대한 작업에서 사용되는지 여부와 작업이 사용하기 위해 캐시된 메타데이터가 작업에서 사용되려면 얼마나 최신이어야 하는지를 지정합니다. 메타데이터 캐싱 고려사항에 대한 자세한 내용은 성능을 위한 메타데이터 캐싱 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko#metadata_caching_for_performance]을 참조하세요.
  메타데이터 캐싱을 사용 중지하려면 0을 지정합니다. 이 값이 기본값입니다.
  메타데이터 캐싱을 사용 설정하려면 30분에서 7일 사이의 간격 리터럴 [https://cloud.google.com/bigquery/docs/reference/standard-sql/lexical?hl=ko#interval_literals] 값을 지정합니다. 예를 들어 4시간 비활성 간격의 경우 INTERVAL 4 HOUR를 지정합니다.
   이 값을 사용하면 지난 4시간 이내에 새로고침된 경우 테이블에 대한 작업이 캐시된 메타데이터를 사용합니다. 캐시된 메타데이터가 이보다 오래된 경우 작업이 대신 Cloud Storage에서 메타데이터를 검색합니다.
  
  CACHE_MODE: 메타데이터 캐시를 자동 또는 수동으로 새로고침할지 지정합니다. 메타데이터 캐싱 고려사항에 대한 자세한 내용은 성능을 위한 메타데이터 캐싱 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko#metadata_caching_for_performance]을 참조하세요.
  시스템 정의 간격(일반적으로 30~60분)으로 메타데이터 캐시를 새로고침하려면 AUTOMATIC으로 설정합니다.
  지정한 일정에 따라 메타데이터 캐시를 새로고침하려면 MANUAL로 설정합니다. 이 경우 BQ.REFRESH_EXTERNAL_METADATA_CACHE 시스템 프로시져 [https://cloud.google.com/bigquery/docs/reference/system-procedures?hl=ko#bqrefresh_external_metadata_cache]를 호출하여 캐시를 새로고침할 수 있습니다.
  STALENESS_INTERVAL이 0보다 큰 값으로 설정된 경우 CACHE_MODE를 설정해야 합니다.


play_circle 실행을 클릭합니다.




쿼리를 실행하는 방법에 대한 자세한 내용은 대화형 쿼리 실행 [https://cloud.google.com/bigquery/docs/running-queries?hl=ko#queries]을 참조하세요.

예시

다음 예시에서는 메타데이터 캐시 비활성 간격을 1일로 사용해서 객체 테이블을 만듭니다.

CREATE EXTERNAL TABLE `my_dataset.object_table`
WITH CONNECTION `us.my-connection`
OPTIONS(
  object_metadata = 'SIMPLE',
  uris = ['gs://mybucket/*'],
  max_staleness = INTERVAL 1 DAY,
  metadata_cache_mode = 'AUTOMATIC'
);

다음 예시에서는 3개의 Cloud Storage 버킷에 있는 객체로 객체 테이블을 만듭니다.

CREATE EXTERNAL TABLE `my_dataset.object_table`
WITH CONNECTION `us.my-connection`
OPTIONS(
  object_metadata = 'SIMPLE',
  uris = ['gs://bucket1/*','gs://bucket2/folder1/*','gs://bucket3/*']
);

다음 예시에서는 Cloud Storage 버킷에서 PDF 객체만으로 객체 테이블을 만듭니다.

CREATE EXTERNAL TABLE `my_dataset.object_table`
WITH CONNECTION `us.my-connection`
OPTIONS(
  object_metadata = 'SIMPLE',
  uris = ['gs://bucket1/*.pdf']
);

--- 탭: bq [https://cloud.google.com/bigquery/docs/object-tables?hl=ko#bq] ---
bq mk 명령어 [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#mk-table]를 사용합니다.

bq mk --table \
--external_table_definition=BUCKET_PATH@REGION.CONNECTION_ID \
--object_metadata=SIMPLE \
--max_staleness=STALENESS_INTERVAL \
--metadata_cache_mode=CACHE_MODE \
PROJECT_ID:DATASET_ID.TABLE_NAME

다음을 바꿉니다.

  PROJECT_ID: 프로젝트 ID입니다.
  DATASET_ID: 객체 테이블을 포함할 데이터 세트의 ID입니다.
  TABLE_NAME: 객체 테이블의 이름입니다.
  REGION: 연결이 포함된 리전 또는 멀티 리전 [https://cloud.google.com/bigquery/docs/locations?hl=ko#supported_locations]입니다.
  CONNECTION_ID: 이 외부 테이블에 사용할 클라우드 리소스 연결 [https://cloud.google.com/bigquery/docs/working-with-connections?hl=ko]의 ID입니다. 연결은 Cloud Storage에서 데이터를 읽는 데 사용되는 서비스 계정을 결정합니다.
   Google Cloud 콘솔에서 연결 세부정보를 볼 때 [https://cloud.google.com/bigquery/docs/working-with-connections?hl=ko#view-connections] 연결 ID는 연결 ID에 표시되는 정규화된 연결 ID의 마지막 섹션에 있는 값입니다(예: projects/myproject/locations/connection_location/connections/myconnection).
  
  BUCKET_PATH: gs://bucket_name/[folder_name/]* 형식으로 객체 테이블에서 참조되는 객체가 포함된 Cloud Storage 버킷의 경로입니다.
  각 경로에 하나의 별표(*) 와일드 카드 문자를 사용하여 객체 테이블에 포함된 객체를 제한할 수 있습니다.
  예를 들어 버킷에 여러 유형의 구조화되지 않은 데이터가 있는 경우 gs://bucket_name/*.pdf를 지정하여 PDF 객체에 대해서만 객체 테이블을 만들 수 있습니다. 자세한 내용은 Cloud Storage URI의 와일드 카드 지원 [https://cloud.google.com/bigquery/docs/external-data-cloud-storage?hl=ko#wildcard-support]을 참조하세요.
  gs://mybucket1/*,gs://mybucket2/folder5/*와 같이 여러 경로를 제공하여 uris 옵션에 대해 여러 버킷을 지정할 수 있습니다.
  BigQuery에서 Cloud Storage URI를 사용하는 방법에 대한 자세한 내용은 Cloud Storage 리소스 경로 [https://cloud.google.com/bigquery/docs/external-data-cloud-storage?hl=ko#google-cloud-storage-uri]를 참조하세요.
  STALENESS_INTERVAL: 캐시된 메타데이터가 객체 테이블에 대한 작업에서 사용되는지 여부와 작업이 사용하기 위해 캐시된 메타데이터가 작업에서 사용되려면 얼마나 최신이어야 하는지를 지정합니다. 메타데이터 캐싱 고려사항에 대한 자세한 내용은 성능을 위한 메타데이터 캐싱 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko#metadata_caching_for_performance]을 참조하세요.
  메타데이터 캐싱을 사용 중지하려면 0을 지정합니다. 이 값이 기본값입니다.
  메타데이터 캐싱을 사용 설정하려면 INTERVAL 데이터 유형 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko#interval_type] 문서에 설명된 Y-M D H:M:S 형식을 사용하여 30분에서 7일 사이의 간격 값을 지정합니다. 예를 들어 4시간 비활성 간격의 경우 0-0 0 4:0:0를 지정합니다.
  이 값을 사용하면 지난 4시간 이내에 새로고침된 경우 테이블에 대한 작업이 캐시된 메타데이터를 사용합니다. 캐시된 메타데이터가 이보다 오래된 경우 작업이 대신 Cloud Storage에서 메타데이터를 검색합니다.
  
  CACHE_MODE: 메타데이터 캐시를 자동 또는 수동으로 새로고침할지 지정합니다. 메타데이터 캐싱 고려사항에 대한 자세한 내용은 성능을 위한 메타데이터 캐싱 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko#metadata_caching_for_performance]을 참조하세요.
  시스템 정의 간격(일반적으로 30~60분)으로 메타데이터 캐시를 새로고침하려면 AUTOMATIC으로 설정합니다.
  지정한 일정에 따라 메타데이터 캐시를 새로고침하려면 MANUAL로 설정합니다. 이 경우 BQ.REFRESH_EXTERNAL_METADATA_CACHE 시스템 프로시져 [https://cloud.google.com/bigquery/docs/reference/system-procedures?hl=ko#bqrefresh_external_metadata_cache]를 호출하여 캐시를 새로고침할 수 있습니다.
  STALENESS_INTERVAL이 0보다 큰 값으로 설정된 경우 CACHE_MODE를 설정해야 합니다.


예시

다음 예시에서는 메타데이터 캐시 비활성 간격을 1일로 사용해서 객체 테이블을 만듭니다.

bq mk --table \
--external_table_definition=gs://mybucket/*@us.my-connection \
--object_metadata=SIMPLE \
--max_staleness=0-0 1 0:0:0 \
--metadata_cache_mode=AUTOMATIC \
my_dataset.object_table

다음 예시에서는 3개의 Cloud Storage 버킷에 있는 객체로 객체 테이블을 만듭니다.

bq mk --table \
--external_table_definition=gs://bucket1/*,gs://bucket2/folder1/*,gs://bucket3/*@us.my-connection \
--object_metadata=SIMPLE \
my_dataset.object_table

다음 예시에서는 Cloud Storage 버킷에서 PDF 객체만으로 객체 테이블을 만듭니다.

bq mk --table \
--external_table_definition=gs://bucket1/*.pdf@us.my-connection \
--object_metadata=SIMPLE \
my_dataset.object_table

--- 탭: API [https://cloud.google.com/bigquery/docs/object-tables?hl=ko#api] ---
tables.insert 메서드 [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/insert?hl=ko]를 호출합니다.
전달하는 Table 리소스 [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables?hl=ko#resource:-table]에서 objectMetadata 필드가 SIMPLE로 설정된 ExternalDataConfiguration 객체 [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables?hl=ko#ExternalDataConfiguration]를 포함합니다.

다음 예시에서는 curl을 사용하여 이 메서드를 호출하는 방법을 보여줍니다.
ACCESS_TOKEN=$(gcloud auth print-access-token) curl \
-H "Authorization: Bearer ${ACCESS_TOKEN}" \
-H "Content-Type: application/json" \
-X POST \
-d '{"tableReference": {"projectId": "my_project", "datasetId": "my_dataset", "tableId": "object_table_name"}, "externalDataConfiguration": {"objectMetadata": "SIMPLE", "sourceUris": ["gs://mybucket/*"]}}' \
https://www.googleapis.com/bigquery/v2/projects/my_project/datasets/my_dataset/tables

--- 탭: Terraform [https://cloud.google.com/bigquery/docs/object-tables?hl=ko#terraform] ---
이 예시에서는 수동 새로고침으로 메타데이터 캐싱이 사용 설정된 객체 테이블을 만듭니다.

BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다. 자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.

객체 테이블에 지정할 키 필드는 google_bigquery_table.external_data_configuration.object_metadata [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_table.html#object_metadata], google_bigquery_table.external_data_configuration.metadata_cache_mode [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_table.html#metadata_cache_mode], google_bigquery_table.max_staleness [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_table.html#max_staleness]입니다. 각 리소스에 대한 자세한 내용은 Terraform BigQuery 문서 [https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_table.html]를 참조하세요.
    




















  





  
    
  
  











  









  




  



  


  
# This queries the provider for project information.
data "google_project" "default" {}

# This creates a connection in the US region named "my-connection-id".
# This connection is used to access the bucket.
resource "google_bigquery_connection" "default" {
  connection_id = "my-connection-id"
  location      = "US"
  cloud_resource {}
}

# This grants the previous connection IAM role access to the bucket.
resource "google_project_iam_member" "default" {
  role    = "roles/storage.objectViewer"
  project = data.google_project.default.project_id
  member  = "serviceAccount:${google_bigquery_connection.default.cloud_resource[0].service_account_id}"
}

# This defines a Google BigQuery dataset.
resource "google_bigquery_dataset" "default" {
  dataset_id = "my_dataset_id"
}

# This creates a bucket in the US region named "my-bucket" with a pseudorandom suffix.
resource "random_id" "bucket_name_suffix" {
  byte_length = 8
}
resource "google_storage_bucket" "default" {
  name                        = "my-bucket-${random_id.bucket_name_suffix.hex}"
  location                    = "US"
  force_destroy               = true
  uniform_bucket_level_access = true
}

# This defines a BigQuery object table with manual metadata caching.
resource "google_bigquery_table" "default" {
  deletion_protection = false
  table_id            = "my-table-id"
  dataset_id          = google_bigquery_dataset.default.dataset_id
  external_data_configuration {
    connection_id = google_bigquery_connection.default.name
    autodetect    = false
    # `object_metadata is` required for object tables. For more information, see
    # https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_table#object_metadata
    object_metadata = "SIMPLE"
    # This defines the source for the prior object table.
    source_uris = [
      "gs://${google_storage_bucket.default.name}/*",
    ]

    metadata_cache_mode = "MANUAL"
  }

  # This ensures that the connection can access the bucket
  # before Terraform creates a table.
  depends_on = [
    google_project_iam_member.default
  ]
}




























프로젝트에 Terraform 구성을 적용하려면 Google Cloud 다음 섹션의 단계를 완료하세요.
Cloud Shell 준비

  Cloud Shell [https://shell.cloud.google.com/?hl=ko]을 실행합니다.
  
    Terraform 구성을 적용할 기본 Google Cloud 프로젝트를 설정합니다.
    이 명령어는 프로젝트당 한 번만 실행하면 되며 어떤 디렉터리에서도 실행할 수 있습니다.
    export GOOGLE_CLOUD_PROJECT=PROJECT_ID
    Terraform 구성 파일에서 명시적 값을 설정하면 환경 변수가 재정의됩니다.
  

디렉터리 준비
각 Terraform 구성 파일에는 자체 디렉터리(루트 모듈이라고도 함)가 있어야 합니다.

  
    Cloud Shell [https://shell.cloud.google.com/?hl=ko]에서 디렉터리를 만들고 해당 디렉터리 내에 새 파일을 만드세요. 파일 이름에는 .tf 확장자가 있어야 합니다(예: main.tf). 이 튜토리얼에서는 파일을 main.tf라고 합니다.
    mkdir DIRECTORY && cd DIRECTORY && touch main.tf
  
  
    튜토리얼을 따라 하는 경우 각 섹션이나 단계에서 샘플 코드를 복사할 수 있습니다.
    샘플 코드를 새로 만든 main.tf에 복사합니다.
    필요한 경우 GitHub에서 코드를 복사합니다. 이는 Terraform 스니펫이 엔드 투 엔드 솔루션의 일부인 경우에 권장됩니다.
    
  
  환경에 적용할 샘플 파라미터를 검토하고 수정합니다.
  변경사항을 저장합니다.
  
    Terraform을 초기화합니다. 이 작업은 디렉터리당 한 번만 수행하면 됩니다.
    terraform init
    원하는 경우 최신 Google 공급업체 버전을 사용하려면 -upgrade 옵션을 포함합니다.
    
    terraform init -upgrade
  

변경사항 적용

  
    구성을 검토하고 Terraform에서 만들거나 업데이트할 리소스가 예상과 일치하는지 확인합니다.
    terraform plan
    필요에 따라 구성을 수정합니다.
  
  
    다음 명령어를 실행하고 프롬프트에 yes를 입력하여 Terraform 구성을 적용합니다.
    terraform apply
    Terraform에 '적용 완료' 메시지가 표시될 때까지 기다립니다.
  
  결과를 보려면 Google Cloud 프로젝트 [https://console.cloud.google.com/?hl=ko]를 엽니다. Google Cloud 콘솔에서 UI의 리소스로 이동하여 Terraform이 리소스를 만들었거나 업데이트했는지 확인합니다.
  

참고: Terraform 샘플은 일반적으로 필요한 API가 Google Cloud 프로젝트에서 사용 설정되었다고 가정합니다.
객체 테이블 쿼리
다른 BigQuery와 같은 객체 테이블을 쿼리할 수 있습니다. 예를 들면 다음과 같습니다.
SELECT *
FROM mydataset.myobjecttable;
객체 테이블을 쿼리하면 기본 객체의 메타데이터를 반환합니다. 자세한 내용은 객체 테이블 스키마 [https://cloud.google.com/bigquery/docs/object-table-introduction?hl=ko#object_table_schema]를 참조하세요.
다음 단계
이미지 객체 테이블에서 추론 실행 [https://cloud.google.com/bigquery/docs/object-table-inference?hl=ko] 방법 알아보기
원격 함수를 사용하여 객체 테이블 분석 [https://cloud.google.com/bigquery/docs/object-table-remote-function?hl=ko] 방법 알아보기
도움이 되었나요?
의견 보내기