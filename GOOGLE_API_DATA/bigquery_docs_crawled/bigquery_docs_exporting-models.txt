Source URL: https://cloud.google.com/bigquery/docs/exporting-models

BigQuery [https://cloud.google.com/bigquery?hl=ko]
Documentation [https://cloud.google.com/bigquery/docs?hl=ko]
가이드 [https://cloud.google.com/bigquery/docs/introduction?hl=ko]
도움이 되었나요?
의견 보내기
이 페이지의 내용
내보내기 모델 형식 및 샘플 [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#export_model_formats_and_samples]
TRANSFORM으로 학습된 모델 내보내기 [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#export_model_trained_with_transform]
지원되는 데이터 유형 [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#export-transform-types]
지원되는 SQL 함수 [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#export-transform-functions]
제한사항 [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#limitations]
모델 내보내기
bookmark_border
이 페이지에서는 BigQuery ML 모델을 내보내는 방법을 설명합니다. BigQuery ML 모델을 Cloud Storage로 내보내서 온라인 예측에 사용하거나 Python에서 수정할 수 있습니다. 다음 방법으로 BigQuery ML 모델을 내보낼 수 있습니다.
Google Cloud 콘솔 [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko] 사용
EXPORT MODEL [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-export-model?hl=ko] 문 사용
bq 명령줄 도구에서 bq extract 명령어 사용
API 또는 클라이언트 라이브러리를 통해 extract [https://cloud.google.com/bigquery/docs/reference/rest/v2/Job?hl=ko#JobConfiguration] 작업 제출
다음 모델 유형을 내보낼 수 있습니다.
AUTOENCODER
AUTOML_CLASSIFIER
AUTOML_REGRESSOR
BOOSTED_TREE_CLASSIFIER
BOOSTED_TREE_REGRESSOR
DNN_CLASSIFIER
DNN_REGRESSOR
DNN_LINEAR_COMBINED_CLASSIFIER
DNN_LINEAR_COMBINED_REGRESSOR
KMEANS
LINEAR_REG
LOGISTIC_REG
MATRIX_FACTORIZATION
RANDOM_FOREST_CLASSIFIER
RANDOM_FOREST_REGRESSOR
TENSORFLOW(가져온 TensorFlow 모델)
PCA
TRANSFORM_ONLY
내보내기 모델 형식 및 샘플
다음 표는 각 BigQuery ML 모델 유형의 내보내기 대상 형식을 보여주고 Cloud Storage 버킷에 작성된 파일의 샘플을 제공합니다.
모델 유형 내보내기 모델 형식 내보낸 파일 샘플
AUTOML_CLASSIFIER TensorFlow 저장된 모델 [https://www.tensorflow.org/guide/saved_model?hl=ko] (TF 2.1.0) gcs_bucket/
  assets/
    f1.txt
    f2.txt
  saved_model.pb
  variables/
    variables.data-00-of-01
    variables.index
AUTOML_REGRESSOR
AUTOENCODER TensorFlow SavedModel [https://www.tensorflow.org/guide/saved_model?hl=ko] (TF 1.15 이상)
DNN_CLASSIFIER
DNN_REGRESSOR
DNN_LINEAR_COMBINED_CLASSIFIER
DNN_LINEAR_COMBINED_REGRESSOR
KMEANS
LINEAR_REGRESSOR
LOGISTIC_REG
MATRIX_FACTORIZATION
PCA
TRANSFORM_ONLY
BOOSTED_TREE_CLASSIFIER 부스터(XGBoost 0.82) gcs_bucket/
  assets/
    0.txt
    1.txt
    model_metadata.json
  main.py
  model.bst
  xgboost_predictor-0.1.tar.gz
    ....
     predictor.py
    ....

main.py는 로컬 실행용입니다. 자세한 내용은 모델 배포 [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#model-deployment]를 참조하세요.
BOOSTED_TREE_REGRESSOR
RANDOM_FOREST_REGRESSOR
RANDOM_FOREST_REGRESSOR
TENSORFLOW(가져옴) TensorFlow 저장된 모델 [https://www.tensorflow.org/guide/saved_model?hl=ko] 모델을 가져올 때 존재한 파일과 정확히 같은 파일
참고: 표준화 및 라벨 인코딩과 같이 모델 생성 중에 수행되는 자동 데이터 사전 처리 [https://cloud.google.com/bigquery/docs/auto-preprocessing?hl=ko]는 내보낸 파일에 TensorFlow SavedModel의 그래프의 일부로서 저장되며 Booster용 외부 파일에 위치합니다. 예측을 위해 데이터를 전달하기 전에 명시적인 사전 처리가 필요하지 않습니다. 일반적으로 입력은 BigQuery ML ML.PREDICT [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-predict?hl=ko]에 사용되는 것과 일치해야 합니다. 내보낸 모델 서명의 모든 숫자 값은 FLOAT64 데이터 유형으로 변환됩니다. 또한 모든 STRUCT 필드를 별도의 필드로 확장해야 합니다. 예를 들어 STRUCT f2의 f1 필드는 이름을 f2_f1으로 변경하고 별도의 열로 전달해야 합니다.
TRANSFORM으로 학습된 모델 내보내기
모델이 TRANSFORM 절 [https://cloud.google.com/bigquery/docs/bigqueryml-transform?hl=ko]로 학습되면 추가 사전 처리 모델은 TRANSFORM 절 [https://cloud.google.com/bigquery/docs/bigqueryml-transform?hl=ko]에서 동일한 로직을 수행하고 하위 디렉터리 transform 아래의 TensorFlow SavedModel 형식으로 저장됩니다. TRANSFORM 절 [https://cloud.google.com/bigquery/docs/bigqueryml-transform?hl=ko]로 학습된 모델을 Vertex AI는 물론 로컬에도 배포할 수 있습니다. 자세한 내용은 모델 배포 [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#model-deployment]를 참조하세요.
내보내기 모델 형식 내보낸 파일 샘플
예측 모델: TensorFlow SavedModel [https://www.tensorflow.org/guide/saved_model?hl=ko] 또는 부스터(XGBoost 0.82)
TRANSFORM 절의 사전 처리 모델: TensorFlow SavedModel [https://www.tensorflow.org/guide/saved_model?hl=ko](TF 2.5 이상) gcs_bucket/
  ....(model files)
  transform/
    assets/
        f1.txt/
        f2.txt/
    saved_model.pb
    variables/
        variables.data-00-of-01
        variables.index
모델에는 학습 중에 TRANSFORM 절 [https://cloud.google.com/bigquery/docs/bigqueryml-transform?hl=ko] 외부에서 실행된 특성 추출에 관한 정보가 포함되어 있지 않습니다. 예를 들어 SELECT 문의 모든 항목이 이에 해당합니다. 따라서 사전 처리 모델로 피드하기 전에 입력 데이터를 수동으로 변환해야 합니다.
지원되는 데이터 유형
TRANSFORM 절 [https://cloud.google.com/bigquery/docs/bigqueryml-transform?hl=ko]로 학습된 모델을 내보낼 때 TRANSFORM 절 [https://cloud.google.com/bigquery/docs/bigqueryml-transform?hl=ko]에 피드할 수 있도록 지원되는 데이터 유형은 다음과 같습니다.
TRANSFORM 입력 유형 TRANSFORM 입력 샘플 내보낸 전처리 모델 입력 샘플
INT64 10,
11 tf.constant(
  [10, 11],
  dtype=tf.int64)
NUMERIC NUMERIC 10,
NUMERIC 11 tf.constant(
  [10, 11],
  dtype=tf.float64)
BIGNUMERIC BIGNUMERIC 10,
BIGNUMERIC 11 tf.constant(
  [10, 11],
  dtype=tf.float64)
FLOAT64 10.0,
11.0 tf.constant(
  [10, 11],
  dtype=tf.float64)
BOOL TRUE,
FALSE tf.constant(
  [True, False],
  dtype=tf.bool)
STRING 'abc',
'def' tf.constant(
  ['abc', 'def'],
  dtype=tf.string)
BYTES b'abc',
b'def' tf.constant(
  ['abc', 'def'],
  dtype=tf.string)
DATE DATE '2020-09-27',
DATE '2020-09-28' tf.constant(
  [
    '2020-09-27',
    '2020-09-28'
  ],
  dtype=tf.string)

"%F" format
DATETIME DATETIME '2023-02-02 02:02:01.152903',
DATETIME '2023-02-03 02:02:01.152903' tf.constant(
  [
    '2023-02-02 02:02:01.152903',
    '2023-02-03 02:02:01.152903'
  ],
  dtype=tf.string)

"%F %H:%M:%E6S" format
TIME TIME '16:32:36.152903',
TIME '17:32:36.152903' tf.constant(
  [
    '16:32:36.152903',
    '17:32:36.152903'
  ],
  dtype=tf.string)

"%H:%M:%E6S" format
TIMESTAMP TIMESTAMP '2017-02-28 12:30:30.45-08',
TIMESTAMP '2018-02-28 12:30:30.45-08' tf.constant(
  [
    '2017-02-28 20:30:30.4 +0000',
    '2018-02-28 20:30:30.4 +0000'
  ],
  dtype=tf.string)

"%F %H:%M:%E1S %z" format
ARRAY ['a', 'b'],
['c', 'd'] tf.constant(
  [['a', 'b'], ['c', 'd']],
  dtype=tf.string)
ARRAY< STRUCT< INT64, FLOAT64>> [(1, 1.0), (2, 1.0)],
[(2, 1.0), (3, 1.0)] tf.sparse.from_dense(
  tf.constant(
    [
      [0, 1.0, 1.0, 0],
      [0, 0, 1.0, 1.0]
    ],
    dtype=tf.float64))
NULL NULL,
NULL tf.constant(
  [123456789.0e10, 123456789.0e10],
  dtype=tf.float64)

tf.constant(
  [1234567890000000000, 1234567890000000000],
  dtype=tf.int64)

tf.constant(
  [' __MISSING__ ', ' __MISSING__ '],
  dtype=tf.string)
지원되는 SQL 함수
TRANSFORM 절 [https://cloud.google.com/bigquery/docs/bigqueryml-transform?hl=ko]로 학습된 모델을 내보낼 때 TRANSFORM 절 [https://cloud.google.com/bigquery/docs/bigqueryml-transform?hl=ko] 내에서 다음 SQL 함수를 사용할 수 있습니다.
연산자 [https://cloud.google.com/bigquery/docs/reference/standard-sql/operators?hl=ko]
+, -, *, /, =, <, >, <=, >=, !=, <>, [NOT] BETWEEN, [NOT] IN, IS [NOT] NULL, IS [NOT] TRUE, IS [NOT] FALSE, NOT, AND, OR.
조건식 [https://cloud.google.com/bigquery/docs/reference/standard-sql/conditional_expressions?hl=ko]
CASE expr, CASE, COALESCE, IF, IFNULL, NULLIF.
수학 함수 [https://cloud.google.com/bigquery/docs/reference/standard-sql/mathematical_functions?hl=ko]
ABS, ACOS, ACOSH, ASINH, ATAN, ATAN2, ATANH, CBRT, CEIL, CEILING, COS, COSH, COT, COTH, CSC, CSCH, EXP, FLOOR, IS_INF, IS_NAN, LN, LOG, LOG10, MOD, POW, POWER, SEC, SECH, SIGN, SIN, SINH, SQRT, TAN, TANH.
변환 함수 [https://cloud.google.com/bigquery/docs/reference/standard-sql/conversion_functions?hl=ko]
CAST AS INT64, CAST AS FLOAT64, CAST AS NUMERIC, CAST AS BIGNUMERIC, CAST AS STRING, SAFE_CAST AS INT64, SAFE_CAST AS FLOAT64
문자열 함수 [https://cloud.google.com/bigquery/docs/reference/standard-sql/string_functions?hl=ko]
CONCAT, LEFT, LENGTH, LOWER, REGEXP_REPLACE, RIGHT, SPLIT, SUBSTR, SUBSTRING, TRIM, UPPER.
날짜 함수 [https://cloud.google.com/bigquery/docs/reference/standard-sql/date_functions?hl=ko]
Date, DATE_ADD, DATE_SUB, DATE_DIFF, DATE_TRUNC, EXTRACT, FORMAT_DATE, PARSE_DATE, SAFE.PARSE_DATE.
날짜/시간 함수 [https://cloud.google.com/bigquery/docs/reference/standard-sql/datetime_functions?hl=ko]
DATETIME, DATETIME_ADD, DATETIME_SUB, DATETIME_DIFF, DATETIME_TRUNC, EXTRACT, PARSE_DATETIME, SAFE.PARSE_DATETIME.
시간 함수 [https://cloud.google.com/bigquery/docs/reference/standard-sql/time_functions?hl=ko]
TIME, TIME_ADD, TIME_SUB, TIME_DIFF, TIME_TRUNC, EXTRACT, FORMAT_TIME, PARSE_TIME, SAFE.PARSE_TIME.
타임스탬프 함수 [https://cloud.google.com/bigquery/docs/reference/standard-sql/timestamp_functions?hl=ko]
TIMESTAMP, TIMESTAMP_ADD, TIMESTAMP_SUB, TIMESTAMP_DIFF, TIMESTAMP_TRUNC, FORMAT_TIMESTAMP, PARSE_TIMESTAMP, SAFE.PARSE_TIMESTAMP, TIMESTAMP_MICROS, TIMESTAMP_MILLIS, TIMESTAMP_SECONDS, EXTRACT, STRING, UNIX_MICROS, UNIX_MILLIS, UNIX_SECONDS.
수동 사전 처리 함수 [https://cloud.google.com/bigquery/docs/manual-preprocessing?hl=ko]
ML.IMPUTER, ML.HASH_BUCKETIZE, ML.LABEL_ENCODER, ML.MULTI_HOT_ENCODER, ML.NGRAMS, ML.ONE_HOT_ENCODER, ML.BUCKETIZE, ML.MAX_ABS_SCALER, ML.MIN_MAX_SCALER, ML.NORMALIZER, ML.QUANTILE_BUCKETIZE, ML.ROBUST_SCALER, ML.STANDARD_SCALER.
제한사항
모델을 내보낼 때 다음 제한사항이 적용됩니다.
학습 중에 다음 특성 중 하나라도 사용된 경우에는 모델 내보내기가 지원되지 않습니다.
입력 데이터에 ARRAY, TIMESTAMP 또는 GEOGRAPHY 특성 유형이 있었습니다.
모델 유형 AUTOML_REGRESSOR 및 AUTOML_CLASSIFIER의 내보낸 모델은 온라인 예측을 위한 Vertex AI 배포를 지원하지 않습니다.
행렬 분해 모델 내보내기의 모델 크기 한도는 1GB입니다. 모델 크기는 대략 num_factors에 비례하기 때문에 학습 중에 num_factors를 줄여 한도에 도달하면 모델 크기를 줄일 수 있습니다.
수동 특성 사전 처리 [https://cloud.google.com/bigquery/docs/manual-preprocessing?hl=ko]를 위해 BigQuery ML TRANSFORM 절 [https://cloud.google.com/bigquery/docs/bigqueryml-transform?hl=ko]로 학습된 모델의 경우 내보내기에 지원되는 데이터 유형 [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#export-transform-types] 및 함수 [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#export-transform-functions]를 참조하세요.
2023년 9월 18일 전에 BigQuery ML TRANSFORM 절 [https://cloud.google.com/bigquery/docs/bigqueryml-transform?hl=ko]로 학습한 모델은 온라인 예측용으로 Model Registry를 통해 배포 [https://cloud.google.com/bigquery/docs/managing-models-vertex?hl=ko]하기 전에 반드시 재학습해야 합니다.
모델을 내보내는 동안 ARRAY<STRUCT<INT64, FLOAT64>>, ARRAY, TIMESTAMP는 사전 변환된 데이터로 지원되지만 사후 변환된 데이터로는 지원되지 않습니다.
BigQuery ML 모델 내보내기
모델을 내보내려면 다음 안내를 따르세요.
--- 탭: 콘솔 [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#%EC%BD%98%EC%86%94] ---
Google Cloud 콘솔에서 BigQuery 페이지를 엽니다.

BigQuery 페이지로 이동 [https://console.cloud.google.com/bigquery?hl=ko] 
탐색 패널의 리소스 섹션에서 프로젝트를 펼치고 데이터 세트를 클릭하여 펼칩니다. 내보낼 모델을 찾아 클릭합니다.
창 오른쪽에서 모델 내보내기를 클릭합니다.

 
Cloud Storage로 모델 내보내기 대화상자에서 다음 안내를 따르세요.


Cloud Storage 위치 선택에서 모델을 내보낼 버킷 또는 폴더 위치를 찾습니다.
내보내기를 클릭하여 모델을 내보냅니다.



작업의 진행 상황을 확인하려면 내보내기 작업의 작업 기록 탐색창에서 맨 위쪽을 확인하세요.

--- 탭: SQL [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#sql] ---
EXPORT MODEL 문을 사용하면 GoogleSQL [https://cloud.google.com/bigquery/docs/reference/standard-sql?hl=ko] 쿼리 구문을 사용하여 BigQuery ML 모델을 Cloud Storage [https://cloud.google.com/storage/docs?hl=ko]로 내보낼 수 있습니다.

 Google Cloud 콘솔에서 EXPORT MODEL 문을 사용하여 BigQuery ML 모델을 내보내려면 다음 단계를 따르세요.


 Google Cloud 콘솔에서 BigQuery 페이지를 엽니다.

BigQuery로 이동 [https://console.cloud.google.com/bigquery?hl=ko] 
새 쿼리 작성을 클릭합니다.
쿼리 편집기 필드에 EXPORT MODEL [https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-export-model?hl=ko] 문을 입력합니다.

다음 쿼리는 이름이 myproject.mydataset.mymodel인 모델을 URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri] gs://bucket/path/to/saved_model/가 있는 Cloud Storage 버킷으로 내보냅니다.

 EXPORT MODEL `myproject.mydataset.mymodel`
 OPTIONS(URI = 'gs://bucket/path/to/saved_model/')
 
실행을 클릭합니다. 쿼리가 완료되면 쿼리 결과 창에 Successfully exported model가 나타납니다.

--- 탭: bq [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#bq] ---
참고: bq 명령줄 도구를 사용하여 모델을 내보내려면 gcloud CLI 버전 287.0.0 [https://cloud.google.com/sdk/docs/release-notes?hl=ko#28700_2020-04-01] 이상에 포함된 bq 도구 버전 2.0.56 이상이 있어야 합니다.
설치된 bq 도구 버전을 보려면 bq version [https://cloud.google.com/bigquery/docs/bq-command-line-tool?hl=ko#getting_help]을 사용하고, 필요한 경우 gcloud components update [https://cloud.google.com/sdk/gcloud/reference/components/update?hl=ko]를 사용하여 gcloud CLI를 업데이트합니다.
bq extract 명령어를 --model 플래그와 함께 사용합니다.

(선택사항) --destination_format 플래그를 지정하고 모델 내보내기 형식을 선택합니다.
(선택사항) --location 플래그를 지정하고 값을 사용자 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]로 설정합니다.

bq --location=location extract \
--destination_format format \
--model project_id:dataset.model \
gs://bucket/model_folder


각 항목의 의미는 다음과 같습니다.


location: 사용자 위치의 이름. --location 플래그는 선택사항입니다. 예를 들어 도쿄 리전에서 BigQuery를 사용한다면 플래그 값을 asia-northeast1로 설정할 수 있습니다. .bigqueryrc 파일 [https://cloud.google.com/bigquery/docs/bq-command-line-tool?hl=ko#setting_default_values_for_command-line_flags]을 사용하여 위치 기본값을 설정할 수 있습니다.
destination_format: ML_TF_SAVED_MODEL(기본값) 또는 ML_XGBOOST_BOOSTER인 내보내는 모델 형식
project_id: 프로젝트 ID
dataset: 소스 데이터 세트의 이름
model: 내보내는 모델
bucket: 데이터를 내보내는 Cloud Storage 버킷 이름. BigQuery 데이터 세트와 Cloud Storage 버킷은 같은 위치 [https://cloud.google.com/bigquery/docs/locations?hl=ko]에 있어야 합니다.
model_folder: 내보내는 모델 파일이 기록되는 폴더의 이름


예를 들면 다음과 같습니다.

예를 들어 다음 명령어는 TensorFlow 저장된 모델 형식의 mydataset.mymodel를 mymodel_folder이라는 Cloud Storage 버킷으로 내보냅니다.

bq extract --model \
'mydataset.mymodel' \
gs://example-bucket/mymodel_folder

destination_format의 기본값은 ML_TF_SAVED_MODEL입니다.

다음 명령어는 XGBoost Booster 형식의 mydataset.mymodel을 mymodel_folder라는 Cloud Storage 버킷으로 내보냅니다.

bq extract --model \
--destination_format ML_XGBOOST_BOOSTER \
'mydataset.mytable' \
gs://example-bucket/mymodel_folder

--- 탭: API [https://cloud.google.com/bigquery/docs/exporting-models?hl=ko#api] ---
모델을 내보내려면 extract 작업을 만들고 작업 구성을 채웁니다.

(선택사항) 작업 리소스 [https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs?hl=ko]의 jobReference 섹션에 있는 location 속성에 사용자 위치를 지정합니다.


BigQuery ML 모델 및 Cloud Storage 대상을 가리키는 추출 작업을 만듭니다.
프로젝트 ID, 데이터 세트 ID, 모델 ID가 포함된 sourceModel 구성 객체를 사용하여 소스 모델을 지정합니다.
destination URI(s) 속성은 gs://bucket/model_folder 형식으로 정규화되어야 합니다.
configuration.extract.destinationFormat 속성을 설정하여 대상 형식을 지정합니다. 예를 들어 부스티드 트리 모델을 내보내려면 이 속성을 ML_XGBOOST_BOOSTER 값으로 설정합니다.
작업 상태를 확인하려면 초기 요청이 반환한 작업 ID를 사용하여 jobs.get(job_id) [https://cloud.google.com/bigquery/docs/reference/v2/jobs/get?hl=ko]을 호출합니다.


status.state = DONE이면 작업이 성공적으로 완료된 것입니다.
status.errorResult 속성이 있으면 요청이 실패한 것이며 해당 객체에 문제를 설명하는 정보가 포함됩니다.
status.errorResult가 없으면 작업은 성공적으로 끝났지만 심각하지 않은 오류가 발생했을 수 있다는 의미입니다. 심각하지 않은 오류는 반환된 작업 객체의 status.errors 속성에 나열됩니다.



API 참고:


jobs.insert를 호출하여 작업을 만들 때 고유 ID를 생성하여 jobReference.jobId로 전달하는 것이 가장 좋습니다. 클라이언트가 알려진 작업 ID로 폴링하거나 재시도할 수 있으므로 이 방법은 네트워크 장애 시에 더욱 안정적입니다.
특정한 작업 ID에 대한 jobs.insert 호출은 멱등성을 지닙니다. 즉, 같은 작업 ID로 원하는 만큼 다시 시도할 수 있으며 최대 한 번만 성공합니다.

--- 탭: tabpanel-자바 ---
이 샘플을 사용해 보기 전에 BigQuery 빠른 시작: 클라이언트 라이브러리 사용 [https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries?hl=ko]의 Java 설정 안내를 따르세요.
        
      
      
  자세한 내용은 BigQuery Java API 참고 문서 [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/overview?hl=ko]를 확인하세요.
  
    
    
      BigQuery에 인증하려면 애플리케이션 기본 사용자 인증 정보를 설정합니다.
      자세한 내용은 클라이언트 라이브러리의 인증 설정 [https://cloud.google.com/bigquery/docs/authentication?hl=ko#client-libs]을 참조하세요.
      
    
      






    
  
  
  
  




















  





  
    
  
  











  









  




  



  


  import com.google.cloud.bigquery.BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko];
import com.google.cloud.bigquery.BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko];
import com.google.cloud.bigquery.BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko];
import com.google.cloud.bigquery.ExtractJobConfiguration [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.ExtractJobConfiguration.html?hl=ko];
import com.google.cloud.bigquery.Job [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Job.html?hl=ko];
import com.google.cloud.bigquery.JobInfo [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.JobInfo.html?hl=ko];
import com.google.cloud.bigquery.ModelId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.ModelId.html?hl=ko];

// Sample to extract model to GCS bucket
public class ExtractModel {

  public static void main(String[] args) throws InterruptedException {
    // TODO(developer): Replace these variables before running the sample.
    String projectName = "bigquery-public-data";
    String datasetName = "samples";
    String modelName = "model";
    String bucketName = "MY-BUCKET-NAME";
    String destinationUri = "gs://" + bucketName + "/path/to/file";
    extractModel(projectName, datasetName, modelName, destinationUri);
  }

  public static void extractModel(
      String projectName, String datasetName, String modelName, String destinationUri)
      throws InterruptedException {
    try {
      // Initialize client that will be used to send requests. This client only needs to be created
      // once, and can be reused for multiple requests.
      BigQuery [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko] bigquery = BigQueryOptions [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryOptions.html?hl=ko].getDefaultInstance().getService();

      ModelId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.ModelId.html?hl=ko] modelId = ModelId [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.ModelId.html?hl=ko].of(projectName, datasetName, modelName);

      ExtractJobConfiguration [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.ExtractJobConfiguration.html?hl=ko] extractConfig =
          ExtractJobConfiguration [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.ExtractJobConfiguration.html?hl=ko].newBuilder(modelId, destinationUri).build();

      Job [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Job.html?hl=ko] job = bigquery.create [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQuery.html?hl=ko#com_google_cloud_bigquery_BigQuery_create_com_google_cloud_bigquery_DatasetInfo_com_google_cloud_bigquery_BigQuery_DatasetOption____](JobInfo.of(extractConfig));

      // Blocks until this job completes its execution, either failing or succeeding.
      Job [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Job.html?hl=ko] completedJob = job.waitFor [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.Job.html?hl=ko#com_google_cloud_bigquery_Job_waitFor_com_google_cloud_bigquery_BigQueryRetryConfig_com_google_cloud_RetryOption____]();
      if (completedJob == null) {
        System.out.println("Job not executed since it no longer exists.");
        return;
      } else if (completedJob.getStatus().getError() != null) {
        System.out.println(
            "BigQuery was unable to extract due to an error: \n" + job.getStatus().getError());
        return;
      }
      System.out.println("Model extract successful");
    } catch (BigQueryException [https://cloud.google.com/java/docs/reference/google-cloud-bigquery/latest/com.google.cloud.bigquery.BigQueryException.html?hl=ko] ex) {
      System.out.println("Model extraction job was interrupted. \n" + ex.toString());
    }
  }
}
모델 배포
내보낸 모델을 Vertex AI는 물론 로컬에도 배포할 수 있습니다. 모델의 TRANSFORM 절 [https://cloud.google.com/bigquery/docs/bigqueryml-transform?hl=ko]에 날짜 함수, 날짜/시간 함수, 시간 함수 또는 타임스탬프 함수를 포함하면 컨테이너의 bigquery-ml-utils 라이브러리 [https://pypi.org/project/bigquery-ml-utils/]를 사용해야 합니다. 내보낸 모델이나 서빙 컨테이너가 필요하지 않은 Model Registry를 통해 배포 [https://cloud.google.com/bigquery/docs/managing-models-vertex?hl=ko]하는 경우에는 예외입니다.
Vertex AI 배포
내보내기 모델 형식 배포
TensorFlow SavedModel(비AutoML 모델) TensorFlow SavedModel 배포 [https://cloud.google.com/vertex-ai/docs/general/deployment?hl=ko] TensorFlow의 지원되는 버전 [https://cloud.google.com/vertex-ai/docs/supported-frameworks-list?hl=ko#tensorflow]을 사용하여 SavedModel 파일을 만들어야 합니다.
TensorFlow SavedModel(AutoML 모델) 지원되지 않음.
XGBoost Booster 커스텀 예측 루틴 [https://cloud.google.com/vertex-ai/docs/predictions/custom-prediction-routines?hl=ko]을 사용합니다. XGBoost Booster 모델의 경우 사전 처리 및 후처리 정보가 내보낸 파일에 저장되며 커스텀 예측 루틴을 사용하면 추가로 내보낸 파일로 모델을 배포할 수 있습니다.

XGBoost의 지원되는 버전 [https://cloud.google.com/vertex-ai/docs/supported-frameworks-list?hl=ko#xgboost_2]을 사용하여 모델 파일을 만들어야 합니다.
로컬 배포
내보내기 모델 형식 배포
TensorFlow SavedModel(비AutoML 모델) SavedModel은 표준 형식이며 TensorFlow Serving Docker 컨테이너 [https://www.tensorflow.org/tfx/serving/serving_basic?hl=ko]에 배포할 수 있습니다.

Vertex AI 온라인 예측의 로컬 실행 [https://cloud.google.com/vertex-ai/docs/training/containerize-run-code-local?hl=ko]도 활용할 수 있습니다.
TensorFlow SavedModel(AutoML 모델) 모델을 컨테이너화하고 실행합니다 [https://cloud.google.com/vertex-ai/docs/training/containerize-run-code-local?hl=ko].
XGBoost Booster XGBoost Booster 모델을 로컬로 실행하려면 내보낸 main.py 파일을 사용할 수 있습니다.
Cloud Storage에서 로컬 디렉터리로 모든 파일을 다운로드합니다.
xgboost_predictor-0.1.tar.gz에서 로컬 디렉터리로 predictor.py 파일의 압축을 풉니다.
main.py를 실행합니다(main.py 안내 참조).
예측 출력 형식
이 섹션에서는 각 모델 유형의 내보낸 모델 예측 출력 형식을 제공합니다. 내보낸 모든 모델은 일괄 예측을 지원합니다. 여러 입력 행을 한 번에 처리할 수 있습니다. 예를 들어 다음 각 출력 형식의 예시에는 두 개의 입력 행이 있습니다.
AUTOENCODER
예측 출력 형식 출력 샘플
+------------------------+------------------------+------------------------+
|      LATENT_COL_1      |      LATENT_COL_2      |           ...          |
+------------------------+------------------------+------------------------+
|       [FLOAT]          |         [FLOAT]        |           ...          |
+------------------------+------------------------+------------------------+
        
+------------------+------------------+------------------+------------------+
|   LATENT_COL_1   |   LATENT_COL_2   |   LATENT_COL_3   |   LATENT_COL_4   |
+------------------------+------------+------------------+------------------+
|    0.21384512    |    0.93457112    |    0.64978097    |    0.00480489    |
+------------------+------------------+------------------+------------------+
        
AUTOML_CLASSIFIER
예측 출력 형식 출력 샘플
+------------------------------------------+
| predictions                              |
+------------------------------------------+
| [{"scores":[FLOAT], "classes":[STRING]}] |
+------------------------------------------+
        
+---------------------------------------------+
| predictions                                 |
+---------------------------------------------+
| [{"scores":[1, 2], "classes":['a', 'b']},   |
|  {"scores":[3, 0.2], "classes":['a', 'b']}] |
+---------------------------------------------+
        
AUTOML_REGRESSOR
예측 출력 형식 출력 샘플
+-----------------+
| predictions     |
+-----------------+
| [FLOAT]         |
+-----------------+
        
+-----------------+
| predictions     |
+-----------------+
| [1.8, 2.46]     |
+-----------------+
        
BOOSTED_TREE_CLASSIFIER 및 RANDOM_FOREST_CLASSIFIER
예측 출력 형식 출력 샘플
+-------------+--------------+-----------------+
| LABEL_PROBS | LABEL_VALUES | PREDICTED_LABEL |
+-------------+--------------+-----------------+
| [FLOAT]     | [STRING]     | STRING          |
+-------------+--------------+-----------------+
        
+-------------+--------------+-----------------+
| LABEL_PROBS | LABEL_VALUES | PREDICTED_LABEL |
+-------------+--------------+-----------------+
| [0.1, 0.9]  | ['a', 'b']   | ['b']           |
+-------------+--------------+-----------------+
| [0.8, 0.2]  | ['a', 'b']   | ['a']           |
+-------------+--------------+-----------------+
        
BOOSTED_TREE_REGRESSOR 및 RANDOM_FOREST_REGRESSOR
예측 출력 형식 출력 샘플
+-----------------+
| predicted_label |
+-----------------+
| FLOAT           |
+-----------------+
        
+-----------------+
| predicted_label |
+-----------------+
| [1.8]           |
+-----------------+
| [2.46]          |
+-----------------+
        
DNN_CLASSIFIER
예측 출력 형식 출력 샘플
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
| ALL_CLASS_IDS | ALL_CLASSES | CLASS_IDS | CLASSES | LOGISTIC (binary only) | LOGITS | PROBABILITIES |
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
| [INT64]       | [STRING]    | INT64     | STRING  | FLOAT                  | [FLOAT]| [FLOAT]       |
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
        
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
| ALL_CLASS_IDS | ALL_CLASSES | CLASS_IDS | CLASSES | LOGISTIC (binary only) | LOGITS | PROBABILITIES |
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
| [0, 1]        | ['a', 'b']  | [0]       | ['a']   | [0.36]                 | [-0.53]| [0.64, 0.36]  |
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
| [0, 1]        | ['a', 'b']  | [0]       | ['a']   | [0.2]                  | [-1.38]| [0.8, 0.2]    |
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
        
DNN_REGRESSOR
예측 출력 형식 출력 샘플
+-----------------+
| PREDICTED_LABEL |
+-----------------+
| FLOAT           |
+-----------------+
        
+-----------------+
| PREDICTED_LABEL |
+-----------------+
| [1.8]           |
+-----------------+
| [2.46]          |
+-----------------+
        
DNN_LINEAR_COMBINED_CLASSIFIER
예측 출력 형식 출력 샘플
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
| ALL_CLASS_IDS | ALL_CLASSES | CLASS_IDS | CLASSES | LOGISTIC (binary only) | LOGITS | PROBABILITIES |
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
| [INT64]       | [STRING]    | INT64     | STRING  | FLOAT                  | [FLOAT]| [FLOAT]       |
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
        
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
| ALL_CLASS_IDS | ALL_CLASSES | CLASS_IDS | CLASSES | LOGISTIC (binary only) | LOGITS | PROBABILITIES |
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
| [0, 1]        | ['a', 'b']  | [0]       | ['a']   | [0.36]                 | [-0.53]| [0.64, 0.36]  |
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
| [0, 1]        | ['a', 'b']  | [0]       | ['a']   | [0.2]                  | [-1.38]| [0.8, 0.2]    |
+---------------+-------------+-----------+---------+------------------------+--------+---------------+
        
DNN_LINEAR_COMBINED_REGRESSOR
예측 출력 형식 출력 샘플
+-----------------+
| PREDICTED_LABEL |
+-----------------+
| FLOAT           |
+-----------------+
        
+-----------------+
| PREDICTED_LABEL |
+-----------------+
| [1.8]           |
+-----------------+
| [2.46]          |
+-----------------+
        
KMEANS
예측 출력 형식 출력 샘플
+--------------------+--------------+---------------------+
| CENTROID_DISTANCES | CENTROID_IDS | NEAREST_CENTROID_ID |
+--------------------+--------------+---------------------+
| [FLOAT]            | [INT64]      | INT64               |
+--------------------+--------------+---------------------+
        
+--------------------+--------------+---------------------+
| CENTROID_DISTANCES | CENTROID_IDS | NEAREST_CENTROID_ID |
+--------------------+--------------+---------------------+
| [1.2, 1.3]         | [1, 2]       | [1]                 |
+--------------------+--------------+---------------------+
| [0.4, 0.1]         | [1, 2]       | [2]                 |
+--------------------+--------------+---------------------+
        
LINEAR_REG
예측 출력 형식 출력 샘플
+-----------------+
| PREDICTED_LABEL |
+-----------------+
| FLOAT           |
+-----------------+
        
+-----------------+
| PREDICTED_LABEL |
+-----------------+
| [1.8]           |
+-----------------+
| [2.46]          |
+-----------------+
       
LOGISTIC_REG
예측 출력 형식 출력 샘플
+-------------+--------------+-----------------+
| LABEL_PROBS | LABEL_VALUES | PREDICTED_LABEL |
+-------------+--------------+-----------------+
| [FLOAT]     | [STRING]     | STRING          |
+-------------+--------------+-----------------+
        
+-------------+--------------+-----------------+
| LABEL_PROBS | LABEL_VALUES | PREDICTED_LABEL |
+-------------+--------------+-----------------+
| [0.1, 0.9]  | ['a', 'b']   | ['b']           |
+-------------+--------------+-----------------+
| [0.8, 0.2]  | ['a', 'b']   | ['a']           |
+-------------+--------------+-----------------+
        
MATRIX_FACTORIZATION
참고: 현재는 predicted_rating를 기준으로 입력 사용자 및 출력(predicted_rating, predicted_item)의 상위 50개 쌍만 내림차순으로 정렬하도록 지원합니다.
예측 출력 형식 출력 샘플
+--------------------+--------------+
| PREDICTED_RATING | PREDICTED_ITEM |
+------------------+----------------+
| [FLOAT]          | [STRING]       |
+------------------+----------------+
        
+--------------------+--------------+
| PREDICTED_RATING | PREDICTED_ITEM |
+------------------+----------------+
| [5.5, 1.7]       | ['A', 'B']     |
+------------------+----------------+
| [7.2, 2.7]       | ['B', 'A']     |
+------------------+----------------+
        
TENSORFLOW(가져옴)
예측 출력 형식
가져온 모델과 동일
PCA
예측 출력 형식 출력 샘플
+-------------------------+---------------------------------+
| PRINCIPAL_COMPONENT_IDS | PRINCIPAL_COMPONENT_PROJECTIONS |
+-------------------------+---------------------------------+
|       [INT64]           |             [FLOAT]             |
+-------------------------+---------------------------------+
        
+-------------------------+---------------------------------+
| PRINCIPAL_COMPONENT_IDS | PRINCIPAL_COMPONENT_PROJECTIONS |
+-------------------------+---------------------------------+
|       [1, 2]            |             [1.2, 5.0]          |
+-------------------------+---------------------------------+
        
TRANSFORM_ONLY
예측 출력 형식
모델의 TRANSFORM 절에 지정된 열과 동일
XGBoost 모델 시각화
모델 내보내기 이후 plot_tree [https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.plot_tree] Python API를 사용하여 부스티드 트리를 시각화할 수 있습니다. 예를 들어 종속 항목을 설치하지 않고도 Colab [https://colab.research.google.com/?hl=ko]을 사용할 수 있습니다.
부스티드 트리 모델을 Cloud Storage 버킷으로 내보냅니다.
Cloud Storage 버킷에서 model.bst 파일을 다운로드합니다.
Colab 메모장 [https://colab.sandbox.google.com/notebooks/welcome.ipynb?hl=ko]에서 model.bst파일을 Files에 업로드합니다.
노트북에서 다음 코드를 실행합니다.
import xgboost as xgb
import matplotlib.pyplot as plt

model = xgb.Booster(model_file="model.bst")
num_iterations = <iteration_number>
for tree_num in range(num_iterations):
  xgb.plot_tree(model, num_trees=tree_num)
plt.show
이 예시에서는 다중 트리(반복당 트리 한 개)를 구성합니다.
참고: 라벨 인코더를 사용해서 범주형 특성을 인코딩하므로, 모델 내보내기 Cloud Storage 버킷 내에 있는 'assets/' 디렉터리의 어휘 파일에서 분할 값에 대한 해당 카테고리를 가져올 수 있습니다. 예를 들어 노드에 'f0 < 2.95'가 있으면 3번째 항목을 조회하여 어휘 파일에서 해당 카테고리를 찾을 수 있습니다.
현재는 모델에 특성 이름이 저장되지 않으므로, 'f0', 'f1', 등의 이름이 표시됩니다. 이러한 이름(예: 'f0')을 색인으로 사용해서 assets/model_metadata.json 내보낸 파일에서 해당 특성 이름을 찾을 수 있습니다.
필수 권한
BigQuery ML 모델을 Cloud Storage로 내보내려면 BigQuery ML 모델에 액세스할 수 있는 권한, 내보내기 작업을 실행할 수 있는 권한, Cloud Storage 버킷에 데이터를 쓸 수 있는 권한이 필요합니다.
BigQuery 권한
모델을 내보내려면 최소한 bigquery.models.export 권한을 부여받아야 합니다. 사전 정의된 Identity and Access Management(IAM) 역할에 bigquery.models.export 권한이 부여됩니다.
bigquery.dataViewer
bigquery.dataOwner
bigquery.dataEditor
bigquery.admin
내보내기 작업 [https://cloud.google.com/bigquery/docs/managing-jobs?hl=ko]을 실행하려면 최소한 bigquery.jobs.create 권한이 부여되어 있어야 합니다. 사전 정의된 다음 IAM 역할에 bigquery.jobs.create 권한이 부여됩니다.
bigquery.user
bigquery.jobUser
bigquery.admin
Cloud Storage 권한
기존 Cloud Storage 버킷에 데이터를 쓰려면 storage.objects.create 권한이 부여되어 있어야 합니다. 사전 정의된 다음 IAM 역할에 storage.objects.create 권한이 부여됩니다.
storage.objectCreator
storage.objectAdmin
storage.admin
BigQuery ML의 IAM 역할과 권한에 대한 자세한 내용은 액세스 제어 [https://cloud.google.com/bigquery/docs/access-control?hl=ko]를 참조하세요.
다른 위치 간 BigQuery 데이터 이동
데이터세트가 생성된 후에는 데이터세트 위치를 변경할 수 없지만 데이터세트를 복사 [https://cloud.google.com/bigquery/docs/copying-datasets?hl=ko]할 수 있습니다.
할당량 정책
내보내기 작업 할당량에 대한 자세한 내용은 할당량 및 한도 페이지의 내보내기 작업 [https://cloud.google.com/bigquery/quotas?hl=ko#export_jobs]을 참조하세요.
가격 책정
BigQuery ML 모델 내보내기는 무료지만 내보내기에는 BigQuery의 할당량 및 한도 [https://cloud.google.com/bigquery/quotas?hl=ko]가 적용됩니다. BigQuery 가격에 대한 자세한 내용은 가격 책정 [https://cloud.google.com/bigquery/pricing?hl=ko] 페이지를 참조하세요.
데이터를 내보낸 후 Cloud Storage에 데이터를 저장하는 데는 요금이 청구됩니다. Cloud Storage 가격에 대한 자세한 내용은 Cloud Storage 가격 책정 [https://cloud.google.com/storage/pricing?hl=ko] 페이지를 참조하세요.
다음 단계
온라인 예측을 위한 BigQuery ML 모델 내보내기 [https://cloud.google.com/bigquery/docs/export-model-tutorial?hl=ko] 튜토리얼 살펴보기
도움이 되었나요?
의견 보내기