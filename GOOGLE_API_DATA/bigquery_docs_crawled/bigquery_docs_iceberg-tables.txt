Source URL: https://cloud.google.com/bigquery/docs/iceberg-tables

BigQuery [https://cloud.google.com/bigquery?hl=ko]
Documentation [https://cloud.google.com/bigquery/docs?hl=ko]
가이드 [https://cloud.google.com/bigquery/docs/introduction?hl=ko]
도움이 되었나요?
의견 보내기
이 페이지의 내용
아키텍처 [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#architecture]
권장사항 [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#best_practices]
위치 고려사항 [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#location_consideration]
결제 [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#billing]
Iceberg 테이블 워크플로 [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#iceberg-table-workflows]
시작하기 전에 [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#before_you_begin]
필요한 역할 [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#required-roles]
Iceberg 테이블 만들기 [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#create-iceberg-tables]
Apache Iceberg용 BigQuery 테이블
bookmark_border
Preview
This feature is subject to the "Pre-GA Offerings Terms" in the General Service Terms section of the Service Specific Terms [https://cloud.google.com/terms/service-terms?hl=ko#1]. Pre-GA features are available "as is" and might have limited support. For more information, see the launch stage descriptions [https://cloud.google.com/products?hl=ko#product-launch-stages].
프리뷰 중에 지원을 받으려면 bigquery-tables-for-apache-iceberg-help@google.com [mailto:bigquery-tables-for-apache-iceberg-help@google.com]으로 이메일을 보내세요.
Apache Iceberg용 BigQuery 테이블(이하 Iceberg 테이블)은 Google Cloud에서 개방형 형식의 레이크하우스를 빌드하기 위한 기반을 제공합니다. Iceberg 테이블은 BigQuery 테이블과 동일한 완전 관리형 환경을 제공하지만, Parquet을 사용하여 고객 소유 스토리지 버킷에 데이터를 저장하여 Iceberg 개방형 테이블 형식과 상호 운용할 수 있습니다.
Apache Iceberg용 BigQuery 테이블은 BigQuery 내에서 직접 수정할 수 있으므로 Apache Iceberg용 BigLake 외부 테이블 [https://cloud.google.com/bigquery/docs/iceberg-external-tables?hl=ko]과 다릅니다. Apache Iceberg용 BigLake 외부 테이블은 Apache Spark와 같은 다른 쿼리 엔진에서 생성된 읽기 전용 테이블이며 BigQuery를 사용하여만 쿼리할 수 있습니다.
Iceberg 테이블은 다음 기능을 지원합니다.
GoogleSQL DML을 사용하는 테이블 변형
Spark, Dataflow, 기타 엔진용 BigLake 커넥터를 통해 Storage Write API [https://cloud.google.com/bigquery/docs/write-api?hl=ko]를 사용하여 통합 일괄 처리 및 높은 처리량 스트리밍
스키마 혁신: 필요에 따라 열을 추가, 삭제, 이름을 바꿀 수 있음. 이 기능을 사용하면 기존 열의 데이터 유형 [https://cloud.google.com/bigquery/docs/managing-table-schemas?hl=ko#change_a_columns_data_type]과 열 모드 [https://cloud.google.com/bigquery/docs/managing-table-schemas?hl=ko#change_a_columns_mode]도 변경할 수 있습니다. 자세한 내용은 유형 변환 규칙 [https://cloud.google.com/bigquery/docs/reference/standard-sql/conversion_rules?hl=ko]을 참조하세요.
적응형 파일 크기 조정, 자동 클러스터링, 가비지 컬렉션, 메타데이터 최적화를 비롯한 자동 스토리지 최적화
열 수준 보안 [https://cloud.google.com/bigquery/docs/column-level-security-intro?hl=ko] 및 데이터 마스킹 [https://cloud.google.com/bigquery/docs/column-data-masking-intro?hl=ko]
다음은 BigQuery Iceberg 테이블을 BigQuery의 다른 유사한 테이블 유형과 비교합니다.
표준 BigQuery 테이블 [https://cloud.google.com/bigquery/docs/tables-intro?hl=ko#standard_tables] BigLake 외부 테이블 [https://cloud.google.com/bigquery/docs/biglake-intro?hl=ko] Apache Iceberg용 BigLake 외부 테이블 [https://cloud.google.com/bigquery/docs/iceberg-external-tables?hl=ko](BigLake Iceberg 테이블이라고도 함) BigQuery 메타스토어 Iceberg 테이블 [https://cloud.google.com/bigquery/docs/bqms-use-tables?hl=ko](프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages]) Apache Iceberg용 BigQuery 테이블 [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko](Iceberg 관리 테이블/BigQuery Iceberg 테이블이라고도 함)(프리뷰 [https://cloud.google.com/products?hl=ko#product-launch-stages])
주요 특징 완전 관리형 환경 오픈소스 및 BigQuery 엔진 전반에서 거버넌스(세분화된 액세스 제어) 및 기능이 적용됨 BigLake 외부 테이블 기능 + 데이터 일관성, 스키마 업데이트. Spark 또는 기타 공개 엔진에서는 만들 수 없습니다. BigLake Iceberg 테이블 기능 + 외부 엔진에서 변경 가능. DDL 또는 bq 명령줄 도구로 만들 수 없습니다. BigLake Iceberg 테이블 기능 + 공공 데이터 및 메타데이터를 통한 낮은 관리 오버헤드
데이터 스토리지 BigQuery 관리형 스토리지 사용자 관리 버킷에 호스팅되는 개방형 형식 데이터
개방형 모델 (커넥터를 통한) BigQuery Storage Read API 개방형 파일 형식(Parquet) 개방형 라이브러리(Iceberg) 오픈소스 호환(Iceberg 메타데이터 스냅샷)
거버넌스 통합 BigQuery 거버넌스
쓰기(DML 및 스트리밍) BigQuery 커넥터, API, 높은 처리량 DML, CDC를 통해 외부 엔진을 통해서만 쓰기 BigQuery 커넥터, API, 높은 처리량 DML, CDC를 통해
아키텍처
Iceberg 테이블은 자체 클라우드 버킷에 있는 테이블에 BigQuery 리소스 관리의 편리성을 제공합니다. Iceberg 테이블을 사용하면 제어하는 버킷에서 데이터를 이동하지 않고도 이러한 테이블에서 BigQuery를 사용할 수 있습니다.
다음 다이어그램은 관리형 테이블 아키텍처를 대략적으로 보여줍니다.
이 테이블 관리는 버킷에 다음과 같은 영향을 미칩니다.
BigQuery는 쓰기 요청 및 DML 문, 스트리밍과 같은 백그라운드 스토리지 최적화에 응답하여 버킷에 새 데이터 파일을 만듭니다.
BigQuery에서 관리형 테이블을 삭제해도 BigQuery에서는 연결된 데이터 파일을 삭제하지 않습니다. 버킷에서 파일과 내보낸 테이블 메타데이터를 수동으로 삭제하여 삭제를 확인해야 합니다.
Iceberg 테이블에는 BigQuery 스토리지 비용이 발생하지 않습니다. 자세한 내용은 결제 [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#billing]를 참조하세요.
Iceberg 테이블을 만드는 방법은 BigQuery 테이블을 만드는 방법 [https://cloud.google.com/bigquery/docs/tables?hl=ko]과 유사합니다. Cloud Storage에 개방형 형식으로 데이터를 저장하므로 다음과 같은 옵션이 더 많습니다.
WITH CONNECTION을 사용하여 Cloud 리소스 연결 [https://cloud.google.com/bigquery/docs/create-cloud-resource-connection?hl=ko]을 지정하여 BigLake가 Cloud Storage에 액세스할 수 있는 연결 사용자 인증 정보를 구성합니다.
file_format을 사용하여 데이터 스토리지의 파일 형식을 지정합니다. PARQUET는 프리뷰에서 지원됩니다.
table_format을 사용하여 오픈소스 메타데이터 테이블 형식을 지정합니다. ICEBERG는 프리뷰에서 지원됩니다.
권장사항
경고: BigQuery 외부에서 Iceberg 테이블의 데이터 파일을 수정하면 쿼리 실패 또는 데이터 손실이 발생할 수 있습니다. 이를 방지하려면 BigQuery를 사용하여 Iceberg 테이블을 업데이트하거나 수정하세요.
BigQuery 외부에서 버킷을 직접 변경하거나 파일을 추가하면 데이터 손실 또는 복구할 수 없는 오류가 발생할 수 있습니다. 다음 표에는 가능한 시나리오가 설명되어 있습니다.
작업 결과 예방 방법
BigQuery 외부의 버킷에 새 파일을 추가합니다. 데이터 손실: BigQuery 외부에 추가된 새 파일 또는 객체는 BigQuery에서 추적하지 않습니다. 추적되지 않은 파일은 백그라운드 가비지 컬렉션 프로세스에 의해 삭제됩니다. BigQuery를 통해서만 데이터를 추가합니다. 이렇게 하면 BigQuery에서 파일을 추적하고 가비지 컬렉션을 방지할 수 있습니다.
실수로 추가 및 데이터 손실을 방지하려면 Iceberg 테이블이 포함된 버킷에서 외부 도구 쓰기 권한을 제한하는 것이 좋습니다.
비어 있지 않은 프리픽스에 새 Iceberg 테이블을 만듭니다. 데이터 손실: 기존 데이터는 BigQuery에서 추적하지 않으므로 이러한 파일은 추적되지 않는 것으로 간주되어 백그라운드 가비지 컬렉션 프로세스에 의해 삭제됩니다. 빈 프리픽스에서만 새 Iceberg 테이블을 만듭니다.
Iceberg 테이블 데이터 파일을 수정하거나 교체합니다. 데이터 손실: 외부에서 수정하거나 교체하면 테이블이 일관성 검사를 통과하지 못하여 읽을 수 없게 됩니다. 테이블에 대한 쿼리가 실패합니다.
이 시점에서는 셀프 서비스로 복구할 수 없습니다. 데이터 복구 지원을 받으려면 지원팀 [https://cloud.google.com/bigquery/docs/getting-support?hl=ko]에 문의하세요. BigQuery를 통해서만 데이터를 수정합니다. 이렇게 하면 BigQuery에서 파일을 추적하고 가비지 컬렉션을 방지할 수 있습니다.
실수로 추가 및 데이터 손실을 방지하려면 Iceberg 테이블이 포함된 버킷에서 외부 도구 쓰기 권한을 제한하는 것이 좋습니다.
동일하거나 중복되는 URI에 Apache Iceberg용 BigQuery 테이블 2개를 만듭니다. 데이터 손실: BigQuery는 Iceberg 테이블의 동일한 URI 인스턴스를 브리징하지 않습니다. 각 테이블의 백그라운드 가비지 컬렉션 프로세스는 반대 테이블의 파일을 추적되지 않은 것으로 간주하고 삭제하여 데이터 손실이 발생합니다. 각 Iceberg 테이블에 고유한 URI를 사용합니다.
위치 고려사항
멀티 리전 버킷 대신에 Cloud Storage 단일 리전 [https://cloud.google.com/storage/docs/locations?hl=ko#available-locations] 또는 이중 리전 [https://cloud.google.com/storage/docs/locations?hl=ko#location-dr] 버킷을 사용하여 성능을 개선할 수 있습니다.
결제
다음 기능은 기존에 게시된 가격 책정 방식을 사용하여 요금이 청구됩니다.
Cloud Storage 버킷에 저장된 모든 데이터, Cloud Storage에서 실행되는 데이터 처리, 버킷에서 읽은 데이터 양에 대한 네트워크 사용량에 대한 Cloud Storage 가격 책정 [https://cloud.google.com/storage/pricing?hl=ko]
쿼리, DML, 백그라운드 스토리지 최적화(클러스터링, 병합, 가비지 컬렉션 포함)에 대한 BigQuery 컴퓨팅 가격 책정 [https://cloud.google.com/bigquery/pricing?hl=ko#analysis_pricing_models]
예약(슬롯)을 사용하는 요금은 기존 슬롯 가격을 따릅니다.
주문형 재고 관리 단위(SKU)를 사용하는 요금은 기존 주문형 가격 책정을 따릅니다. 자세한 내용은 BigLake 비용 [https://cloud.google.com/bigquery/docs/biglake-intro?hl=ko#costs]을 참조하세요.
일괄 로드 [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko] 및 추출 [https://cloud.google.com/bigquery/docs/exporting-data?hl=ko#export-data-in-bigquery] 컴퓨팅에는 주문형 SKU 또는 예약(슬롯)을 사용하여 요금이 청구됩니다.
Read API를 통한 Spark에서 읽기에 대한 Storage Read API 가격 책정 [https://cloud.google.com/bigquery/pricing?hl=ko#storage-api]
스트리밍을 위한 Storage Write API 가격 책정 [https://cloud.google.com/bigquery/pricing?hl=ko#data_ingestion_pricing]
Iceberg 테이블 워크플로
다음 섹션에서는 관리형 테이블을 만들고, 로드하고, 관리하고, 쿼리하는 방법을 설명합니다.
시작하기 전에
Iceberg 테이블을 만들고 사용하기 전에 저장소 버킷에 클라우드 리소스 연결 [https://cloud.google.com/bigquery/docs/create-cloud-resource-connection?hl=ko]을 설정했는지 확인하세요. 연결에는 다음 필수 역할 [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#required-roles] 섹션에 지정된 대로 저장소 버킷에 대한 쓰기 권한이 필요합니다.
필요한 역할
BigQuery에서 프로젝트의 테이블을 관리하도록 허용하는 데 필요한 권한을 얻으려면 관리자에게 다음 IAM 역할을 부여해 달라고 요청하세요.
Iceberg 테이블 만들기:
프로젝트에 대한 BigQuery 데이터 소유자 [https://cloud.google.com/iam/docs/understanding-roles?hl=ko#bigquery.dataOwner](roles/bigquery.dataOwner)
프로젝트에 대한 BigQuery 연결 관리자 [https://cloud.google.com/iam/docs/understanding-roles?hl=ko#bigquery.connectionAdmin](roles/bigquery.connectionAdmin)
Iceberg 테이블 쿼리하기:
프로젝트에 대한 BigQuery 데이터 뷰어 [https://cloud.google.com/iam/docs/understanding-roles?hl=ko#bigquery.dataViewer](roles/bigquery.dataViewer)
프로젝트에 대한 BigQuery 사용자 [https://cloud.google.com/iam/docs/understanding-roles?hl=ko#bigquery.user](roles/bigquery.user)
연결 서비스 계정에서 Cloud Storage의 데이터 읽고 쓰기:
버킷에 대한 스토리지 객체 사용자 [https://cloud.google.com/iam/docs/understanding-roles?hl=ko#storage.objectUser](roles/storage.objectUser)
버킷에 대한 스토리지 기존 버킷 리더 [https://cloud.google.com/iam/docs/understanding-roles?hl=ko#storage.legacyBucketReader](roles/storage.legacyBucketReader)
역할 부여에 대한 자세한 내용은 프로젝트, 폴더, 조직에 대한 액세스 관리 [https://cloud.google.com/iam/docs/granting-changing-revoking-access?hl=ko]를 참조하세요.
이러한 사전 정의된 역할에는 BigQuery에서 프로젝트의 테이블을 관리하도록 허용하는 데 필요한 권한이 포함되어 있습니다. 필요한 정확한 권한을 보려면 필수 권한 섹션을 펼치세요.
필수 권한
커스텀 역할 [https://cloud.google.com/iam/docs/creating-custom-roles?hl=ko]이나 다른 사전 정의된 역할 [https://cloud.google.com/iam/docs/understanding-roles?hl=ko]을 사용하여 이 권한을 부여받을 수도 있습니다.
Iceberg 테이블 만들기
Iceberg 테이블을 만들려면 다음 방법 중 하나를 선택합니다.
--- 탭: SQL [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#sql] ---
CREATE TABLE [PROJECT_NAME.]DATASET_NAME.TABLE_NAME (
COLUMN DATA_TYPE[, ...]
)
CLUSTER BY CLUSTER_COLUMN_LIST
WITH CONNECTION CONNECTION_NAME
OPTIONS (
file_format = 'PARQUET',
table_format = 'ICEBERG',
storage_uri = 'STORAGE_URI');

다음을 바꿉니다.


PROJECT_NAME: 데이터 세트가 포함된 프로젝트.
정의되지 않으면 명령어는 기본 프로젝트를 가정합니다.
DATASET_NAME: 기존 데이터 세트
TABLE_NAME: 생성할 테이블의 이름
DATA_TYPE: 열에 포함된 정보의 데이터 유형
CLUSTER_COLUMN_LIST: 최대 4개의 열을 포함하는 쉼표로 구분된 목록. 최상위 수준의 반복되지 않는 열이어야 합니다.
CONNECTION_NAME: 연결의 이름. 예를 들면 myproject.us.myconnection입니다.
STORAGE_URI: 정규화된 Cloud Storage URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri].
예를 들면 gs://mybucket/table입니다.

--- 탭: bq [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#bq] ---
bq --project_id=PROJECT_NAME mk \
    --file_format=PARQUET \
    --table_format=ICEBERG \
    --connection_id=CONNECTION_NAME \
    --storage_uri=STORAGE_URI \
    --schema=COLUMN_NAME:DATA_TYPE[, ...] \
    --clustering_fields=CLUSTER_COLUMN_LIST \
    MANAGED_TABLE_NAME

다음을 바꿉니다.


PROJECT_NAME: 데이터 세트가 포함된 프로젝트.
정의되지 않으면 명령어는 기본 프로젝트를 가정합니다.
CONNECTION_NAME: 연결의 이름. 예를 들면 myproject.us.myconnection입니다.
STORAGE_URI: 정규화된 Cloud Storage URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri].
예를 들면 gs://mybucket/table입니다.
COLUMN_NAME: 열 이름
DATA_TYPE: 열에 포함된 정보의 데이터 유형
CLUSTER_COLUMN_LIST: 최대 4개의 열을 포함하는 쉼표로 구분된 목록. 최상위 수준의 반복되지 않는 열이어야 합니다.
MANAGED_TABLE_NAME: 생성할 테이블의 이름

--- 탭: API [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#api] ---
다음과 같이 정의된 테이블 리소스 [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables?hl=ko]를 사용하여 tables.insert [https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/insert?hl=ko] 메서드를 호출합니다.

{
"tableReference": {
  "tableId": "TABLE_NAME"
},
"biglakeConfiguration": {
  "connectionId": "CONNECTION_NAME",
  "fileFormat": "PARQUET",
  "tableFormat": "ICEBERG",
  "storageUri": "STORAGE_URI"
},
"schema": {
  "fields": [
    {
      "name": "COLUMN_NAME",
      "type": "DATA_TYPE"
    }
    [, ...]
  ]
}
}

다음을 바꿉니다.


TABLE_NAME: 생성할 테이블의 이름
CONNECTION_NAME: 연결의 이름. 예를 들면 myproject.us.myconnection입니다.
STORAGE_URI: 정규화된 Cloud Storage URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri].
와일드 카드 [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#load-wildcards]도 지원됩니다. 예를 들면 gs://mybucket/table입니다.
COLUMN_NAME: 열 이름
DATA_TYPE: 열에 포함된 정보의 데이터 유형
Iceberg 테이블에 데이터 가져오기
다음 섹션에서는 다양한 테이블 형식에서 Iceberg 테이블로 데이터를 가져오는 방법을 설명합니다.
Parquet 파일에서 빠르게 로드
copy_files_only 옵션을 사용하면 콘텐츠를 읽고 새 파일로 다시 작성하는 대신 기존 Parquet 파일을 복사하여 데이터를 더 빠르게 로드할 수 있습니다. 빠른 로드는 일반 파일 로드에 비해 컴퓨팅 용량을 덜 사용합니다. Parquet 파일은 Apache Iceberg 사양 [https://iceberg.apache.org/spec/#parquet]과 호환되어야 하며 완전한 열 통계를 보유해야 합니다. 빠른 로드는 파일이 읽혀 다시 처리되지 않으므로 파일에서 잘못된 값(예: 범위를 벗어난 타임스탬프)을 인식하지 못합니다. Parquet 파일 로드에 관한 자세한 내용은 새 테이블에 Parquet 데이터 로드 [https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet?hl=ko#loading_parquet_data_into_a_new_table]를 참조하세요.
플랫 Parquet 파일을 기존 Iceberg 테이블에 빠르게 로드하려면 bq load 명령어 [https://cloud.google.com/bigquery/docs/reference/bq-cli-reference?hl=ko#bq_load]를 사용합니다.
bq load \
    --copy_files_only \
    --source_format=PARQUET \
    
DATASET_NAME.
TABLE_NAME \
    
PATH_TO_SOURCE
다음을 바꿉니다.
DATASET_NAME: Iceberg 테이블이 포함된 데이터 세트
TABLE_NAME: 데이터를 로드할 Iceberg 테이블의 이름
PATH_TO_SOURCE: 정규화된 Cloud Storage URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri] 또는 쉼표로 구분된 URI 목록. 와일드 카드 [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#load-wildcards]도 지원됩니다. 예를 들면 gs://mybucket/mydata*.parquet입니다.
플랫 파일에서 표준 데이터 로드
Iceberg 테이블은 BigQuery 로드 작업을 사용하여 외부 파일을 Iceberg 테이블에 로드합니다. 기존 Iceberg 테이블이 있는 경우 bq load CLI 가이드 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko#bq] 또는 LOAD SQL 가이드 [https://cloud.google.com/bigquery/docs/reference/standard-sql/other-statements?hl=ko#load_a_file_that_is_externally_partitioned]에 따라 외부 데이터를 로드합니다. 데이터를 로드하면 새 Parquet 파일이 STORAGE_URI/data 폴더에 쓰여집니다.
기존 Iceberg 테이블 없이 이전 안내를 사용하면 대신 BigQuery 테이블이 생성됩니다.
관리형 테이블에 대한 일괄 로드의 도구별 예시는 다음을 참조하세요.
--- 탭: SQL [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#sql] ---
LOAD DATA INTO MANAGED_TABLE_NAME
FROM FILES (
uris=['STORAGE_URI'],
format='FILE_FORMAT');

다음을 바꿉니다.


MANAGED_TABLE_NAME: 기존 Iceberg 테이블 이름
STORAGE_URI: 정규화된 Cloud Storage URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri] 또는 쉼표로 구분된 URI 목록.
와일드 카드 [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#load-wildcards]도 지원됩니다. 예를 들면 gs://mybucket/table입니다.
FILE_FORMAT: 소스 테이블 형식. 지원되는 형식은 load_option_list [https://cloud.google.com/bigquery/docs/reference/standard-sql/load-statements?hl=ko#load_option_list]의 format 행을 참조하세요.

--- 탭: bq [https://cloud.google.com/bigquery/docs/iceberg-tables?hl=ko#bq] ---
bq load \
  --source_format=FILE_FORMAT \
  MANAGED_TABLE \
  STORAGE_URI

다음을 바꿉니다.


FILE_FORMAT: 소스 테이블 형식. 지원되는 형식은 load_option_list [https://cloud.google.com/bigquery/docs/reference/standard-sql/load-statements?hl=ko#load_option_list]의 format 행을 참조하세요.
MANAGED_TABLE_NAME: 기존 Iceberg 테이블 이름
STORAGE_URI: 정규화된 Cloud Storage URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri] 또는 쉼표로 구분된 URI 목록.
와일드 카드 [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#load-wildcards]도 지원됩니다. 예를 들면 gs://mybucket/table입니다.
Hive 파티션을 나눈 파일에서 표준 로드
표준 BigQuery 로드 작업을 사용하여 Hive 파티션을 나눈 파일을 Iceberg 테이블에 로드할 수 있습니다. 자세한 내용은 외부에서 파티션을 나눈 데이터 로드 [https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs?hl=ko]를 참조하세요.
Pub/Sub에서 스트리밍 데이터 로드
Pub/Sub BigQuery 구독 [https://cloud.google.com/pubsub/docs/subscription-properties?hl=ko#bigquery]을 사용하여 스트리밍 데이터를 Iceberg 테이블에 로드할 수 있습니다.
Iceberg 테이블에서 데이터 내보내기
다음 섹션에서는 Iceberg 테이블에서 다양한 테이블 형식으로 데이터를 내보내는 방법을 설명합니다.
데이터를 플랫 형식으로 내보내기
Iceberg 테이블을 플랫 형식으로 내보내려면 EXPORT DATA 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/other-statements?hl=ko#export_data_statement]을 사용하고 대상 형식을 선택합니다. 자세한 내용은 데이터 내보내기 [https://cloud.google.com/bigquery/docs/exporting-data?hl=ko#sql]를 참조하세요.
Iceberg 테이블 메타데이터 스냅샷 만들기
Iceberg 테이블 메타데이터 스냅샷을 만들려면 다음 단계를 따르세요.
EXPORT TABLE METADATA [https://cloud.google.com/bigquery/docs/exporting-data?hl=ko#export_table_metadata] SQL 문을 사용하여 메타데이터를 Iceberg 형식으로 내보냅니다.
(선택사항) Iceberg 메타데이터 스냅샷 새로고침 예약 설정된 시간 간격을 기준으로 Iceberg 메타데이터 스냅샷을 새로고침하려면 예약된 쿼리 [https://cloud.google.com/bigquery/docs/scheduling-queries?hl=ko]를 사용하세요.
다음 예에서는 DDL 문 EXPORT TABLE METADATA FROM mydataset.test를 사용하여 My Scheduled Snapshot Refresh Query라는 예약된 쿼리를 만듭니다. 대상 데이터 세트는 mydataset입니다. DDL 문은 24시간마다 실행됩니다.
bq query \
    --use_legacy_sql=false \
    --destination_dataset=mydataset
    --display_name='My Scheduled Snapshot Refresh Query' \
    --schedule='every 24 hours' \
    'EXPORT TABLE METADATA FROM mydataset.test'
Iceberg 테이블 메타데이터 스냅샷 보기
Iceberg 테이블 메타데이터 스냅샷을 새로고침하면 Iceberg 테이블이 원래 생성된 Cloud Storage URI [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko#gcs-uri]에서 스냅샷을 찾을 수 있습니다. /data 폴더에는 Parquet 파일 데이터 샤드가 포함되고 /metadata 폴더에는 Iceberg 테이블 메타데이터 스냅샷이 포함됩니다.
SELECT
  table_name,
  REGEXP_EXTRACT(ddl, r"storage_uri\s*=\s*\"([^\"]+)\"") AS storage_uri
FROM
  `mydataset`.INFORMATION_SCHEMA.TABLES;
mydataset 및 table_name는 실제 데이터 세트와 테이블의 자리표시자입니다.
Apache Spark로 Iceberg 테이블 읽기
HadoopCatalog [https://iceberg.apache.org/javadoc/1.7.0/org/apache/iceberg/hadoop/HadoopCatalog.html]를 사용하여 Apache Spark에서 테이블 데이터를 설정하고 읽습니다.
다음 샘플은 Apache Iceberg에서 Spark SQL을 사용하도록 환경을 설정하고, 지정된 Iceberg 테이블에서 데이터를 가져오기 위한 쿼리를 실행합니다.
spark-sql \
  --packages org.apache.iceberg:iceberg-spark-runtime-
ICEBERG_VERSION_NUMBER \
  --conf spark.sql.catalog.
CATALOG_NAME=org.apache.iceberg.spark.SparkCatalog \
  --conf spark.sql.catalog.
CATALOG_NAME.type=hadoop \
  --conf spark.sql.catalog.
CATALOG_NAME.warehouse='
BUCKET_PATH' \

# Query the table
SELECT * FROM 
CATALOG_NAME.
FOLDER_NAME;
다음을 바꿉니다.
ICEBERG_VERSION_NUMBER: Apache Spark Iceberg 런타임의 현재 버전. Spark 출시 버전 [https://iceberg.apache.org/releases/]에서 최신 버전을 다운로드하세요.
CATALOG_NAME: Iceberg 테이블을 참조할 카탈로그
BUCKET_PATH: 테이블 파일이 포함된 버킷의 경로. 예를 들면 gs://mybucket/입니다.
FOLDER_NAME: 테이블 파일이 포함된 폴더. 예를 들면 myfolder입니다.
Iceberg 테이블 수정
Iceberg 테이블을 수정하려면 테이블 스키마 수정 [https://cloud.google.com/bigquery/docs/managing-table-schemas?hl=ko]에 표시된 단계를 따르세요.
가격 책정
Iceberg 테이블 가격은 다음 세 가지 구성요소로 구성됩니다.
스토리지
Iceberg 테이블은 모든 데이터를 Cloud Storage [https://cloud.google.com/storage?hl=ko]에 저장합니다. 이전 테이블 데이터를 비롯하여 저장된 모든 데이터에 대해 요금이 청구됩니다. 해당하는 경우 Cloud Storage 데이터 처리 [https://cloud.google.com/storage/pricing?hl=ko#process-pricing] 및 전송 요금 [https://cloud.google.com/storage/pricing?hl=ko#network-buckets]도 적용될 수 있습니다. BigQuery 전용 스토리지 요금은 없습니다. 자세한 내용은 Cloud Storage 가격 책정 [https://cloud.google.com/storage/pricing?hl=ko]을 참조하세요.
스토리지 최적화
Iceberg 테이블에는 파일 병합 및 재클러스터링과 같은 스토리지 최적화 작업이 필요합니다. 이러한 최적화 작업은 Enterprise 버전 사용한 만큼만 지불 슬롯 [https://cloud.google.com/bigquery/pricing?hl=ko#enterprise-edition-slots]을 사용하며 기존 BACKGROUND 예약은 사용하지 않습니다.
BigQuery Storage Write API를 통해 스트리밍하는 동안 실행되는 데이터 내보내기 작업은 Storage Write API 가격 책정에 포함되며 백그라운드 유지보수로 청구되지 않습니다. 자세한 내용은 데이터 수집 가격 책정 [https://cloud.google.com/bigquery/pricing?hl=ko#data_ingestion_pricing]을 참조하세요.
스토리지 최적화 사용량은 INFORMATION_SCHEMA.JOBS [https://cloud.google.com/bigquery/docs/information-schema-jobs?hl=ko#get-iceberg-storage-optimization-jobs] 뷰에 표시됩니다.
쿼리 및 작업
BigQuery 테이블과 마찬가지로 BigQuery 주문형 가격 책정 [https://cloud.google.com/bigquery/pricing?hl=ko#on_demand_pricing]을 사용하는 경우 쿼리 및 읽은 바이트 수(TiB당)에 따라 비용이 청구되며, BigQuery 용량 컴퓨팅 가격 책정 [https://cloud.google.com/bigquery/pricing?hl=ko#capacity_compute_analysis_pricing]을 사용하는 경우에는 슬롯 소비(슬롯 시간당)에 따라 비용이 청구됩니다.
BigQuery 가격 책정은 BigQuery Storage Read API [https://cloud.google.com/bigquery/pricing?hl=ko#data_extraction_pricing] 및 BigQuery Storage Write API [https://cloud.google.com/bigquery/pricing?hl=ko#data_ingestion_pricing]에도 적용됩니다.
로드 및 내보내기 작업(예: EXPORT METADATA)은 Enterprise 버전 사용한 만큼만 지불 슬롯 [https://cloud.google.com/bigquery/pricing?hl=ko#enterprise-edition-slots]을 사용합니다. 이는 이러한 작업에 비용이 청구되지 않는 BigQuery 테이블과 다릅니다. Enterprise 또는 Enterprise Plus 슬롯이 있는 PIPELINE 예약을 사용할 수 있는 경우 로드 및 내보내기 작업은 이러한 예약 슬롯을 우선적으로 사용합니다.
제한사항
Iceberg 테이블에는 다음과 같은 제한사항이 있습니다.
Iceberg 테이블은 이름 변경 작업 [https://cloud.google.com/bigquery/docs/managing-tables?hl=ko#renaming-table] 또는 ALTER TABLE RENAME TO 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#alter_table_rename_to_statement]을 지원하지 않습니다.
Iceberg 테이블은 테이블 사본 [https://cloud.google.com/bigquery/docs/managing-tables?hl=ko#copy-table] 또는 CREATE TABLE COPY 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#create_table_copy]을 지원하지 않습니다.
Iceberg 테이블은 테이블 클론 [https://cloud.google.com/bigquery/docs/table-clones-intro?hl=ko] 또는 CREATE TABLE CLONE 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#create_table_clone_statement]을 지원하지 않습니다.
Iceberg 테이블은 테이블 스냅샷 [https://cloud.google.com/bigquery/docs/table-snapshots-intro?hl=ko] 또는 CREATE SNAPSHOT TABLE 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#create_snapshot_table_statement]을 지원하지 않습니다.
Iceberg 테이블은 다음 테이블 스키마를 지원하지 않습니다.
빈 스키마
INTERVAL, JSON, RANGE 또는 GEOGRAPHY 데이터 유형이 있는 스키마
필드 콜레이션 [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=ko#collatable_data_types]이 있는 스키마
기본값 표현식 [https://cloud.google.com/bigquery/docs/default-values?hl=ko]이 있는 스키마
EXPORT METADATA [https://cloud.google.com/bigquery/docs/reference/standard-sql/other-statements?hl=ko#export_data_statement]는 정밀도가 38자리보다 큰 BIGNUMERIC 또는 NUMERIC 데이터 유형이 포함된 테이블을 지원하지 않습니다.
Iceberg 테이블은 다음과 같은 스키마 개선 사례를 지원하지 않습니다.
NUMERIC에서 FLOAT로 유형 강제 변환
INT에서 FLOAT로 유형 강제 변환
SQL DDL 문을 사용하여 기존 RECORD 열에 새 중첩 필드 추가
Iceberg 테이블은 콘솔이나 API에서 쿼리할 때 0바이트 스토리지 크기를 표시합니다.
Iceberg 테이블은 구체화된 뷰 [https://cloud.google.com/bigquery/docs/materialized-views-intro?hl=ko]를 지원하지 않습니다.
Iceberg 테이블은 멀티 문 트랜잭션 [https://cloud.google.com/bigquery/docs/transactions?hl=ko]을 지원하지 않습니다.
Iceberg 테이블은 변경 데이터 캡처(CDC) [https://cloud.google.com/bigquery/docs/change-data-capture?hl=ko] 업데이트를 지원하지 않습니다.
BigQuery Storage Write API를 사용하여 Iceberg 테이블로 데이터를 스트리밍할 때는 먼저 쿼리 캐시 [https://cloud.google.com/bigquery/docs/cached-results?hl=ko#disabling_retrieval_of_cached_results]를 사용 중지해야 합니다.
Iceberg 테이블은 관리형 재해 복구 [https://cloud.google.com/bigquery/docs/managed-disaster-recovery?hl=ko]를 지원하지 않습니다.
Iceberg 테이블은 파티셔닝 [https://cloud.google.com/bigquery/docs/partitioned-tables?hl=ko]을 지원하지 않습니다. 대안으로 클러스터링 [https://cloud.google.com/bigquery/docs/clustered-tables?hl=ko]을 고려하세요.
Iceberg 테이블은 행 수준 보안 [https://cloud.google.com/bigquery/docs/row-level-security-intro?hl=ko]을 지원하지 않습니다.
Iceberg 테이블은 시간 이동 [https://cloud.google.com/bigquery/docs/time-travel?hl=ko]을 지원하지 않습니다.
Iceberg 테이블은 장애 안전 기간 [https://cloud.google.com/bigquery/docs/time-travel?hl=ko#fail-safe]을 지원하지 않습니다.
Iceberg 테이블은 추출 작업을 지원하지 않습니다.
INFORMATION_SCHEMA.TABLE_STORAGE 뷰에는 Iceberg 테이블이 포함되지 않습니다.
Iceberg 테이블은 쿼리 결과 대상으로 지원되지 않습니다.
CREATE OR REPLACE는 표준 테이블을 Iceberg 테이블로 또는 Iceberg 테이블을 표준 테이블로 대체하는 것을 지원하지 않습니다.
일괄 로드 [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko] 및 LOAD DATA 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/load-statements?hl=ko]은 기존 Iceberg 테이블에 데이터를 추가하는 작업만 지원합니다.
일괄 로드 [https://cloud.google.com/bigquery/docs/batch-loading-data?hl=ko] 및 LOAD DATA 문 [https://cloud.google.com/bigquery/docs/reference/standard-sql/load-statements?hl=ko]은 스키마 업데이트를 지원하지 않습니다.
TRUNCATE TABLE은 Iceberg 테이블을 지원하지 않습니다. 다음과 같은 두 가지 대안이 있습니다.
CREATE OR REPLACE TABLE [https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language?hl=ko#create_table_statement]: 동일한 테이블 생성 옵션을 사용합니다.
DELETE FROM 테이블 WHERE true
APPENDS 테이블 값 함수(TVF) [https://cloud.google.com/bigquery/docs/change-history?hl=ko]는 Iceberg 테이블을 지원하지 않습니다.
Apache Spark의 Iceberg 내보내기에는 쓰기 최적화 스토리지에 최근에 스트리밍된 데이터가 포함되지 않습니다.
빠른 로드는 유연한 열 이름 [https://cloud.google.com/bigquery/docs/schemas?hl=ko#flexible-column-names]이 있는 파일을 지원하지 않습니다.
tabledata.list를 사용하는 레코드 기반 페이지로 나눈 액세스는 Iceberg 테이블을 지원하지 않습니다.
Iceberg 테이블은 연결된 데이터 세트 [https://cloud.google.com/bigquery/docs/analytics-hub-introduction?hl=ko#linked_datasets]를 지원하지 않습니다.
도움이 되었나요?
의견 보내기